\chapter{ToyWorld implementation}\label{toyworld-implementation}

ToyWorld is custom Python code that uses third-party packages and
libraries for certain functions. The most significant chunks of external
functionality come from RDKit, an open-source toolkit for
ChemInformatics, and PyMunk, a physics toolkit. Additionally, we use the
NetworkX package for Python for network graph manipulations (mainly in
the cycle evaluators) and in \url{Molecule} to determine the individual
molecules within an aggregation, and we use arrays from the Numpy
package for Python to record the molecular populations.

\section{RDKit}\label{rdkit}

RDKit provides a number of useful capabilities including format
conversions to and from SMILES \autocite{smiles}, a standard language
for representing molecules; simple visualisations of molecule structure;
standard sanity checks for molecular structure; and molecular
manipulations. RDKit is also well-tested, and keenly optimised for
performance.

The ToyWorld \url{Molecule} is a subclass of a RDKit \url{AllChem.Mol}.
Molecules in ToyWorld are therefore built from RDKit \url{Atoms} and
\url{Bonds}, although all manipulations and transformations of these
elements are written in our own code.

RDKit also provides a number of handy functions to the ToyWorld Chemical
Model:

\begin{enumerate}
\item
  Format conversions between RDKit molecules and a string representation
  of a molecule (SMILES); conversion from the representation of a
  molecule into a canonical form; and representation as a 2D graphical
  form
\item
  Reference information: for example, the mass of an atom and number of
  outer electrons for an atom
\item
  Molecular structure manipulation: iteration over the atoms or bonds in
  a molecule; addition, modification and deletions of bonds and atoms
\item
  Utility functions: combining two representations, each of one
  molecule, into one representation of two molecules, and vice versa;
  sanitising the representation of a molecule by checking for molecular
  validity
\end{enumerate}

These are so standard that it isn't worth our while to replace them with
anything specific to ToyWorld.

\section{PyMunk}\label{pymunk}

PyMunk is used extensively for 2D Physics calculations, for example:

\begin{enumerate}
\item
  Calculating the future position of a molecule inside a reaction vessel
  based on the molecules velocity and current position
\item
  Collision detection between two (or more) molecules
\item
  Summing the forces acting on a molecule and adjusting the molecule's
  acceleration
\item
  Simple visualisation of the molecules within the reaction vessel as
  shapes on a 2D plane
\end{enumerate}

\begin{algorithm}[ht]
$\text{collision list}=\{\}$\;
\BlankLine
\While{not finished}{
    \BlankLine
    \tcp{Selection of reactants}
    \While{$\text{collision list}=\{\}$}{
        Move all molecules by time increment $\tau$\;
        $\text{collision list} \leftarrow \text{all collisions}$\;
    }
    reactants $\leftarrow$ select two colliding molecules from collision list\;
    \BlankLine
    \tcp{Construction of reaction}
    Discover all possible reactions that could occur between reactants\;
    Determine the available energy to drive the reaction\;
    \BlankLine
    \uIf{$\exists$ a reaction option that is possible with the available energy}{
        Determine chemical products of the reaction\;
        Transform chemical products into physical molecules with kinetic and internal energy\;
        \uIf{a change in maximum or minimum molecular velocities}{\label{alg:adjust_tau}
            Adjust time step increment $\tau$\;
        }
    }
    \uElse{
        No reaction possible -- so just bounce the molecules off each other (a collision)\;
    }
}
\caption{The main simulation loop in ToyWorld}
\end{algorithm}

\begin{sidewaystable}
\begin{center}
\tiny
\begin{tabular}{@{}lllp{10cm}@{}}
\toprule
Parameter & Default value & Possible values & Description \\
\midrule
Energy&300&Int&The initial average kinetic energy (KE) for each molecule in the reaction vessel\\
EnergyModel&\url{DefaultEnergyModel}&Subclass of \url{DefaultEnergyModel}&More sophisticated model of energy inflow and outflow from the reaction vessel\\
RadiationRate&0.0&Float&Proportion of kinetic energy lost (apparently by radiation) each unit time interval from the reaction vessel\\
EnergyInput&0.0&Float&Absolute energy added to reaction vessel each unit time interval\\
Reactions&\url{EmergentReactions}&Subclass of \url{Reactions}&Reaction mechanism--EmergentReactions provides a fully constructive reaction chemistry\\
ProductSelectionStrategy&"energy"&String&See Section \cref{product-selection-strategies}\\
Molecule&molecule.Molecule&Subclass of Molecule&Model of a molecule\\
Vessel&\url{ReactionVessel}&Subclass of \url{ReactionVessel}&Model of the container in which the simulation proceeds\\
DipoleForceConstant&0.01&Float&Multiplier for the electro-magnetic force acting between two \url{ChargedMolecule}s\\
\midrule
name&<None>&String&Name of the experiment--primarily used to identify the output data files for the experiment\\
PopulationFilename&None&Filename&Name of the XML file defining the initial set of molecules to be placed in the reaction vessel\\
Iterations&10000&Int&Number of reactions before finishing\\
recover&True&Boolean&If True then do not redo completed repeats if the simulation is restarted, say after a machine reboot\\
repeats&1&Int&Number of replicates to run for this experiment\\
seed&None&Anything&Initial seed for the random number generation at the beginning of the experiment\\
DeltaT&1&Float&Size of a time-step in the simulation\\
StateRecordRate&0.01&Float&Recording interval for snapshots of \url{ReactionVessel} state information (e.g., molecule positions)\\
Visualize&False&Boolean&If \url{True} then display a PyMunk display of molecules, updated each DeltaT\\
ShowForceVectors&False&Boolean&If \url{Visualize} is \url{True} then show lines representing the electro-magnetic forces between \url{ChargedMolecule}s\\
ShowOrientation&True&Boolean&If \url{Visualize} is \url{True} then show a line representing a molecule's orientation\\
\bottomrule
\end{tabular}
\end{center}
\caption{Simulation Parameters in the Experiment Design XML file}
\label{tbl:simulation_parameters}
\end{sidewaystable}

\section{Workflow}\label{workflow}

Each run of an experiment in ToyWorld is usually split into three
stages:

\begin{enumerate}
\item
  Create the overall experiment design in XML--either manually, or by
  modifying an existing design, or by running \url{doe.py} which will
  generate an experiment design from a set of inputs.
\item
  Run the experiments with \url{main.py}, which takes an experiment
  design and executes it with optional logging, saving the data
  generated by each experiment repeat to a separate datafile for later
  analysis.
\item
  Analyse the resulting data either through \url{evaluate.py} or some
  other tool. \url{Evaluate.py} performs the evaluations defined in the
  experiment design, again with options for logging, saving the raw
  analysis output as text files for graphing or further statistical
  examination.
\end{enumerate}

The overall sequence of experiments to run is defined by an experiment
design. The experiments are run in the order they are defined, with all
replicates of an experiment being completed before we move to the
replicates of the next experiment in the sequence.

All replicates of an experiment are run with the same set of parameters
with the exception of a random seed which varies between replicates in a
predictable way. The reactions in the replicate are grouped into
fixed-size blocks and run in sequence with results saved incrementally
between each block. By writing incrementally we attempt to make sure
that a record of at least a partial set of reactions is recoverable
should the experiment come to a premature end.

\section{Evaluation and Analysis module}\label{evaluation-and-analysis-module}

ToyWorld provides a number of Evaluators, both numerical and graphical,
that can be used to analyse the results from each repeat of each
experiment.

The evaluations to perform are listed in the Evaluation section of the
experiment design, for example:

\begin{verbatim}
<Evaluation>
    <Method>evaluators.evaluator_summary.EvaluatorSummary</Method>
        <<Method>evaluators.plot_new_molecule_types.PlotNewMoleculeTypes</Method>
        <Method>evaluators.plot_new_cycle_types.PlotNewCycleTypes</Method>
        <Method partition="False">evaluators.evaluator_spatial_correlation.EvaluatorSpatialCorrelation</Method>
        <Method partition="True">evaluators.evaluator_cycles.EvaluatorActualCycles</Method>
        <Method>evaluators.evaluator_iterations.EvaluatorIterations</Method>
</Evaluation>
\end{verbatim}

\chapter{Systematic Map}\label{systematic-map}

The purpose of this \namecref{systematic-map} is to provide a systematic summary of the research area to:

\begin{enumerate}
	\item Outline where the proposed work fits into the existing body of knowledge.
	\item Ensure that we do not repeat previous work.
	\item Possibly identify future research directions.
\end{enumerate}

The research method is a an informal Systematic Map, derived from evidence-based medicine \parencite{Cochrane:2011qy, CRD:2008fj}. The major difference to a standard expert review is in the pre-definition of a research protocol, search strategy, exclusion and inclusion criteria, and quality criteria. All of these are documented so the review may be repeated or, given the difficulty of repeating a digital library search, at least evaluated by other researchers and practitioners.

\section{Need for a review}

To the best of our knowledge, no review has been published of our specific topic of inheritance in artificial chemistries.

\section{Method}
Our objective is to confirm that we have identified all relevant previous work:

\begin{enumerate}[label=RQ\arabic*:]
	\item What previous work in Artificial Life specifically discusses inheritance or heredity in artificial chemistries?
\end{enumerate}

\subsection{Systematic Reviews and Maps}

Systematic Maps \parencite{Petersen:2008fk} are exploratory (``what is known about X?'') while Systematic Literature Reviews \parencite{Kitchenham:2007nx} address specific research questions (``Is procedure X more effective than procedure Y for outcome O in context C?''). For Maps, ``The main goal of a systematic mapping studies is to provide an overview of a research area, and identify the quantity and type of research and results available within it. Often one wants to map the frequencies of publication over time to see trends. A secondary goal can be to identify the forums in which research in the area has been published.'' \parencite{Petersen:2008fk} For Systematic Reviews, \cite{Kitchenham:2007nx} recommends research questions address five criteria: population (those affected), intervention (method or technology under investigation), comparison (control method or technology), outcomes (factors or elements of comparison), context (in which the comparison takes place)

Systematic Maps also provide categorisation of a research area, but this is not the main goal of the process. Instead a Map uses the generated classification as a framework for further analysis, summarising contributions by category. However the processes are similar in that one process for categorisation in Maps \parencite{Petersen:2008fk} extracts keywords from the paper abstracts and iteratively groups and refines these into the final categories.

Note that both Reviews and Maps usually rely exclusively on Primary sources (originals) rather than Secondary (interpretation, or after-the-fact), or Tertiary sources (distillation or collections of Primary and Secondary sources).

\subsection{Inclusion and exclusion criteria}

\begin{itemize}
	\item \emph{Inclusions.} Primary research, published in conference proceedings or peer-reviewed journals.
	\item \emph{Exclusions}. Reference works, technical reports, biological modelling, education, introductions, summaries of research, case studies, application of research, abstracts of conference keynotes, computer art, biologically-specific works, programming paradigms, work related to the practice or theory of software engineering, and genetic programming and algorithms.
\end{itemize}

\subsection{Stage 1--Source selection}
The main conferences for \gls{alife} are Alife, the International Conference on the Synthesis and Simulation of Living Systems, and ECAL, the European Conference in Artificial Life, both published by MIT Press. The first in the Alife series, An Interdisciplinary Workshop on the Synthesis and Simulation of Living Systems, was held in 1987 at Los Alamos, New Mexico, and the $15^{th}$ is to be held in June 2016. Alife is now held biennially in even numbered years, although earlier conferences were more irregular. ECAL began  in 1991 with the $13^{th}$ and most recent held in 2015, and is also held biennially, in odd numbered years so as not to conflict with Alife.

Other sources were identified by examining the publishers and publications of the primary sources previously discovered by an earlier standard literature review. The main publishers were MIT Press, and Springer (indexed by \emph{Web of Science} and \emph{SpringerLink}, respectively), with the most common sources being the conference proceedings of \emph{Alife} or the journals \emph{Artificial Life} and the \emph{Journal of Theoretical Biology}, all indexed by \emph{Web of Science}).

\begin{table}
\footnotesize
\begin{center}
\begin{tabular}{@{}p{4cm}p{9cm}@{}}
\toprule
Data source & Rationale for inclusion\\
\midrule
ACM Guide to Computing Literature & Major computer science database and proceedings for \textit{GECCO}.\\
IEEE Xplore & Major computer science database and proceedings for \textit{IEEE Congress on Evolutionary Computing}.\\
Web of Science & Broad coverage, multiple fields, includes indexing for MIT Press publications.\\
SpringerLink & Lecture Notes in Computer Science series, including proceedings of \textit{ECAL}, \textit{CompLife}, \textit{Parallel Problem Solving from Nature conferences}, and other conferences.\\
Previously identified primary studies & Quality and consistency check\\
\bottomrule
\end{tabular}
\end{center}
\caption{Data sources}\label{map-data-sources}
\end{table}

No journals were directly included as these databases index all the journals identified during the earlier literature search. For example, the principal journals in the Artificial Life field, \emph{Artificial Life} and \emph{Adaptive Behaviour} \parencite{Aicardi2010}, are indexed by \textit{Web of Science}.

\Cref{map-data-sources} lists the sources used.

\subsection{Stage 2--Keywords}

The keywords used were driven by the research question, expanded with common synonyms:

\texttt{"artificial chemistry" AND (inheritance OR replicator OR template OR holistic OR reproduction OR reproduce OR heredity OR composome)}

\subsection{Stage 3--Automated Search}
Query parameters for each source are given in \cref{map-queries}.
\begin{table*}
\footnotesize
\begin{center}
\begin{tabular}{@{}lp{8cm}p{2cm}@{}}
\toprule
Datasource & Query & Results\\
\midrule
ACM Guide to Computing Literature & (+"artificial chemistry" inheritance replicator template holistic reproduction reproduce heredity composome)&73 records\\
\midrule
IEEE Xplore& "Abstract":“artificial chemistry” AND (“inheritance” OR “replicator” OR “template” OR “holistic” OR “reproduction” OR “reproduce” OR “heredity” OR “composome”)&6 records  \\
\midrule
Web of Science & (TS=("artificial chemistry" AND (inheritance OR replicator OR template OR holistic OR reproduction OR reproduce OR heredity OR composome))) AND LANGUAGE: (English)&26 records\\
\midrule
SpringerLink (via JabRef) &"artificial chemistry" AND (inheritance OR replicator OR template OR holistic OR reproduction OR reproduce OR heredity OR composome) & 129 records\\ 
\bottomrule
\end{tabular}
\end{center}
\caption{Query parameters for automated search. Searches were not restricted to any year range.}\label{map-queries}
\end{table*}

\subsection{Stage 4--Screening on title}

Combine all entries, and remove duplicates. After the removal of duplicates, 78 entries remained.

\begin{table*}
\footnotesize
\begin{center}
\begin{tabular}{@{}lp{6cm}@{}}
\toprule	
Literature & Result \\
\midrule
Coreworld \cite{Rasmussen1990} & No, no mention of replication or inheritance, just emergence.\\
Tierra \cite{Ray1991} & No.\\
Amoeba \cite{Pargellis2001} & No, no mention of ``Artificial Chemistry'', instead domain is given as ``Digital life''.\\
Avida \cite{Ofria2004} & No.\\
\cite{Nellis2012}\cite{Nellis2014} & No--abstracts reference embodiment and novelty but not inheritance and heredity.\\
StringMol \cite{Hickinbotham2012} & No, but similar found. This is a special case as  \cite{Hickinbotham2012} is a technical report rather than a peer-reviewed paper (see inclusion and exclusion criteria).\\
\cite{Fontana1992}	& No--abstract doesn't reference inheritance or heredity, but focusses on function composition and patterns.\\
\cite{Dittrich1998}	& No, but similar found.	\\
\cite{Nowostawski2005} & No.\\
\cite{Fenizio2000}\cite{Fenizio2001} & Yes.	\\		
NAC \cite{Suzuki2006}    & No, but similar found.\\
\cite{Gardiner2007}  & Yes.\\
\bottomrule
\end{tabular}
\end{center}
\caption{Rediscovery of existing key papers.}\label{map-existing}
\end{table*}

As a quality check, did we rediscover the papers we'd found earlier by expert search? And if not, why not? \Cref{map-existing} gives the results for this check. There are a variety of reasons why a number of previously-identified papers were not discovered, however the main cause is that some meta-information did not directly refer to replication or inheritance but rather implied it through a more general concept such as emergence. This is difficult to resolve with a keyword search without increasing the number of false positives.

\subsection{Stage 5--Screening on abstract}
Difficult to be error-free; preference is therefore not to exclude based solely on abstract unless clear-cut.

Issues specific to the abstracts:
\begin{itemize}
	\item Ambiguous terminology
	\item Insufficient detail in abstract
	\item Depth or degree--difficulty in determining the degree of focus on relevant ideas from the abstract. If a paper mentions generative ideas amongst other exclusion considerations, is the paper included or excluded? 
\end{itemize}

%\cite{smDecraeneMcmullin2011}
%\cite{smMadinaIkegami2004}
%\cite{smHutton2003}
%\cite{smKvasnicka2002}
%\cite{smBedauMcCaskillPackardEtAl2000}
%\cite{smSuzukiDittrich2009}
%\cite{smBanzhafBaumgaertnerBeslonEtAl2016}
%\cite{smBanzhafMcMullin2012}
%\cite{smBersini2010}
%\cite{smEibenKernbachHaasdijk2012}
%\cite{smGarzonBlainBobbaEtAl2003}
%\cite{smGohEweGoh2013}
%\cite{smHarrisChen2012}
%\cite{smHutton2003a}
%\cite{smIngerSolomonShenhavEtAl2009}
%\cite{smKobayashiSuzukiArita2012}
%\cite{smKvasnickaPospichalKalab2001}
%\cite{smMadinaOnoIkegami2003}
%\cite{smMenezesCosta2007}
%\cite{smSperonidiFenizioDittrich2007}--dynamics of chemical reaction system at different scales
%\cite{smStadler2016}
%\cite{smSuzukiIkegami2003}
%\cite{smGrossMcMullin2002}--micellar structures, response to other work on dynamical hierarchies
%\cite{smFenizioBanzhaf2001}--no mention of replication or inheritance
%\cite{smMcMullinGros2001}--autopoiesis based on Swarm Achem, and no mention of keywords in abstract
%\cite{smOnoFujiwaraYuta2005}--consideration of topological structures of networks, metabolism
%\cite{smGrosMcMullin2003}--general discussion around novelty in artificial chemistries
%\cite{smKomosinskiAdamatzky2009}--book, general discussion of available Alife software
%\cite{smMarro2013}--hard to determine content from abstract
%\cite{smGazzolaBuchananPackardEtAl2007}--no mention of keywords in abstract
%\cite{smFilisettiVillaniDamianiEtAl2014}--RAF sets, pre-replication
%\cite{smSuzuki2011}--no mention of keywords in abstract
47 records after abstract screening.

\subsection{Stage 6--Removal of duplicates}

Removal of exact duplicates--same publication source, title, authors. In practice performed during Stage 4 using JabRef's duplicate feature to identify potential duplicates. Unfortunately the JabRef algorithm appears to be case-sensitive, and so doesn't detect some potential duplicates that were then identified in a follow-up by inspection.

% sed -n "s/\stitle.*{\([^\}]*\)},/\1/p" post5.bib > titles
% sed -n "s/\stitle.*{\([^\}]*\)},/\1/p" ../mythesis.bib > fulltitles
% diff -iw titles fulltitles | grep -e "^<" | wc

Finally, we removed duplicates of previously identified works (32 duplicates), such as \cite{smFaulconbridgeStepneyMillerEtAl2011} which is closely related to \cite{Faulconbridge2011, Faulconbridge2010}.

\section{Results, and discussion}

At the end of the exercise, our Systematic Map contained 12 new papers:
\begin{enumerate}
\item \cite{smAdamsLipson2003}
\item \cite{smBobrikKvasnickaPospichal2008a}
\item \cite{smBobrikKvasnickaPospichal2008}
\item \cite{smEllabaan2007}
\item \cite{smSugiuraSuzukiShioseEtAl2003}--enhancements to Tierra
\item \cite{smFenizioMatsumaruDittrich2011}--discussion of AlChemy, and novelties so likely to involve replication
\item \cite{smHickinbothamClarkNellisEtAl2016}--StringMol, not clear if discuss replication, but given that other works concerning StringMol do, included
\item \cite{smHinzeFaslerLenserEtAl2009}
\item \cite{smSuzuki2003a}
\item \cite{smBanzhafDittrichEller1999}--``survival strategies'' might involve replication
\item \cite{smGordon-Smith2011}
\item \cite{smGohEweGoh2014}
\end{enumerate}

This review does have some limitations, of which the most serious are:
\begin{itemize}
	\item Subjective assessment of papers from title and abstract may miss some relevant studies based solely on quality of description.
	\item Sole researcher means no cross-checking of inclusions and exclusions.
\end{itemize}

\chapter{Applications of GRN in EAs}\label{applications-of-grn-in-eas}

Although a variety of approaches have been explored for genotype-phenotype encoding in EAs, two forms of inspiration are apparent. The following summary is drawn from the review in \textcite{Stanley:2003fh}:

\textbf{Grammatical approaches,} such as L-systems, Grammar Trees, Cellular Encoding, and the application of Genetic Programming to encoding, where the mechanism is based upon the manipulation of abstract data structures. The origins of the grammatical approach lie in the observation by \textcite{Lindenmayer:1968nl} that the structure of plants was essentially fractal and could be modelled by a series of nested rewrite rules. With the addition of parameters to control when and how a rule would become active the resulting L-system had the potential to describe many biological structures. L-systems however were never intended to be evolved, and so Lindenmayer's approach has needed to be adapted somewhat for use within evolutionary algorithms. Some researchers have modified the original string representation of the rules into a form more suitable for evolution, such as bit-strings \parencite{Boers:1992cn}, 2x2 matrices \parencite{Kitano:1990fs}, or graph structures (e.g.,\cite{Sims:1994uq}). Another direction, known as Cellular Encoding (Gruau, 1993), replaces the L-system rules by grammar trees, thus recruiting (inherently evolvable) Genetic Programming for developmental encoding.

\textbf{Cell chemistry approaches,} such as cell diffusion and Cellular Automata, where the mechanism is explicitly based upon processes found in living organisms. Given these considerations, the focus of this thesis is on \emph{biological} models as they possess the greatest likelihood of successfully capturing the range of behaviours in which we are interested. As \textcite{Stanley:2003fh} described, further development of biologically-inspired models has taken two philosophically defined paths. On one path, the research attempts to solve an independently interesting problem, such as neural network development, (\eg \cite{Bongard:2003tf}), with the expectation that this will speed the eventual realisation of a complete developmental system. However, on this path it can be difficult to assess the relative contribution of the developmental system itself within the much larger system. On the other path, researchers have chosen to focus on simpler proof-of-concept problems where the focus is on developing and demonstrating the particular aspects thought needed of a future goal system (\eg \cite{Bentley:1999zr,Roggen:2007kl}). This path however, in my opinion, presupposes that those particular aspects have been correctly identified.

The need for search space compaction is common in problems in design (e.g., \cite{Benedetti:2006bl,Nicolaou:2009hs,Yang:2009ch}), Neural Networks \parencite{Roy:2009jf}, and Electronic Circuit Design \parencite{Roggen:2007kl,Trefzer:2009qf,Tufte:2006bh,Remortel:2002fk}. Therefore one motivation for improving the genotype-phenotype encoding is to reduce the genotype complexity and to improve search performance.  

Other reasons also exist however: \textcite{Dorica:2007wq,Hornby:2003jt,Hornby:2005rw,Hornby:2006kj} believe that developmental encoding improves the modularity of solutions, which is particularly desirable in design problems; \textcite{Devert:2007wl,Federici:2006pb,Miller:2003qy,Roggen:2007kl,Trefzer:2009qf,Yu:1998hx} argue that developmental encoding improves the robustness of evolved solutions; and \textcite{Hornby:2005rw,Hornby:2006kj,Yang:2009li} are advocates for the belief that developmental encoding can improve solution quality as perceived by a human decision maker. 

The first two of these motivations are further explored in the sections below. 

\subsubsection{Search space compaction}

Search space compaction is related to genotype size as the size of the search space grows exponentially with the size of the genotype. A reduction in genotype size therefore leads to a reduction in the search space. Three types of embryological developmental system were compared in \cite{Bentley:1999zr}: a hand-designed development program which in effect used pre-developed modular components to construct complete solutions, an explicit embryology in the form of a program tree to control development and to act as a genotype, and an implicit embryology based on a CA with a gradient-directed development program. 

In the system described in \cite{Federici:2006pb} the issue at hand was how to increase genotype/phenotype correlation; that is, how differences between phenotypes can be made proportional to the difference between the genotypes. The mechanism described was Neutral Complexification (NC), or ``an increase in genetic material that is functional (expressed) but neutral to the phenotype'', implemented by duplication of a control gene within the \gls{grn} without immediate mutation. At each generation a single control gene may be duplicated; experimental results showed that this then resulted in improved genotype-phenotype correlation. However, the mechanism by which NC achieves this was essentially left unexplained. Interestingly, the \gls{ca} was controlled by a Recursive Neural Network (RNN) modelling a \gls{grn} with the claim that it was faster to evaluate than a standard model of a \gls{grn}, and that the evolutionary properties of RNNs were better understood than those of \glspl{grn}.

\subsubsection{Modularity}
The modularity displayed by most living organisms is striking: from the segmentation of thorax and abdomen in insects, to the repetition of fingers on a hand or toes on a foot.  These patterns are created by the expression of regulatory genes during development, and this has lead to the belief that developmental encoding might also improve modularity in artificial systems. 

\cite{Hornby:2003jt}) introduced a generic evolutionary development system, GENRE, and compared generative (incorporating repeated or reused elements) and non-generative L-system developmental programs on problems from a selection of design domains: voxels (cubes), neural-networks, robots, and neural-network controlled robots.  \cite{Hornby:2005rw} reapplied GENRE to table design and in \cite{Hornby:2006kj} extended the use of GENRE for robot design. All of these works demonstrated improvements in fitness over direct representation encodings that the authors attributed to the modularity, increased reuse of components, and possibility of large-scale mutations enabled by the L-system developmental program. \cite{Dorica:2007li} investigated the effect of developmental encoding on the performance of an EA for the design a 2-D patch antenna for operation at two radio frequencies. The most impressive evolved designs rediscovered and improved upon the design of a well-known E-patch antenna, and the developmental encoding adopted (the \emph{quadtree}--a recursive tree mapping from genotype to a grid cell within the 2-D space) resulted in a less fragmented and easier to manufacture shape. However, the quadtree genotype structure appears restricted to the design of 2-D structures, and may not be easily generalised.
