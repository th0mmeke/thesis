\chapter{Introduction}\label{introduction}

\settowidth{\epigraphwidth}{Wonderful life : the Burgess Shale and the nature of history}
\epigraph{%
Without hesitation or ambiguity, and fully mindful of such paleontological wonders as large dinosaurs andAfrican ape-men, I state that the invertebrates of the Burgess Shale, found high in the Canadian Rockies in YohoNational Park, on the eastern border of British Columbia, are the world's most important animal fossils. Modern multicellular animals make their first uncontested appearance in the fossil record some 570 million years ago--and with a bang, not a protracted crescendo.}%
{\textit{\\Wonderful life : the Burgess Shale and the nature of history}\\\textsc{Stephen Jay Gould}}

\begin{NOTES}
	
``One must clearly distinguish between heredity (a relation), heritability (a capacity), and inheritance (a process)'' \autocite{Griesemer2005}
	
Constitutive definitions of \gls{oee}
Emergent systems easy to code but produce surprising results. Cannot predict results from rules (or in fact easily predict rules from desired results. One-way function, akin to encryption) \parencite{Nellis2014}

Much of this work falls under the banner of \gls{alife}, both weak and strong as distinguished by \cite{Langton1989}: ``study the phenomena of life, not by simulating life as it is (weak AL) but by instantiating life as it could be (strong AL)''

First, a distinction: open-ended evolution refers to a goal or result, while evolution-of-evolution, or EvoEvo, describes a process or mechanism. The first is constitutive, the second causal. In artificial systems, the most influention formulation of the problem overall remains that of \cite{Bedau:2000mi}:

\quote{A key challenge is whether digital systems based on symbolic logic harbor the same potential for evolutionary innovation as physical systems. A preliminary challenge is to unlock the full potential of evolution in digital media. Many believe that digital life today falls far short in this regard, and this issue is starting to be approached quantitatively.}{\cite{Bedau:2000mi}}

\parencite{Taylor2001} like others makes a distinction between OEE and ``kinds of evolutionary innovation''. He gives as an example of limited innovation the emergence of paratism in \cite{Ray1991} as direct result of system design and initial seeding conditions. In this reading, ``fundamentally new'' (labelled by Taylor as ``creative'') means new ways of sensing the environment and interacting with it \cite{Taylor2001}.

\quote{by open-ended evolutionary capacity we understand the potential of a system to reproduce its basic functional-constitutive dynamics, bringing about an un-limited variety of equivalent systems, of ways of expressing that dynamics, which are not subject to any predetermined upper bound of organizational complexity (even if they are, indeed, to the energetic-material restrictions imposed by a finite environment and by the universal physico-chemical laws)}{\cite{Ruiz-Mirazo2004}}

\begin{compactitem}
	\item An open-ended evolutionary system must demonstrate unbounded diversity during its growth phase.
	\item An open-ended evolutionary system must embody selection.
	\item An open-ended evolutionary system must exhibit continuing (``positive'') new adaptive activity.
	\item An open-ended evolutionary system must have an endogenous implementation of niches.
\end{compactitem} \cite{Maley1999} (considered ``rather abstract'' by Hutton \parencite[p.341]{Hutton2002}).

``openendedness depends fundamentally on the continual production of novelty.'' Standish, in \parencite{Soros2014}

``we would like the evolutionary system, like life, to continue to produce individuals of increasing complexity and diversity.''--although note, following McShea, that much of life is single-celled and hasn't become much more complex in billions of years \parencite{Maley1999}

\quote{by open-ended evolutionary capacity we understand the potential of a system to reproduce its basic functional-constitutive dynamics, bringing about an un-limited variety of equivalent systems, of ways of expressing that dynamics, which are not subject to any predetermined upper bound of organizational complexity (even if they are, indeed, to the energetic-material restrictions imposed by a finite environment and by the universal physico-chemical laws.}{\parencite{Ruiz-Mirazo2004}}
\end{NOTES}

\section{Motivation}\label{motivation}

\begin{NOTES}
Perpetual production of novelty
unbounded evolution
The potential size and complexity of the individuals' phenotypes should be (in principle) unbounded.  \parencite{Soros2014}
Unlimited heredity--number of possible heritable types should astronomically exceed individuals in population \parencite{Vasas2015}.

continual production of complexity
essence of life

\autocite{VonNeumann1966} as reviewed in \autocite{Taylor1999} (Lack of environmental emphasis)
Von Neumann's architecture for how ``complicated machines could evolve from simple machines''

\begin{enumerate}[label=\Alph*]
	\item A \emph{constructive} machine that takes a description and builds a new machine;
	\item A \emph{copying} machine to make a copy of a description, and 
	\item A \emph{control} machine to sequence the other two machines - first the copying machine, then constructive, then finally to link the new machine to its description.
\end{enumerate}

Von Neumann makes a fundamental distinction between a description of a machine and the machine itself; in biological terms, the architecture separates between genotype (description) and phenotype (the machine.) However, because some of the function of the three machines (A, B, C) are provided by the world there is a limit to how self-referential the system can be, and hence how much its function can evolve over time.

Taylor states ``I would suggest that the reproducing programs in Tierra and similar systems can also sensibly be analysed in terms of von Neumann's architecture.''

Just a few years later, \autocite{Waddington2008} as reviewed in \autocite{Taylor:1999sc}--Originally published in ``Towards a Theoretical Biology, Vol. 2'' in 1969

Also Genotype (G) and Phenotype (Q*) based, where Q* associated with an environment (E from Ej)

For OEE need: Ej infinite numbered set, and sufficient Qs for Q*s for all those Ejs

Q*s are part of Ej satisfies condition one {[}recursive?{]}

Second is an emergent one - ``it is not sufficient to create new mutations which merely insert new parameters into existing programmes; they must actually be able to rewrite the programme''
- key distinction between OEE and creative evolution

\parencite{Maley1999}
Focus on diversity (to make progress), as measured by new adaptive activity, $A_new$. Some suggestions previously that diversity is bounded (at minimum, by number of molecules available for biosphere, also by energy and minimal populations and probably other things), and plateaus (punctuated equilibrium). Indicates two time constants - a fast expansion to use available resources, with a slower rhythm of innovations to create and enter new adaptive spaces.

Maley builds up the requirements by beginning with almost the simplest model possible (called Urmodel 1) where the only changes in a population from generation to generation are 1-bit flips in a 32-bit genotype. This results in a neutral fitness landscape, and the (unsurprising) result was unbounded diversity but no heritable effect on fitness.

Selection was added to Urmodel 2, based on the hamming distance ``dissimilarity'' between the species competing for an available niche (or vacant location on a 256x256 grid)) where there is selective advantage for the most dissimilar, justified by biological example of niche overlap theory. However, $A_new$ trended towards $0$.

Urmodel 3 moved to a model where fitness is determined by the degree of match (number of bits with same value) between a parasite and a single fixed ``host'' bit pattern. Maley claims that Urmodel 3 shows unbounded activity using measure $A_new$--``the first known artificial evolutionary system demonstrating unbounded evolutionary activity''. But in Maley's words this is probably not a unique or even significant result--``The only trick is to defer the point when the model hits its true asymptotic behaviour for long enough that the growth dynamics of the model are themselves asymptotic in some sense'' \parencite{Maley1999}.

Note that the niches in Urmodel 3 are imposed from outside, rather than arising endogenously. This leads to Urmodel 4, where coevolution is added to Urmodel 3 by letting hosts mutate. Urmodel 4 also showed ``unbounded`` evolutionary activity.

No model however resulted in ``surprise''. Maley believes this is because of a lack of complexity, illustrated through a nice biological metaphor: ``A puddle of inert, multicoloured and diverse algae would not be nearly so inspirational as the rain forest.''



\Textcite{Taylor2001,Taylor:1999sc} discuss creativity in \gls{oee} in depth and argues that, for it to be possible, the replicators must \parencite{Hutton2004}:
\begin{compactenum}
	\item Be fully embedded in their arena of competition 
	\item Have rich, unlimited interactions between each other and with their environment 
	\item Initially replicate implicitly, rather than using some encoding of the replication process, and 
	\item Be constructed entirely of `material' components, allowing the possibility of different encodings of information. (\quote{the very stuff from which they are constructed is a valuable resource of matter and energy}{\cite[s3.6]{Taylor2001}})
\end{compactenum}

``the potential for a large degree of intrinsic adaptation'' \parencite{Taylor2001}

\parencite{Soros2014} presents four necessary conditions for OEE (it is left open if these are also sufficient conditions):
\begin{compactenum}
	\item A rule should be enforced that individuals must meet some minimal criterion (MC) before they can reproduce, and that criterion must be nontrivial.
	\item The evolution of new individuals should create novel opportunities for satisfying the MC
	\item Decisions about how and where individuals interact with the world should be made by the individuals themselves.
	\item The potential size and complexity of the individuals' phenotypes should be (in principle) unbounded.
\end{compactenum}
Along with these specific conditions, \parencite{Soros2014} assumes certain general conditions: a ``good'' genetic representation, a ``sufficiently large world for every individual to be evaluated'', and a seed or starting point.

Minimal conditions for OEE \parencite{Vasas2015}:
\begin{compactenum}
	\item Very rich combinatorial generative mechanism \eg organic chemistry.
	\item Unlimited heredity--number of possible heritable types should astronomically exceed individuals in population (Maynard-Smith:1995lw).
	\item Inexhaustible fitness landscape--implies rich, dynamical environment.
	\item Cannot state in advance possible preadaptations.
\end{compactenum}

General difficulty with grounding these definitions, as the terms on which they rely are themselves only loosely defined (although commonly understood). \parencite{BanzhafBaumgaertnerBeslonEtAl2016}. As \textcite{Gayon2010} notes, many fundamental things generally taken for granted, such as ``life'' and ``energy'', are hard to define. 

``We therefore arrive at two contrasting definitions. On the one hand, there is the idea of continual (unbounded) creation of \emph{novelty}, which appears to be necessary but not sufficient. On the other hand, there is the notion of continual (unbounded) creation of \emph{complexity}, which appears to be sufficient, but not necessary for OE.'' \parencite{BanzhafBaumgaertnerBeslonEtAl2016}
\end{NOTES}

\begin{mdframed}[style=box, frametitle={Creativity, and its relationship to Novelty, Surprise, and Value}]
Creativity is related to exploration--how we explore and what we find--a general problem in Artificial Life, Artificial Evolution, and in fact life in general. That no standard definition exists is a good indication that this is a hard problem. Intuitively, creativity is something that causes a sense of surprise or wonder in an observer. Creative systems and products are beautiful; interesting; impressive; novel; surprising; transformative.  For example, in \parencite{Lehman2012}, creativity is related to beauty and interestingness--while impressiveness is time-independent, interestingness often drops over time.

Following \textcite{Boden2004}, a starting point might be that creativity is a \emph{process} that results in \emph{artifacts} with the properties of novelty, surprise, and value. It's clear that to \cite{Boden2004} not all novelties are creative; creativity means something more than change-for-changes sake. Creativity is the ability to come up with ideas or artifacts that are \begin{inparaenum}[1)]\item new--a jump not just extension,\item surprising--statistically unlikely, or unexpectedly belonging to a class, or thought impossible--a sense of wonder and \item valuable--a sense of a deeper meaning; fitness or appropriateness or usefulness \end{inparaenum}\parencite{Boden2004}. Perkins interprets \cite{Boden2004} as saying that creativity is a search plan that breaks or changes the rules (or representation or landscape) so as to make previously inaccessible (or hard to access or isolated) regions of the search space (the ones that contain new, surprising and valuable items) accessible (or rich) \parencite{Perkins1995}. For example, moving from individual organisms to assemblages or aggregations (changing the level of selection--a rule change) would certainly be seen as novel, surprising and valuable.

For Dorin and Korb \cite{Dorin2009} creativity is primarily connected to rareness--if something was rare but is now less rare in another framework, then the framework is more creative. Value (and incidentally appropriateness) is explicitly denied \cite[p.18]{Dorin2009}, in part because of the difficulty of defining value in a general way. Novelty is important, but comes as a consequence of the introduction of a new framework which generates novel patterns. In \cite[p.16]{Dorin2009} though, novelty is introduced as the time lag between successive more creative frameworks--humans become habituated to ideas, so novelty means surprise. Surprise is therefore equated with one (``unlikely'') of Boden's three ideas of surprising (``unlikely or unfamiliar'', ``unexpectedly belongs to a class'', and ``thought impossible.'')

\emph{Novelty} can be seen as either historical novelty (new to all) or psychological novelty (new to self), where the latter is more interesting as a superset of the former (and removes historical chance.)\footnote{I would argue that in biology, the identification of novelty has been essentially subjective based upon a reading of the historical record to identify patterns and changes in those patterns. Any measures, such as proposed by \cite{McShea1998,Maynard-Smith:1995lw,Walker2012} are post-hoc.}

Almost by definition, novelty is difficult to identify. A straightforward definition would suggest we're interested in changes--identifying significant changes seems reasonable, but changes in what? Pre-identifying characteristics to monitor limits our scope, and our imagination, to those characters. How do we create a list of existing characters as a baseline? How could this be done objectively? And what about completely new characters? How could we ever describe those ahead of time? In other words, if we can describe it ahead of time, it isn't novel. A second related issue is one of \textit{reification}--if these characters emerge from lower-order operations, rather than being specified, then we need a mechanism to identify, capture, and describe each new one.

Systems which are only random are not creative (\eg Racter in \cite[p.16]{Dorin2009})--it seems that novelty is not enough, and random variation within bounds that do not change is quickly seen as normal and not novel. 

Next, changes are obviously relative, so we must identify what we are comparing--within a population there is inherent variation. Do we compare to an average, or to a range? And presumably the population is undergoing evolution, and therefore there will be some underlying trends. To be significant, any change should be more than just an acceleration (or dimunition) of a pre-existing trend. Finally, at what point can we declare a novelty? On its first appearance? Perhaps though the putative novelty is maladaptive, and doesn't last beyond one generation. Perhaps it doesn't even last that long: the individual isn't viable. Hereditary lineages (\eg Fitness Transmission \parencite{Miconi:2007xh}) might be one approach to this. For all of these reasons, any objective measure of novelty based on characters seems in practice impossible. This problem applies to both physical characteristics, such as cellular membranes, or legs, and processes, such as cross-membrane transport or genome replication.

\emph{Surprise} is almost as difficult to define as creativity, as it is also relative in general to an observer, but previous work has successfully equated surprise with rarity (\eg \cite{Kowaliw2009}). Related to surprise, is impressiveness or ``rare and hard-to-recreate'' \parencite{Lehman2012}: an asymmetrical transformation in that is easy to recognize yet hard to create, and so similar to NP-completeness, which can be verified but not solved in polynomial time \parencite{Lehman2012}.

\emph{Valuable} seems at first problematic: valuable to who? Introducing an observer into the definition freights in subjectivity and the associated practical difficulty of capturing the observer's assessments. A pragmatic answer might instead be that it is valuable to itself--valuable ideas are ones that are successful, or in other words, that are of high fitness. 
\footnote{\cite{Bringsjord2000} argues that Boden is wrong in two ways: first, that computer creativity does not shed much insight into human creativity (citing Searle's Chinese Room to demonstrate that shuffling symbols, as a creative AI would do, doesn't add much to our understanding), and second, that Boden's formulation of a rule change is too weak. Systems (citing BRUTUS) that are not considered creative, do rule changes of the form proposed by Boden. Instead, these changes must be more special than simple first-order logic. The first criticism is not relevant to us (echoed by \cite{Dorin2009}), but the second holds.}
\end{mdframed}

\begin{NOTES}
\Cite{BanzhafBaumgaertnerBeslonEtAl2016} (an outcome of a workshop held in the summer of 2014 on ``Open-ended Novelty'', attended by many of those whose works are cited elsewhere in this thesis) provide a satisfying way to formalize novelty by making the idea of \cite{Boden2004}, that novelties ``break the rules'', explicit in the form of models and meta-models. By proposing a standard meta-model to describe any \gls{oee} system, be it living or non-living, \cite{BanzhafBaumgaertnerBeslonEtAl2016} can then define three levels of novelty by their effect on the model of the system itself and the overall meta-model:

\begin{itemize}
	\item Type-0 variation--novelty occurs within the scope of the existing model, by changing the values of existing variables.
	\item Type-1 innovation--changes to the model itself, either new types or relationships.
	\item Type-2 emergence--changes to the meta-model, again either in the form of new meta-types or meta-relationships between meta-types.
\end{itemize}
	
The significance of this formulation is that novelty for almost the first time becomes non-subjective and measurable (assuming agreement on the overall meta-model, and that a model for the specific system can be defined.)
\end{NOTES}

\subsection{Elements/Embodiment/Emergence}
\begin{NOTES}
Open-ended evolution can be seen as the outcome of evolution in an open-ended system (\eg Chemistry), where an open-ended system has effectively unrestricted representation: the number of possible types must be much larger than the number of individuals. In the terminology of \cite{Szathmary:2006ty}, these are unlimited replicators, in contrast to limited replicators where the number of possible types is less than the number of individuals. Without this property all possible types can be generated in a finite time, and the system will either reach stasis or begin to repeat. Not all open-ended systems necessarily support evolution, but in those that do, our intuition suggests that open-ended evolution produces increasing complexity, increasing diversity, accumulation of novelty and continual adaptation \parencite{Lehman2012}.

Everything in our artificial world must be built from a common set of raw materials; a loop connects the targets of selection with the environment. Other work, although superficially similar in that it models objects of similar scale, uses different models for the objects and the world (see \parencite{Sanchez-Dehesa:2008uq}) and so lack this loop.

Similar to the \emph{semantic closure} of \cite{Pattee1995a}--``organisms should be constructed `with the parts and laws of an artificial physical world''' \cite{Taylor2001}
Smith-Szathmary hypothesis that major transitions in biology are characterized by new ways of transmitting information. Adami follows this direction in stating ``It is probably more appropriate to say that evolution increases the amount of information a population harbors about its niche (and therefore, its physical complexity).'' \cite{Adami2002}

\cite{Pattee1995a}: complementary matter (\eg genotype, hardware, brain, physical laws)--symbol (\eg phenotype, software, mind, measurements) aspects (referred to as \textit{Semantic Closure}) define life. Matter is objective and compressible; symbols are subjective and incompressible, specific to the individual's purpose. Semantic Closure is also a necessary condition for \gls{oee}. \Textcite{VonNeumann1966}

The argument is as follows: evolution requires self-replication. Self-replication requires both matter and symbols. In essence, \quote{"the organism's measurement,memory, and control constraints must be \textit{constructed} by the genes of the organism from parts of the artificial physical world.}{\cite[p.29]{Pattee1995},emphasis in original} 

\cite[p.29]{Pattee1995}: three fundamental types of knowledge must be represented in models of \gls{alife}: laws, initial conditions, and statistics. Given that initial conditions are measurements, the implication is that \quote{any form of artificial life must be able to detect events and discover laws of its artificial world.}{\cite[p.29]{Pattee1995}}

\quote{Additionally, from an epistemological point of view, Pattee (1995b) points out that symbolic information (such as that contained in an organism's genes) has ``no intrinsic meaning outside the context of an entire symbol system as well as the material organization  that constructs (writes) and interprets (reads) the symbol for a specific function, such a classification, control, construction, communication\ldots''. He argues that a necessary condition for an organism to be capable of creative open-ended evolution is that it encapsulates this entire self-referent organisation (Pattee refers to this condition as semantic closure). From this it follows that organisms should be constructed ``with the parts and the laws of an artificial physical world'' Pattee (1995a) (p.36). In other words, the interpretation (phenotype) of the symbolic information (genotype) of an artificial organism should be constructed and act within the artificial physical environment of the system. Additionally, if the system is to model the origin of genetic information, then the genotype itself must also be embedded within the environment; that is, the complete semantically-closed organisation `the entire organism' must be completely embedded within the physical environment. }{\cite[p.82]{Taylor2001}}

``From the point of view of the evolvability of individuals, the more embedded they are, and the less restricted the interactions are, then the more potential there is for the very structure of the individual to be modified. Recall that this is one aspect of my definition of creative evolution. Sections of the individual which are not embedded in the arena of competition are `hard-wired' and likely to remain unchanged unless specific mechanisms are included to allow them to change (and the very fact that specific mechanisms are required suggests that they would still only be able to change in certain restricted ways).'' \cite{Taylor2001}

Resources must be ``(a) a vital commodity to individuals in the population; (b) of limited availability; and (c) that individuals can compete for (at either a global or local level). This resource can usually be interpreted as en\eg space, matter, or a combination of these.'' \parencite{Taylor2001}

Need something emergent. \parencite{Nellis2014}
A ``good'' genetic representation \parencite{Soros2014}
Contains an interesting discussion mapping a list of desirable properties onto the emergent properties that are then required of an \gls{achem} \parencite{Faulconbridge2010, Faulconbridge2011}
``A phenomenon is embodied within a world if there exist some mechanisms within the world that enable the phenomenon to emerge.'' \cite{Nellis2014}
Quick defined embodiment in terms of two dynamical systems mutually affecting each other--no need for a physical world. System modifies environment. Doesn't address if system is constructed from environment. Autopoiesis does say though that system built from environment. But autopoiesis talks about maintenance not evolution. \parencite{Nellis2014}

Bottom-up models for open-ended evolution leverage the richness of underlying environment--less information in entity definition, more in environment definition. Similar to biology, where physics and chemistry underpin living organisms, where definition of minimal cell many orders of magnitude simpler than the working out of the chemical and physical rules that it relies upon. Top-down models assume a knowledge of the necessary elements.
\end{NOTES}

\subsection{Selection}
\begin{NOTES}
Individuals and environment mutually affect each other \parencite{Taylor2001}
Competition between individuals for resources--VanValen1973 Red Queen hypothesis--primary source of intrinsic selection pressure. \parencite{Taylor2001}
Ray made similar arguments in favour of interactions with other individuals (rather than isolated as in EA) 
Decisions about how and where individuals interact with the world should be made by the individuals themselves. \parencite{Soros2014}
A rule should be enforced that individuals must meet some minimal criterion (MC) before they can reproduce, and that criterion must be nontrivial.\parencite{Soros2014}
The evolution of new individuals should create novel opportunities for satisfying the MC \parencite{Soros2014}
A ``sufficiently large world for every individual to be evaluated'' \parencite{Soros2014}
``the potential for a large degree of intrinsic adaptation'' \parencite{Taylor2001}
Inexhaustible fitness landscape--implies rich, dynamical environment. \parencite{Vasas2015}
Cannot state in advance possible preadaptations. \parencite{Vasas2015}
``the most important aspect of an organism's environment are the other organisms with which it interacts'' \parencite{Maley1999}
\end{NOTES}

\subsection{Replication, reproduction and inheritance}\label{replication-reproduction-and-inheritance}

\begin{NOTES}
Initially replicate implicitly, rather than using some encoding of the replication process  \parencite{Taylor2001}
Be constructed entirely of `material' components, allowing the possibility of different encodings of information. (\quote{the very stuff from which they are constructed is a valuable resource of matter and energy}{\cite[s3.6]{Taylor2001}})
Very rich combinatorial generative mechanism \eg organic chemistry \parencite{Vasas2015}
``An important property of most strong AL systems is that they contain the ability for self-reference. For instance, Ray's Tierra organisms are able to read, copy, and modify their own code. In Fontana's algorithmic chemistry every object is a character string able to process other objects by using the lambda-calculus that maps the character string into an (active) function. The dualism inherent in those systems can be traced back to Godel who defined a mapping of mathematical statements into natural numbers `` that allowed self-reference, to Turing's universal machine, and to von Neumann's stored program computer .''\parencite{Dittrich1998}
``The term self-evolution should refer to an evolutionary process within a population system where the components responsible for the evolutionary behavior are (only) the individuals of the population
system itself. Every variation is carried out by the individuals. Selection pressure is generated implicitly through interaction among the individuals and not by external agents. The system must not contain a component that can be identified as a fitness function or global operators performing selection or variation (\eg crossover).'' \cite{Dittrich1998}
``We want to embody the copying program, implementing it as a phenomenon resulting from the interaction of multiple mechanisms in a world. This will allow the copied strings to vary and evolve, and will also allow the copying process to vary and evolve.'' \cite{Nellis2014}
``Rasmussen then designed a system similar to core war in which the command that copied instructions was flawed and would sometimes write a random instruction instead on the one intended.'' \parencite{Ofria2004}
\end{NOTES}
\begin{NOTES}
\autocite{Watson2015}:
Darwinian machine is fundamentally self-referential - products of evolution affect process of evolution - lots of examples
\begin{itemize}
\item Major transitions in evolution not possible without self-referentiality - unit of evolution must change between levels e.g., from molecules to cells. This was/is accomplished by changing the way that individuals interact, from competition to cooperation (fitness change) to form the next level. How does selection at one level get suppressed, and introduced at the next?
\item Independent replication before transition, must replicate as part of a larger whole afterwards
\item Fundamental for complexity - complexity associated with levels
\item Draws analogy with Hinton 2008 Deep Learning
\item At one level, supervised learning improving adaptation; at next higher, unsupervised improving robustness
\end{itemize}
\end{NOTES}

\section{Background and context}\label{background-and-context}

There has long been interest in understanding how biological evolution generates robust, novel, creative outcomes, unlike those seen in current artificial evolutionary systems. This has led to a drive towards understanding the fundamentals of biological evolution rather than in the historical inspiration of specific biological elements and structures, many of which are contingent and perhaps even arbitrary; certainly complex.
	
This \namecref{background-and-context} expands upon prior work that is relevant, but not specific, to our thesis to provide context and background.

\subsection{Life}\label{life}

\epigraph{%
In the world of human thought generally, and in physical sciences in particular, the most important and most fruitful concepts are those to which it is impossible to attach a well-defined meaning.}%
{\textsc{\\H.A. Kramers}}

Natural evolution is the best example we have today of a transformative, adaptive improvement process. Many fields would benefit from a robust general optimisation heuristic for use when exact methods are not possible, and the example of natural evolution is our current gold-standard. 

As stated by many (\eg \cite{Pascal2013, Malaterre2015}) a definition of life is elusive, and probably not useful. There is no definite boundary between the living and the non-living; as \parencite{Pascal2013} goes on to explain, the most likely scenario for the origin of life is that there was a series of intermediates, of increasing degrees of ``aliveness''. The corollary is that it is hard therefore to imagine a clear cut transition between non-living and living. Think of a present day virus--is it alive, or not? Reproduction is generally thought of as a requirement for life, yet viruses cannot reproduce without co-opting the necessary machinery from an independent host. 

\parencite{Fernando:2007pf} presents a partial compendium of definitions which illustrates the range of opinion:

\quote{
...at least one of the following outcomes: ‘open-ended evolution’ (Bedau et al., 2000); the origin of basic autonomy, i.e. a dissipative system capable of the recursive generation of functional constraints (Ruiz-Mirazo et al., 2004); a process ultimately capable of the production of nucleic acids or other modular replicators with unlimited heredity potential (Maynard-Smith and Szathmary, 1995; Szathmary, 2000); identification of ``the course of evolution by which the determinate order of biological metabolism developed out of the chaos of intercrossing reactions'' (Oparin, 1964); the coupled cycling of bioelements (Morowitz, 1968, 1971); the maximization of entropy production by a biosphere (Kleidon, 2004); the minimal unit of life (Ganti, 2003a, b); or an autopoetic unit (Maturana and Verela, 1992)?}{\parencite{Fernando:2007pf}}

One interesting distinction between living and non-living comes from \parencite{Rasmussen2004}--non-living systems explore a state-space driven by thermodynamics, and so in a sense through a random ergodic search. Living systems however almost universally employ evolution. Another information-theoretic view, from \parencite{Adami2015}, is that living systems can preserve information on a much longer timescale than non-living things. Given the relationship between information and entropy, the statement about metabolism in \cite{Schrodinger1944}--how ``living matter evades the decay to equilibrium''--seems very similar.

\begin{mdframed}[style=box, frametitle={The orgins of life}]

The evolution of life was almost certainly contingent, and there is an absence of evidence from early stages \parencite{Pross2013}. There were many possible pathways, and unless some record remains somewhere (either geological or phylogenetic), the actual path is essentially lost to history. So without evidence for historic aspect, it is not possible to test hypotheses by falsification, and hence they can only be speculative.

However, a consensus is forming that early life began with chemoautotrophs fueled by energy from inorganic redox couples and biomass from CO\textsubscript{2}, and that innovations in carbon-fixation created the main branches in the tree-of-life \parencite{Braakman2012}. Initiation of selection marked by \gls{ida}, probably from RNA world, followed substantially later by Last Universal Common Ancestor (LUCA) \parencite{Yarus2011}, which, it is important to note for clarity, was almost certainly not a single cell or even species, but rather a construct of evolutionary genetics because of the likely predominance of Lateral Gene Transfer (LGT) in archaic biology (http://sandwalk.blogspot.ca/2007/03/web-of-life.html).

Self-replicating RNA enzymes shown in \parencite{Lincoln2009}, forming basis of selective system (link to natural selection) (also see \parencite{Cheng2010}, \parencite{Powner2009} for formation of RNA in prebiotic conditions). Some elements of \gls{ida} thought still with us in lineages of informational (for protein synthesis and RNA transcription) and operational genes (for some standard cellular processes) \parencite{Ragan2009}, for example the ribosome and ribonuclease P (RNase P) \parencite{Wilson2009}. Next major transition to Protein world (although predominance of RNA transcripts leads to suggestions that should be called RNA-Protein world \parencite{Altman2013}). Note however that Lateral or Horizontal Gene Transfer thought to have been so common in early life that there was no single common ancestor, but genes from multiple lineages combined into all lineages today.\parencite{Ragan2009}

\begin{tikzpicture}
\node (prebiota) at (0,0) {prebiota};
\node (metabolism-first) at (1,-1) {metabolism-first} edge [<-] (prebiota);
\node (replication-first) at (1,1) {replication-first} edge [<-] (prebiota);
\node (acs) at (2,0) {autocatalytic sets} edge [<-] (replication-first) edge [<-] (metabolism-first);
\node (ida) at (4,0) {IDA} edge [<-] (acs);
\node at (5.5,0) {LUCA} edge [<-] (ida);
\end{tikzpicture}

Two alternative models exist for the step from abiotic to \gls{ida}: genetic or replicators or RNA-first, and metabolism or protein-first. Both metabolism and replication were almost certainly required for \gls{ida} however. A self-sustaining autocatalytic network (in terms of a RAF set specifically a ``set of molecules and reactions which is collectively autocatalytic in the sense that all molecules help in producing each other (through mutual catalysis, and supported by a food set).'') generally considered essential \parencite{Pross2013}, but not sufficient \parencite{Hordijk2011}. Both competing models--replication first and metabolism first--build on that. Autocatalysis expressed by self-replication of oligomeric compounds in replication first; by cycles and network in metabolism first. In the broadest sense, life can be seen as an autocatalytic process where an entity catalyses the production of one or more descendant entities.
From another perspective, Metabolism-first privileges function, while replicator-first privileges descent.

The main issues with replicator-first model are the sizeable step required from abiotic compounds to template-based replication (although ribonucleotides conceivably could form in pre-life conditions see \parencite{Powner2009}). Templates encode information in biology, so require a encode/decode mechanism as well as an information code to represent the product. This is a step more complex than simpler duplication. By contrast, the main issue with metabolism-first model concerns the shift from composome inheritance to template-based, and the ability of composomes to fulfill heredity requirement for natural selection.

The origin of life can be seen as the transition from chemistry to biology, and is analogous to our goal of transitioning from simple uninteresting systems, to systems which evolve. However, the usefulness of the similarity is limited: the primary postulates of OOL are not our postulates. Some abiogenesis results fundamentally assume real-world chemistry and
conditions, a constraint that doesn't apply to Alife or artificial OEE, and so is more restrictive than required. Other abiogenesis work such as on properties of autocatalytic sets, or the suitability of the genetic and catalytic properties of RNA for Alife \parencite{Cheng2010}, is broader in applicability.
\end{mdframed}

\paragraph{Living organisms are supremely well suited to their environments, and can adapt to environmental changes}

Adaptation of organisms to their environments occurs in the main on two different time-scales.

Evolution by \gls{naturalselection} acts over a period of generations on populations of individual organisms. Changes are therefore relatively gradual, and many generations can pass before a change such as a beneficial mutation becomes ubiquitous in a population (\eg 300-500 generations for targeted modifications in lactose processing in \emph{E. coli} \parencite{Dekel:2005fk}. In contrast, gene regulatory effects act during the life cycle of a single individual, either during development to affect morphology, or during the adult lifespan in reaction to seasonal or other environmental cues. These regulation-driven changes are not in themselves heritable, but they can be assimilated back into the population by influencing the organisms fitness under natural selection (\eg,\parencite{Baldwin:1896ly,Dennett:2003ve,Paenke:2009xe,Paenke:2007ve}).

Similar effects can be seen by another adaptive mechanism that operates on individuals during their lifespan: learning, where behavioural adaptions can also lead to genetic change (\eg \parencite{Hinton:1987vy}.)

\paragraph{Natural selection, acting on populations, is the primary driver for long-term adaptation}

The year 2009 saw the celebration of the 150\textsuperscript{th} anniversary of the publication of \emph{On the Origin of Species}, the explanation of evolution by natural selection, with extensive coverage in scientific and popular media. The terms are therefore fairly well known to many people, but what exactly does \emph{natural selection} mean? To quote from \parencite{Futuyama:1979tg}, \gls{naturalselection} is the ``differential survival and reproduction of genotypes''.

Let's examine each of the components in this idea in turn:

Differential survival. Living organisms are constantly engaged in an intimate relationship with their environments. Indeed, according to the theory of \emph{autopoiesis} \parencite{Varela:1974qd}, organisms are defined by this engagement: to be alive means maintaining oneself against the surrounding environment. In general the more effectively the organism is able to do this, the more likely it is to survive. However, in practice survival for an individual may be affected by random events. Scholarship winning students can be killed by drunk drivers. Sardines in shoals flash and turn, yet sharks still manage to grab one or two from the shoal effectively at random. Averaged over a population however these chance events balance out; a succession of random trials leads to a skewed distribution of fitness away from the less able.

Reproduction. In this sense, reproduction simply means inheritance. Only those characteristics that can be passed on from one generation to the next are relevant. One implication of this is that the only traits of an organism that matter to natural selection are those that are apparent while the organism can reproduce. Altruism and kin-selection, where an individual acts to increase the fitness of a related individual, are interesting for the light they shed on this implication.

Genotypes. An organism's \gls{genotype} is the heritable information that defines an individual, of which the great majority is encoded in DNA (some \emph{epigenetic} information is inherited through DNA-methylation, maternal protein concentrations and other mechanisms. However, generally DNA remains the primary source.)

How then does natural selection unfold in practice? Although an organism is defined by its genotype, its survival is based not on the raw genotype, but on the expression of the genotype--called the \gls{phenotype}--that participates in the interaction with the environment. There is not necessarily a direct one-to-one mapping between genotype and phenotype; for example, environmental triggers
during development can switch the phenotype in different directions (a phenomenon called \gls{polyphenism}.)

This indirect mapping enables a number of important mechanisms significant to the operation of natural selection: first, changes in the genotype (caused by mutations for example) may build up independent of phenotype changes--the idea of \emph{neutral mutations} \parencite{Ohta:1996vn,Ohta:2002ys,Ohta:1973kx}. Examples from studies of RNA secondary structures (the physical folding of RNA molecules) show that many closely-related RNA sequences can produce the same RNA folding \parencite{Fontana:1993zn}. Adjacent changes often have little effect on structure.

Second, by extension, \parencite{Gavrilets:1997qt} and \parencite{Gravner:2007yd} have shown that in cases involving many gene loci under well-defined conditions there is a path between viable phenotypes that requires only neutral mutations.

Third, behaviours such as learning, rather than purely genetic mechanisms, can influence the form of this \gls{gpmap} in combination with natural selection, as illustrated by the Baldwin effect \parencite{Baldwin:1896ly} and other examples of genetic assimilation \cite{Hinton:1987vy,Siegal:2002qn,Waddington:1942jb}.

Finally, a \gls{grn} provides another mechanism to modify the \gls{gpmap} and hence to guide natural selection.

\paragraph{Novelties often arise from new regulatory connections rather than changes to genes}

The phenotype in living organisms is many orders of magnitude more complex than the genotype, and the methods used during development to build this complexity are many and various.

Cells call upon a complex of regulatory processes to regulate the expression of genes, and hence to control development and morphology (as well as to implement the cell's basic machinery.) The majority of these processes (at current understanding) use proteins to affect the initiation of transcription (the production of RNA from a segment of DNA, the first stage of gene expression); most commonly the presence of a specific protein promotes or inhibits the transcription of a related gene, and without transcription the gene is silenced.

One step further along the protein production chain, editing and splicing of the RNA products of transcription in eukaryotes prior to translation (the production of a protein from mRNA) is also under regulatory control. Many alternative proteins from one transcript can be produced, triggered by environmental or other influencing factors; each alternative protein will have a different effect on cell function. As a result, in biological organisms, the phenotype is not uniquely determined by the genotype, and a genotype contains the potential for multiple different phenotypes under the influence of the environment (a phenomenon known as plasticity).

Patterns of gene expression can also have an effect outside the originating cell, a phenomenon crucial for development. Signalling proteins produced by a cell act as regulators on the machinery of surrounding cells, and epigenetic mechanisms allow signal effects to be long-lived so that a pattern of expressions may be inherited by daughter cells without the continued presence of the original signals. These mechanisms determine the fate of new cells during development: a cell originating in an area bathed in a particular combination of signalling molecules will develop in a specific manner (such as into a skin cell); another cell in another area will receive different signals, and therefore develop in a different way.

The development of an organism from a zygote is thus controlled by a pattern of gene expression under the combined influence of a regulatory mechanism and the environment.

As the regulatory mechanism is constructed from proteins and RNAs encoded in the genotype, and as the genotype is generally under the influence of natural selection, evolution also acts upon gene regulation, and hence upon development. The study of the evolution of the developmental mechanism itself is known as Evolutionary Development, or, more colloquially, EvoDevo.

\parencite{Prudhomme:2007ax} believe that evolutionary novelties more commonly arise from changes or additions of regulatory \emph{connections} than from the development of \emph{new} genes or regulatory elements; that is, from changes to the network topology rather than from additions to the network elements. The underlying implication is that novelties are therefore new compositions of
pre-existing elements, rather than being constructed `\emph{de novo}', and that production of novelties may be relatively rapid. Connection changes may happen quickly; by comparison, new genes may take many generations.

\begin{flushright}
	\emph{According to the strictly structural concept, the genotype is considered as a mosaic of independent molecular blue-prints for the building of individual cellular constituents. In the execution of these plans, however, co-ordination is evidently of absolute survival value. The discovery of regulator and operator genes, and of repressive regulation of the activity of structural genes, reveals that the genotype contains not only a series of blue-prints, but a co-ordinated program of protein synthesis and the means of controlling its execution.}
	\par\cite[p354]{Jacob:1961ys}
\end{flushright}

A network formed by the regulatory interactions between genes and the transcriptional products of those genes (\glspl{tf}) is known as a Gene Regulatory Network, or \gls{grn}.

\paragraph{Modularity is an emergent property of GRNs}
Even a superficial look at a set of randomly sampled insects reveals a striking level of similarity between supposedly distantly related species. Mouthparts, segmented bodies, wings and halteres springing from body segments, antennae on head segments; common patterns abound. The explanation lies in the action of a group of homeotic (or body-patterning) genes, which act in concert to impose a structure on the developing body plan. These regulatory genes, amongst the first patterning genes to be identified and characterised, in fact appear in very similar forms across all animals and hence appear to share a common evolutionary origin, and to be highly conserved \parencite{Shubin:2009vw}. 

As an example of their action, the gene \emph{Ubx}, or \emph{Ultrabithorax}, is involved in development of the \gls{metathorax}, one of the body segments, in \glspl{arthropod} \parencite[pg. 696-697]{Watson:2008fm}. Changes in \emph{Ubx} expression in combination with expression of a second homeotic gene, \emph{Scr}, are responsible for some of the differences in body plan between two arthropod groups--brachiopods, and isopods. In brachiopods, the expression of \emph{Ubx} suppresses \emph{Scr} in the leading thorax segment leading to development there of swimming legs. In isopods however, \emph{Ubx} expression has been lost in that segment, and instead a feeding appendage develops \parencite{Watson:2008fm}.

The morphological patterns that result from changes in expression of the \emph{hox} homeotic genes are textbook examples of modularity caused by regulatory networks. These networks in general appear to take a characteristic form, sometimes called a `medusa' network \parencite{Kauffman:2004zi,Aldana:2007da} where a regulatory head controls the expression of many functional genes. For example, in \gls{drosophila}, the medusa has a head of around 80 genes \parencite{Aldana:2007da}. \Textcite{Davidson:2006wi}, using the well-characterised sea urchin genotype, identifies GRN `kernels' of interconnected and hence very robust regulatory genes that control essential functions such as heart development and the endoderm specification in sea urchins. 

\subsection{Evolution by Natural Selection}\label{evolution-by-natural-selection}

\quote{Evolution is a process that results in heritable changes in a population spread over many generations.}{
	``Sandwalk: strolling with a skeptical biochemist'',
	\url{http://sandwalk.blogspot.co.nz/2012/10/what-is-evolution.html}}

\quote{
	Biological evolution consists of change in the hereditary characteristics of groups of organisms over the course of generations. Groups of organisms, termed populations and species, are formed by the division of ancestral populations or species, and the descendant groups then change independently. Hence, from a long-term perspective, evolution is the descent, with modification, of different lineages from common ancestors.}{``Evolution, Science, and Society: Evolutionary Biology and the National Research Agenda'', Working Draft, 28 September 1998, \url{http://www.zoology.ubc.ca/~otto/evolution/Evolwhite.pdf}}

``We take it as given that biology instantiates ENS'', but that doesn't mean that the algorithm of biology is in fact \gls{ens} \parencite{Watson2012}. Adaptation in biology appears to precede Natural Selection, so adaptation is possible without \gls{ens} \cite{Watson2010}, and other forms of evolution have been proposed in artificial systems (\eg the compositional evolution of \cite{Arthur2009}), and on the boundaries of \gls{ens} in the domain of living systems (\eg composomal inheritance and \gls{hgt}). These variants are examined in the following \nameref{alternatives-to-evolution-by-natural-selection}, but here we concentrate on canonical \gls{ens}.

\cite{Godfrey-Smith2007} examined a number of summaries of \gls{ens} taken from the most influential items in the literature. The purposes of the summaries varied, but have interest for us ``as attempts to capture some core principles of evolutionary theory in a highly concise way.''. Incidentally, as an illustration of the difficulty of definitions, although the usual aim is to ``give conditions that are sufficient ceteris paribus for a certain kind of change occurring.'', \cite{Godfrey-Smith2007} notes that the scope of most summaries is somewhat ambiguous. They can be read as either being discriminatory--``this process is ENS''-- or providing conditions that will result in \gls{ens} when it is assumed that the meaning of \gls{ens} is clear. In other words, these are alternative \emph{constitutive} or \emph{causal} readings; in the example of \cite{Godfrey-Smith2007}, ``becoming pregnant\ldots{}{[}versus{]} being pregnant'':

\begin{compactenum}
\item ``Owing to this struggle for life, any variation, however slight and from whatever cause proceeding, if it be in any degree profitable to an individual of any species, in its infinitely complex relations to other organic beings and to external nature, will tend to the preservation of that individual, and will generally be inherited by its offspring. The offspring, also, will thus have a better chance of surviving, for, of the many individuals of any species which are periodically born, but a small number can survive. I have called this principle, by which each slight variation, if useful, is preserved, by the term of Natural Selection, in order to mark its relation to man's power of selection.'' \cite{Darwin1859}
\item ``if there is a population of entities with multiplication, variation and heredity, and if some of the variations alter the probability of multiplying, then the population will evolve. Further, it will evolve so that the entities come to have adaptations....'' (Maynard-Smith, in \cite{Griesemer2001})
\item ``any entities in nature that have variation, reproduction and heritability may evolve'' \cite{Lewontin:1970mc} and ``1. Different individuals in a population have different morphologies, physiologies, and behaviors (phenotypic variation). 2. Different phenotypes have different rates of survival and reproduction in different environments (differential fitness). 3. There is a correlation between parents and offspring in the contribution of each to future generations (fitness is heritable).'' \cite{Lewontin:1970mc}
\item ``...evolution will occur whenever and wherever three conditions are met: replication, variation (mutation), and differential fitness (competition)'' \parencite[quoting Daniel Dennett]{Ofria2004}
\end{compactenum}

From the study of the summaries, \cite{Godfrey-Smith2007} concludes that the core requirement for \gls{ens} is some ``combination of variation, heredity, and fitness differences'', although he identified a number of differences between the summaries. For example, the most commonly cited summary is \cite{Lewontin:1970mc}, but unusually that formulation states that ``fitness is heritable'' whereas typically phenotypic heredity (as appears in Lewontin's later 1980 summary) is stated as sufficient for a trait to evolve. 

These differences are also discussed in \parencite{Griesemer2001}, in particular with reference to the variations between Darwin's concept of inheritance in \cite{Darwin1859} which includes both heritability (a capacity) and inheritance (a process carrying the capacity); Lewontin, which stresses the heritability while assuming inheritance, and Maynard Smith's multiplication which is actually about inheritance; his heredity is both. \parencite{Griesemer2001}

Quite apart from these differences in interpretation, the major theoretical difficulty in a literal application of \gls{ens} to artificial systems is captured succinctly by \parencite{Griesemer2005}: ``Darwin's theory of evolution by natural selection is restricted in scope. One sense in which it is restricted is that it refers to organisms.'' Organisms are not defined, but the context and scope is clearly biological. This will be discussed further in the following \nameref{alternatives-to-evolution-by-natural-selection}, \labelcref{alternatives-to-evolution-by-natural-selection}.

\subsection{Extensions and alternatives to evolution by natural selection}\label{alternatives-to-evolution-by-natural-selection}

Although \gls{ens} is usually only discussed within the context of modern day biology, as we've seen when examining the definition of \gls{ens} there is nothing exclusively biological about the standard formulations. By abstracting the concepts of variation, selection, and in particular inheritance or heredity, a generalised form of \gls{ens} can be developed that goes beyond the usual biological readings. 

A specific example lies in the transition from non-living to living things.One of the main problems (of several) in extending \gls{ens} to prebiotic entities is that the meaning of the foundational elements--such as variation, selection, heredity, multiplication--are generally couched in biological forms. For example, heredity is often discussed in terms of alleles, or traits. However, there must have been some point at which the prebiotic processes transitioned to \gls{ens}, and it is clear that this transition did not happen abruptly in a population of fully-fledged modern organisms. The pathway to \gls{ens}, the evolution of evolution itself, is one of the main open problems in origins-of-life research, and it involves an extension of those foundational elements back into the prebiotic world.

The example of the transition to life is an example of \emph{extending} \gls{ens}; two further examples are now presented that are \emph{alternatives} to \gls{ens}: DaisyWorld, or regulation without selection, and evolution in an entirely non-living domain--the evolution of technology. 

\cite{Arthur2009} describes a mechanism for the evolution of technology, where evolution is used in the sense of \quote{all objects of some class are related by ties of common descent from the collection of earlier objects.}{\parencite{Arthur2009}}. Evolution in technology occurs by using earlier technologies as building blocks in the composition of new technologies, and these new technologies then become building blocks for use in later technologies, and so on. Arthur calls this ``combinatorial evolution.'' But what is the starting point? How is this regression grounded? Arthur proposes that the capture and harnessing of natural phenomena starts each lineage and provides new raw components for inclusion in later technologies. \Cite{Bourrat2015} comments that distributive evolution (where only the distribution of elements changes, as result of selection or drift) cannot result in novelties: Arthur's answer is that novelty comes from this incorporation of new phenomena from the source, the natural world.

Evolution is related to innovation: in fact, Arthur claims that by understanding the mechanism by which technologies evolve we will understand how innovations arise. In other words, innovations arise as the result of an evolutionary process, rather than de novo from the brain of a designer. Darwinian evolution, or natural selection, is not appropriate for technology. Arthur quotes from Samuel Butler's essay ``Darwin Among the Machines'' to illustrate the impossibility of the slavish adoption of biological models: ``{[}t{]}here is nothing which our infatuated race would desire more than to see a fertile union between two steam engines\ldots{}''.

The first obstacle to a more general scope is the existence of innovations such as the jet engine, laser, railroad locomotive, or QuickSort computer algorithm (to name Arthur's examples.) Innovations seem to appear without obvious parentage; they do not appear to be the result of gradual changes or adaptations to earlier technologies. Arthur's answer is to look inside the innovation and to recognise that each is made up of recognisable components or modules; the key lies in the nature of heredity in technology. Technologies are formed by combining modules of earlier technologies. These groupings start as loose assemblages to meet some new function, but over time become fixed into a standard unit (for example, the change in DNA amplification mechanisms from assemblages of laboratory equipment to standard off-the-shelf products.)

However, even Arthur in his rejection of ``Darininan evolution'', describes a process that still relies on selection, variation and inheritance. This is not the case in our final example, DaisyWorld.

\Cite{LovelockMargulis2011} propose Daisyworld as a example of an alternative to selection for regulation, based on two feedback loops. \cite{Saunders1994} explains how regulation can emerge in DaisyWorld without selection--the planet's temperature is adjusted to meet the conditions for maximum growth of the daisies without the daisies adapting to the planet. ``As a result, regulation, one of the most fundamental and necessary properties of organisms, appears without being selected for. What is more, it appears as a property not of the daisies, on which natural selection may have acted, but of the planet, on which, as Dawkins rightly points out, it could not.'' \parencite{Saunders1994}

The fundamental insight in Daisyworld is that individuals modify environments (that is, niche construction): the daisies adapt the planet (specifically the temperature for maximum growth) to suit themselves, rather than adapting themselves to the planet; and in fact there's little benefit to adaptation by the daisies to the planetary conditions. As \cite{Saunders1994} states, ``the ability to withstand a greater variability is not the result of Darwinian adaptation. On the contrary, it exists because of the absence of Darwinian adaptation.''

\subsection{Evolutionary Algorithms}

The field of \glspl{ea} originated in the exploration of abstract biological evolution, but rapidly diverged into problem-solving and optimization \cite{De-Jong:1993gy,DeJong2006}. The fundamental differences between the biological original and the modern canonical \gls{ea} include:

\begin{compactitem}
\item \Glspl{ea} search through a fixed space, and hence cannot surprise by 'kind', only by 'degree' (\eg \parencite{Nellis2014})
\item The evolutionary process in an \gls{ea} is not itself subject to evolution; it is designed, and a large body of literature exists to guide the implementor in the choice of algorithms to employ.
\item Fitness in an \gls{ea} is measured by an explicit \emph{objective function} whereas in biology fitness \emph{emerges dynamically} through continuous interaction with the environment. ``The difference is that we require a system with the potential for a large degree of intrinsic adaptation for open-ended evolution, rather than a system where the selection of individuals is determined by an externally-defined fitness function'' \parencite{Taylor2001}
\item \Glspl{ea} conduct a series of discrete trials of fitness, rather than a continuous evaluation.
\item Individuals in a \gls{ea} do not interact other than indirectly through a pre-designed selection mechanism.
\item \Glspl{ea} are not dynamical systems unlike the biological origina. Dynamics required for novelty-generation \parencite{Nellis2012}
\item Natural organisms must replicate themselves to pass on genetic information--``final arbiter of fitness'', and interaction with other organisms and with environment \parencite{Ofria2004}
\end{compactitem}

The first two of these differences are significant; \glspl{ea} are not capable of open-ended, or evolutionary, evolution. However, recent research in biology continues to be applied to improve the performance of \glspl{ea} in their core function of optimization:
\begin{compactitem}
	\item Redundancy and degeneracy--\eg \parencite{Whitacre:2010qy}
	\item Novelty--\eg novelty search \parencite{Lehman:2008cr}
	\item EvoEvo, or the evolution of evolution--\eg the remainder of this work.
\end{compactitem}

A summary of some relevant work in the application of \glspl{grn} to \glspl{ea} to improve the robustness and modularity of solutions can be found in \cref{applications-of-grn-in-eas}.

A form of re-unification between biological evolution and artificial evolution has been attempted in works such as \parencite{Paixao2015}, based on \quote{models in theoretical population genetics and in the theory of evolutionary computation}{\parencite{Paixao2015}}. For example: \quote{Some EDAs can be regarded abstractions of evolutionary processes: instead of generating new solutions through variation and then selecting from these, EDAs use a more direct approach to refine the underlying probability distribution. The perspective of updating a probability distribution is similar to the Wright--Fisher model.}{\parencite{Paixao2015}}

\subsection{Alife}\label{alife}
The well-known description of \gls{alife} by \cite{Langton1989} is that it is ``life-as-it-could-be'', rather than ``life-as-we-know-it''. The main conference series in \gls{alife}, also called ``Alife'', uses as a tagline ``Synthesis and simulation of living systems'', which is closely related to the definition of \cite{Bedau:2007ga} (not coincidentally one of the prime movers in the field, and a board member of the conference organizing body, the International Society for Artificial Life): ``an interdisciplinary study of life and life-like processes, whose two most important qualities are that it focuses on the essential rather than the contingent features of living systems and that it attempts to understand living systems by artificially synthesizing simple forms of them.''. 

Interestingly, these later two definitions place the study of living things as a subfield within \gls{alife}, appropriately as many consider life to be the only working example we have of the most interesting ideas in \gls{alife}, such as open-ended, or creative, evolution.

An alternate, thematic, view of \gls{alife} is given by \cite{Aguilar2014}:
\begin{compactitem}
\item Properties of living systems--origins of life, autonomy, self-organization, adaptation (evolution, development, and learning)
\item Life at different scales--Ecology, artificial societies, behaviour, computational biology, artificial chemistries
\item Understanding, uses and descriptions of the living--information, living technology, art and philosophy
\end{compactitem}

Technological imperatives have driven the division of \gls{alife} overall into three largely independent subfields: \emph{hard}, \emph{soft} and \emph{wet} \gls{alife}, where hard \gls{alife} is implemented in physical hardware (made from atoms), soft \gls{alife} in computer software (from bits) and wet \gls{alife} from biological compounds. Soft \gls{alife} has the great advantages of relative cheapness and immediacy, and consequently is the basis for the majority of current research, including this work.

Good summaries of the state of the field can be found in \cite{Aicardi2010} and \cite{Aguilar2014}; \cite{Aguilar2014} also contains a comprehensive history from early (classical Greek) interest in automata, through the publication in 1818 of Mary Shelley's ``Frankenstein; or, The Modern Prometheus'', which revitalized interest in artificial creatures in modern times, to the consensus view of the birth of the modern field of \gls{alife} in 1987 with the first ``Workshop on the Synthesis and Simulation of Living Systems'' in Sante Fe, New Mexico.

\section{Guide to this work}

This work is structured in four parts. The first part contains material general to the entire thesis and establishes the overall research context; the second part moves to theory, specifically the meaning of fidelity and inheritance, and an experimental investigation of a theory-based model; the third part to consideration of how a system based on this model might be implemented in an artificial system, specifically our \gls{achem}, ToyWorld; and the final, fourth, part closes the work with conclusions, a general discussion, and some thoughts on future work.

This first part begins with an introductory chapter to motivate the work and place it in context. The overall impetus for study of inheritance and heredity in artificial systems comes from the age-old dream of self-improving systems, more recently expressed in the research topic of \gls{oee}, as outlined in \cref{motivation}. \Gls{oee} increasingly is seen as an evolutionary, emergent, process and as such we can identify a set of fundamental elements considered either necessary or sufficient for \gls{oee} in artificial systems (\cref{motivation}.) One of those elements is replication, and establishing the means by which an evolutionary replicator can emerge in an artificial system drives the work described in this thesis.

\Gls{oee} is in turn inspired and, in some sense, in competition with the achievements of evolution in living systems. \Cref{life} provides a broad but necessarily shallow overview of relevant ideas from modern biology, to explain this link with \gls{oee} and to give some sense of what might be possible should the goal be reached. Evolution in general and the specific evolutionary mechanism behind the richness of biology, \gls{ens}, are described in \cref{evolution-by-natural-selection} for context. As a second example of evolutionary process that fits within the broad umbrella of evolution in general, compositional evolution is introduced in \cref{alternatives-to-evolution-by-natural-selection}, foreshadowing its importance to discussions of the origins of life and the evolution of technology.

The field of \gls{alife}, introduced in \cref{alife}, is almost synonymous with \gls{oee}; although little in this thesis is specific or restricted to \gls{alife}, the spirit and historical context of the field permeates the work, and so a brief introduction in \cref{alife} seems appropriate. 

Of the wide variety of approaches to \gls{alife}, one in particular, \glspl{achem}, seems most promising for \gls{oee} in \gls{alife}, as seen concretely in the number of relevant works reviewed in \cref{previous-work} specific to replication and replicators in artificial chemistries. The structure follows the recent broad classification proposed by \cite{Zachar2010} which moves from simple multipliers through to informational replicators and finally reproducers. Most existing work can be placed in the earlier categories; very few systems are capable of emergent replicators, and none at all meet the requirements needed for reproducers.

\begin{DRAFT}
The question of why this should be is the driving force behind the next section of the work, in part two. 

In the third part we move to the specifics of \glspl{achem} implementations of an emergent inheritance mechanism.  
\end{DRAFT}

\section{Previous publications}\label{previous-publications}

A version of Reactant and Product Strategies \cref{reactant-and-product-strategies} was published as \cite{Young2015}, and material from \cref{model-validation} in \cite{Young2013}.

ToyWorld, the \gls{achem} from \ref{toyworld}, is available under an GNU GPL v2 open source licence from GitHub \cite{toyworld}.

\section{Contributions}\label{contributions}

\begin{compactenum}
\item First review of inheritance and heredity in artificial chemistries.
\item Model for the emergence of heredity.
\item Demonstration that heredity emerges under a variety of environmental forms.
\item Proof by simulation that \emph{erroneous copying} \parencite{Zachar2010} results in informational replicators.
\item Open-sourced Artificial Chemistry model.
\end{compactenum}

\chapter{Previous work}\label{previous-work}

\epigraph{%
It may appear that the properties one would have to assign to a population of self-reproducing elements in order to obtain Darwinian evolution are of a spectacular simplicity. The elements would only have to: (1) Be self-reproducing and (2) Undergo hereditary changes (mutations) in order to permit evolution by a process based on the survival of the fittest.}%
{\textit{\\Nils Barricelli}\\\textsc{Cited in \cite{Taylor2001}}}

Our focus in this work is on the nature of inheritance and heredity, specifically endogenous inheritance mechanisms that can evolve. We’ve seen in earlier sections that heredity is one of the foundational elements of \gls{ens}, the means by which information from one generation can be leveraged in the next. This form of inheritance, from parent to child, is called vertical inheritance, and the type of entity that participates in and enables vertical inheritance (that is, can form a child) is called a replicator. 

By analogy, it’s easy to envisage another kind of information transfer where information is passed from one entity to another horizontally, without replication or a parent-child relationship. In today’s biology, \gls{hgt} provides one mechanism for this; in the early prebiotic world, the horizontal transfer of information might have occurred through a number of conceptually similar mechanisms (such as auto-catalytic cores) that didn’t involve genes. 

Now, in the transfer from the prebiotic world to the biotic one, it’s clear that the proportion of information held by a predecessor that could be passed on to its successor increased somehow, probably over many generations, from ``none’’ to ``nearly all’’, as seen today; \cite{Vasas2012a} links heritability to the correlation between the parent and child entities. Heredity is therefore likely a matter of degree, rather than being a binary relationship; related or not-related, and that opens up the possibility that a series of gradual changes might over time transform a very poor replicator into a very good one. Of course, one possible process for this transformation might well be \gls{ens}.

This progression is comprehensively explored in \cite{Zachar2010}, extending earlier work by \cite{Szathmary1999,Szathmary:2006ty}: ''The simplest of replicators is the \emph{exact replicator}, which is \emph{non-informational}, and any change made to it causes a change in the phenotype. If a variation can arise in the structure in such a way that it does not change equivalence of the entity, then it is a \emph{variable} replicator, with more than one stable state. If such changes can be passed on to the offspring then the replicator is \emph{informational}. If the non-heritable part is constructed by a developmental process, then the replicator is a \emph{reproducer}.'' \parencite[p.21]{Zachar2010}

Interestingly, in biology at least, the starting point for the development of modern replicators might have began with horizontal inheritance. First, the changes from horizontal inheritance can be heritable in a vertical sense. In organisms with genes, by definition under \gls{hgt} the change becomes part of the target’s genome and hence heritable. In entities without genes, there are forms of entity where the horizontal change can be subsequently inherited vertically. Second, mechanisms for horizontal transfer don’t require replication (by definition). Therefore it’s possible that they can act as a precursor for the development of replication. That is, horizontal inheritance plus selection might be sufficient for replication, rather than replication being required for inheritance.

But what exactly does it mean for something to be a replicator? Is a rock that erodes to form grains of sand a replicator \footnote{In \cite{Bourrat2015} rocks are given as examples of \emph{persistors}, unable to reproduce and subject to only a ``weak'' form of selection for hardness}? Is a set of autocatalytic reactions that splits into two replicating? \Cite{Dawkins1976} was the first to define replicators, including a range from biological genes to non-biological ideas (memes) in the scope of the definition. Many other definitions and formulations followed as various properties or features were examined. Relatively recently, \cite{Zachar2010} saw a need to rexamine the definition primarily to resolve issues of discrimination between entities which are clearly replicators or not replicators, and those which are borderline, and between biological replicators and non-biological or cultural ones. 

%A regenerating/recreating entity can produce at least one entity equivalent to it. It is possible that the original entity immediately decomposes (that is, cannot be the subject of further turns of the cycle), causing sequential replacement, although this is the most simple of regenerating entities. If it can effectively increase the number of entities equivalent to itself, then it is autocatalytic and is a \emph{replicator}.

\Cite{Zachar2010} concludes that a replicator is ``any autocatalytic entity for which there is a selection process defined'', using autocatalysis in the general sense of a process where $X + A\rightarrow 2A + Y$, and where selection has the fairly standard definition of ``a process, acting on a particular population of entities in a particular environment, which sorts entities according to their phenotypes.'' \parencite[p.21]{Zachar2010}

\section{Exact replicators}

Autocatalysis by definition is replication; where the entities are molecules, the autocatalytic reaction $X + A\rightarrow 2A + Y$ replicates the molecule $A$ (\eg \cite{Zachar2010,Lifson1997}). Evolutionary variation though is difficult as the exponential growth of the main autocatalytic product will generally overwhelm the molecules produced by any side reactions unless 1) they are also autocatalytic, and 2) the solution contains the molecules needed to initiate and maintain this alternate autocatalysis cycle.

%GGL/ToyChem \cite{Benko2003,Benko2005}                        	&Atoms/Molecules&&None--at level of reactions\\	
%RBN-World \cite{Faulconbridge2011}                            	&Boolean Networks and Graphs& None--at level of ACS\\

\emph{RBN-World} \parencite{Faulconbridge2011} is a \gls{achem} where the entities take the form of \gls{rbn} \parencite{Kauffman:1969ne}, with the addition of a bonding mechanisms to allow for their composition and decomposition. The resulting form of \gls{rbn} is called a bonding \gls{rbn} or bRBN.  Larger structures are formed by ``bonding'' two independent bRBNs at each bRBNs bonding node. ``All reactions are between two reactants; it is assumed that more complicated reactions can be expressed as a series of two-reactant reactions with intermediate structures.'' The choice of reactants is described as ``Gillespie-like'', and essentially random, uncorrelated in any way with reaction energies or rates \parencite[chap.8]{Faulconbridge2011}.

Each bRBN is a synchronous RBN, made up of a number of nodes, each with an initial state (true/false) assigned randomly and with a input/output matrix assigned randomly. Finally k(=2) inputs are established per node. The bonding method uses ``cycle length as the bonding property and equality as the bonding criterion....bonds only exist between bRBNs that have the same cycle length.'' After initial bond formation the algorithm recalculates cycle lengths, and checks again for equality. This might result then in decomposition (records are kept of composition operations so that the reverse decomposition can be easily done.)

A number of parameters affect the behaviour of the chemistry, and so a series of experiments sampled from the parameter-space, and then used a GA, to search for interesting variants as measured by non-catalysed ``loops'' (ideal measures of auto-catalytic sets and Hypercycles too rare for use as a measure) \parencite[chap.8]{Faulconbridge2011}. 

The development of RBN-World involved many design choices, some essentially adhoc, such as the choice of \gls{rbn}: ``...the choice to use RBNs as the sub-symbolic representation in RBN-World was based on limited information. As a discrete dynamical system that is computationally tractable yet also spans a wide range of behaviours, RBNs met the appropriate criteria. It is not expected that RBNs are the best representation however; others may be more suitable for particular emergent properties.''

The model for \emph{Chemical Evolution by Natural Selection} in \cite{Fernando:2008xy,Fernando:2007pf} is driven by origin-of-life objectives (``the evolution of chemical networks that lead to autonomous systems''), and takes the form of a simulation of laboratory experiments of lipid aggregates (``phase separated ‘individuals’, e.g. liposomes'') in a reactor. The molecules and food molecules (that make up an autocatalytic cycle) share a common representation and underlying chemistry, while replication, unlike the (rare) autocatalytic cycles in \cite{Faulconbridge2011}, is by `` division by externally imposed agitation, i.e. replication rather than self-replication.''. New molecular species (evolutionary variation), comes from chemical ``avalances'' initiated when two existing species are chosen at random, tested to see if a reaction between them is possible by thermodynamics, and then the resulting products seeded in the reactor at low concentrations. These new reactions may be autocatalytic, or the products may complete a food-set for another autocatalytic reaction, or they may enable a side-reaction from an existing autocatalytic one. Introducing these new species into the reactor therefore can trigger the rapid formation of a series of novel products--a chemical avalanche.

\section{Variable replicators}
\begin{NOTES}
Heredity by \cite{MaynardSmith1999} is modular or holistic--if module changed only that module changes in descendants, holistic change part changes whole. Believe it true that unlimited heredity => modular. \cite{Szathmary1999} calls these digital and holistic, and adds phenotypic replicators whereby ‘phenotype or function of one object is translated to the other, without any modular copying effect” (how does this differ from holistic?)

\cite{Hogeweg1998} describes attractor-based heredity (inheritance of state) and storage-based. 

\cite{Vasas2012a} ACS cores are attractor based, DNA/RNA storage based. HGT/LGT--compositional inheritance.
Difficulties with Compositional inheritance in something like GARD where just a correlation between parent and child--response to selection not seen \parencite{Vasas2015}--end up with just one large component (so no selection), no replication as contents not inherited equally, so properties might be quite different from parent. Information fidelity varies widely. Mutations in cycles \parencite{Vasas2012a} generally not heritable as mutant copies generally not functional in autocatalysis. So problem with mutations as source of variation. Alternative to mutations is avalanches--form new cycles from side-products.
But can see heredity in autocatalytic cores (one or more linked autocatalytic loops) as a form of genotype--any molecule in core will produce remaining species in core and periphery \parencite{Vasas2012a}. Core forms an attractor; one core=one attractor, and no evolution possible as no selection. Multiple cores (from inhibition \cite{Vasas2012a})=multiple attractors, but need attractors to be stable for stable selection. Cores are equivalent to one-bit of heritable information, so hard to see as unrestricted heredity as limits to numbers of cores…
\cite{Watson2015} summarizes two forms of inheritance for groups, being either ``migrant pools'', where members disperse horizontally to form new pools, or group fissioning, where the dispersion is vertical. Fissioning, in the view of \cite{Watson2015}, provides for group inheritance whereas migrant pools do not.

%\cite{Fernando:2008xy,Fernando:2007pf}                          &Compositional&Non-template: Lipid aggregates\\
%Lattice Artificial Chemistry \cite{Ono2000,Madina2003}        	&&&Non-template\\
			
\cite{Kauffman1986}
Reflexively Autocatalytic Polymer Networks (RAPN) are evolvable. First, likelihood of such networks higher than expected (Hordijk and Steel) and second, in Vasas2012 putting these networks into compartments (so not well-stirred) then can do directional selection.

GARD \parencite{Segre1998}
Eigen threshold applies--mutation rates (see issue of replication--big differences between parent and child) overwhelm selection \parencite{Vasas2015, Vasas2012, Vasas2012a}

Claim made that GARD is capable of darwinian evolution, but population analysis showed not in response to directional selection (Vasas2010) \parencite{Vasas2015, Vasas2012, Vasas2012a}
GARD does not result in selectable replicating entities--there is no replication as certain highly catalytic molecules determine the properties of the compotype, and these are not inherited equally--instead a child may or may not inherit one of these molecules and so its properties may be similar to or very different from its parent \parencite{Vasas2015, Vasas2012, Vasas2012a}

Differences to RAPN:
\begin{compactitem}
	\item Kinetics of growth--RAPN has ligation, GARD does not. Ligation allows new components to be formed with new properties
	\item Search for adaptations--GARD has fixed catalysis, Kauffman does not--mutant polymers can arise, be incorporated into the set, and influence its fitness
\end{compactitem}

\parencite{Vasas2015, Vasas2012, Vasas2012a}
Based on GARD \parencite{Segre1998}. Can evolution happen when information transfer is non-digital? Specifically where there is a parent-offspring correlation in molecular composition? Compositional inheritance. If inheritance is statistical only then ok; but literature stresses digitally encoded although might just be cognitive bias. Ganti and Eigen showed that distinct, organizationally different alternative autocatalytic networks in same environment might compete and fittest would prevail (\eg autocatalytic networks as units of selection).	Check number of network components (=autocatalytic networks). In GARD, end up with just one big component

%\subsection{Other} % Not capable of OEE
%	
%\cite{Sayama2011} explores the ability of Swarm Chemistry--an integration of Artificial Chemistry with Swarm Robotics--to achieve \gls{oee}. The models are rather non-biological, and interpretation as biology is difficult. One specific difficulty with the results as reported, noted by the author, is that all results were obtained by visual inspection, and that measures need to be developed based on some standard works.
%
%\cite{Dorin:2006fk} demonstrates that an \gls{achem} can support a simple ecology--autotrophs and heterotrophs--loosely based on simplified model of generic terrestrial ecosystem, with interactions between organisms, and between organisms and the abiotic environment. All organisms emerge from an environment consisting of unbound atoms, from a fixed set with given properties. A set of predetermined reactions, most catalysed by an specific enzyme taken from a set of enzyme atoms, models various biologically-inspired types of interaction. For example, photosynthesis is defined as $AO + BO --(chlorophyll & sunlight) \rightarrow AB + 2O$, where chlorophyll is an enzyme.
\end{NOTES}

\section{Informational replicators with shortcut replication mechanism}
\begin{NOTES}
Modular/template heredity has advantages of: mutations hereditary; problems of correct copying \parencite{Eigen1977}

Selection implies limits on fidelity--at least one perfect copy on average at each replication required \parencite{Eigen1977}

\Cite{BanzhafBaumgaertnerBeslonEtAl2016} where the replication mechanism is directly implemented by the experimenter rather than being an emergent property. As the mechanism is external to the entities it is not under selection; shortcut replicators are not, by our definition, open-ended.

%ZChem \cite{Tominaga2004}                                     	&&Not self-referential--recombination rules are defined separately from objects\\
%Substrate-Catalyst-Link (SCL) \cite{Varela:1974qd,Suzuki2008} 	&&Not self-referential--recombination rules are defined separately from objects\\
%Squirm3 \cite{Hutton2002,Hutton2007,Lucht2012}                	&Atoms/Molecules&Replication by predefined reaction rules (not embedded)&\\

Squirm3 \cite{Hutton2007,Hutton2002}:
Artificial system capable of life-like \gls{oee} (creativity).
Based on hypothesis (materiality, interactions, embedding) of \textcite{Taylor2001}, better expressed in \textcite[p.341]{Hutton2002}; membrane to allow individuals to benefit from innovations by protecting internal reactions from others.
\Gls{achem} from \textcite{Hutton2002} used to construct all elements in world--material and embedded.
Atoms in \gls{achem} of different types and states; reaction rules; otherwise no energy modelling; only physics modelling is the concept of location (either integer-coordinates or real number-coordinates) and impossibility of colocation. Floods are used to recycle raw materials.
Individuals (each bounded by a membrane) with the capability for division and mutation. Raw materials (atoms) are only required for division.
Interactions between individuals are limited to effects on shared environment (niche construction without direct interaction), so one element of hypothesis untested; restrictions on open-endedness: evolution of new enzymes unobserved as extremely unlikely, and genotype-phenotype mapping hard-coded (unevolvable)
Enzymes can act as catalysts so G affects P; but enzyme evolution too improbable for OEE
2D grid of squares (lattice), spring force for membrane
Enzymes can now affect all reactions except enzyme production; in practice too slow
Production rules hardcoded into AChem
Only with raw materials in environment, niche construction through adaptation to availability of raw materials
AChem hand-built with reactions instead of enzymes
Prespecified reactions \parencite[p.4]{Hutton2007}- also see description in \cite[p.49]{Faulconbridge2011} where this set of reaction rules is presented as an example of an explicit set of rules. As these reaction rules that drive replication and hence inheritance are external to the model, the inheritance mechanism in Squirm3 lacks the property of self-reference.

\parencite{Lucht2012}

Challenge to community--"to develop a system in which, starting with a soup of free atoms and a simple ``bootstrap'' chemistry, a cell-like creature similar to the one in H-41 evolves."
Based on Hutton2007 Squirm3 chemistry, using Hutton's floods 
Squirm3--fixed molecule types, and pre-defined reactions for replication and gene-sequence transcription, and so although capable of interesting behaviour is not capable of unlimited extension
Added reaction types to address Squirm3's ``global-extinction problem and showing how quasi-universal enzymes can evolve''

\end{NOTES}

\section{Informational replicators or self-replicators}
\begin{NOTES}
Replication in these systems emerges from the level-0 rules without being directly specified by the experimenter or designer. However, even here most systems still shortcut this by providing a seed or universal ancestor (\eg \cite{Ofria2004}) that contains a working module for replication that can be then modified (for good or ill) in each subsequent generation.
%
%\begin{sidewaystable}
%	\begin{center}
%		\scriptsize
%		\caption{Previous work}
%		\label{tb:previous-work}
%		\begin{tabular}{@{}llll@{}}
%			\hline\noalign{\smallskip}
%			\Gls{achem}                                                     & Type 	& Notes\\ 
%			\\ \noalign{\smallskip}
%			\hline
%			\noalign{\smallskip}
%			Avida \cite{Ofria2004}                                  		&Assembler Automata&	& Embedded copy algorithm\\
%			Tierra \cite{Ray1991}                                  			&Assembler Automata&	& Embedded copy algorithm\\
%			\cite{Nellis2012}\cite{Nellis2014}								&Boolean Networks and Graphs&&\\
%			StringMol \cite{Hickinbotham2012}                             	&Rewriting or String-based&&\\
%			\cite{Fontana1992}												&Rewriting or String-based&&2-parent function\\
%			\cite{Dittrich1998}												&Rewriting or String-based&&2-parent function\\
%\hline
%			\cite{Nowostawski2005}											&&&\\		
%
%			\cite{Fenizio2000}\cite{Fenizio2001}							&Rewriting or String-based&&\\			
%			NAC \cite{Suzuki2006}                                         	&&&\\	
%			\cite{Gardiner2007}                                             &&&\\
%\hline			
%			\cite{Kauffman1986}												&Compositional&&\\
%			Turing															&Rewriting 	&&Yes\\
%			Von Neumann														&&&\\
%			Waddington														&Biology&&\\
%			\hline
%		\end{tabular}
%	\end{center}
%	\caption{Achems with evolutionary replicators.}
%\end{sidewaystable}

\subsection{String-manipulation systems}
\emph{AlChemy} \cite{Fontana1992}

A new object in Fontana's Algorithmic Chemistry, or AlChemy, is defined as the interaction expression, $h$, of two randomly chosen objects $f$ and $g$, if, and only if, the interaction expression contains at least one variable and one primitive operator, and is shorter than some maximum length \parencite[p.173--p.180]{Fontana1992}. New objects in AlChemy are therefore the children of two parents.

How then is the interaction expression $(('f)('g))$ between $f$ and $g$ evaluated to produce $h$? AlChemy is a form of pure LISP (with some ``minor idiosyncrasies''), based on toyLISP, with six primitive operators defined in \cite[p.205]{Fontana1992}. The interaction expression is defined in \cite[Definition A.9, p.204]{Fontana1992} as $V[(('f)('g)),()] = (V[f,(a\leftarrow g)])$, using the notation $V[e,L]=v$ to mean the expression $e$ with the ``association list'' $L$ (a list of value assignments between atoms and expressions) evaluates to $v$. The result $h$ is described as $f(g)$ and the process as $f+g \rightarrow (('f)('g)) \rightarrow h + f + g$.

Clearly reproduction in AlChemy is self-referential--the process to construct a child object is defined in the code of the parent objects. Unfortunately, inheritance doesn't follow straightforwardly as the reproduction process is unique in two important ways. First, each new object has two parents, rather than one, as is more common. Producing new objects as some function of the two parents in turn means that the relationship between parents and child is not a straightforward mutation or other syntactic difference, but rather a complex functional relationship. What this means for the relationship between the parent's fitness and the child's fitness is not obvious. It seems that the fitness differences in AlChemy might be more extreme than in other systems where parent and child are syntactically similar.

\parencite{Fenizio2000}:

Original AlChemy reactions of form $A+B\rightarrow C$ where $C$ replaces an existing element.

This system generates $A+B\rightarrow C_1+C_2...C_n$ where $C$ is a multiset of size $n$. Done by modifying the original K rule to detach x2 and eliminate both original elements (like reactants in chemistry)

Uses combinators rather than lambdas

To prevent from stopping (out of elements) added modification where randomly add/remove some elements

Combinator first combines (appends) elements, each element other than first bracketed. Then each 1-term combinator applied to string, where it makes specific changes \eg K x1x2s0-\textgreater{}x1s0 (s0 is remaining substring, may be null). Apply until no further reductions possible (that is, in normal form). Two combinators are equivalent if can be reduced to same combinator (and previously noted that order is not important--same results regardless of order).

Free pool of atoms for conservation of ``mass''

\parencite{Fenizio2001}:

Experiment to show spontaneous formation of autopoietic cells, with a focus on ``identity as an entity separated from its environment'', that is, membrane formation. Graph used to model spatial structures: ``an artificial chemistry (AC) is embedded in a graph, with each molecule being a vertex of the graph and possible interactions being allowed only along the edges of the graph''. Molecules are composed of atoms taken from a 

``Molecules are built from a substrate of elements called atoms. There are seven types of atoms ($I, K, W, R, B, C, S$), each with a different function. The total number of atoms in the reactor is kept constant during a run. Free atoms (not bounded in molecules) are separately stored and form a global pool.''

As the rules for the combinations of two molecules are predetermined (the reaction mechanisms are described in \cite{Fenizio2000}), this model is not by our definition open-ended.

\subsection{Automata}

\emph{Coreworld} \parencite{Rasmussen1990}, inspired by the computer game core war, set segments of simplified assembly code into competition in core memory. The assembly command to copy values from one memory location to another could spontaneously introduce errors into the copying, and hence could introduce evolutionary variation. However, as reviewed by \cite{Ofria2004}, the system ``collapsed into a non-living state'' perhaps as organisms could copy over each other in the shared system memory \parencite{Ofria2004}.

\emph{Tierra} \parencite{Ray1991}

In Ray's words, ``...this approach involves engineering over the early history of life to design complex evolvable organisms, and then attempting to create conditions that will set off a spontaneous evolutionary process of increasing diversity and complexity of organisms''\parencite{Taylor2001}. The problem with `engineering over' is we don't understand the natural examples well enough to engineer them \parencite{Taylor2001}

Mutations are introduced during replication by randomly flipping bits during the copy operation (at a given rate of generally between 1 bit flip per 1,000 and 2,500 instructions copied). This rate is set by the experimenter, and is not evolvable. Mutations can also be introduced by the copy algorithm itself however; as it is an algorithm defined in the organism in standard Tierra instructions (and hence fulled embedded), mutations in the algorithm during a copy will be inherited by the child. The initial copy algorithm is part of the 80-instruction ancestral creature documented in \cite[app.C]{Ray1991}.

Emergence claimed in the three forms of \cite{Cariani1991}.

Tierra was the starting point for \cite{Taylor2001, Taylor:1999sc} to explore the creation of \gls{alife}, by adding cell regulation, parallel processes and energy modelling \cite[p.4]{Taylor:1999sc}.

Seed (proto-DNA) must itself be an indefinite heredity replicator {[}assumes that this is minimal starting point, rather than that this itself may evolve{]} \parencite{Taylor2001}
Assume that early stages see A+B implicitly encoded in the environment, essentially as simpler than explicit mechanism, but little justification given beyond ``At the early stages of an evolutionary process, however, we would not expect there to be mechanisms for explicitly decoding the proto-DNA\ldots{}'' \parencite{Taylor2001}

Phenotype fundamentally ``involves interaction with the environment (and that this is the essential distinction between the notions of phenotype and genotype--the latter being an informational concept)'' \parencite{Taylor2001}

Tierra has been the testbed for a number of other works. For example, \cite{SugiuraSuzukiShioseEtAl2003} converted Tierra into a string manipulation systems, introducing a set of 140 regular-expression based rewriting rules where each rule encoded one or more of the original 32 Tierran instructions. The initial rewriting ruleset was manually generated by the experimenters, although details are unclear. Unlike in Tierra where the instruction set is fixed during a run, the rewriting rule set for each organism itself could evolve through a separate genetic algorithm. This algorithm removed the least applied rules and inserted the same number of new rules generated by mutating (through duplication, removal and addition of operations) a selection of the most applied rules. Although results support the claim that the ruleset as well as the genome evolves, the use of a separate genetic algorithm for ruleset evolution artificially separates the ruleset from the genome--the feedback loop from genome back to ruleset is broken.

In Ray's words, ``...this approach involves engineering over the early history of life to design complex evolvable organisms, and then attempting to create conditions that will set off a spontaneous evolutionary process of increasing diversity and complexity of organisms''\parencite{Taylor2001}. The problem with `engineering over' is we don't understand the natural examples well enough to engineer them \parencite{Taylor2001}

Mutations are introduced during replication by randomly flipping bits during the copy operation (at a given rate of generally between 1 bit flip per 1,000 and 2,500 instructions copied). This rate is set by the experimenter, and is not evolvable. Mutations can also be introduced by the copy algorithm itself however; as it is an algorithm defined in the organism in standard Tierra instructions (and hence fulled embedded), mutations in the algorithm during a copy will be inherited by the child. The initial copy algorithm is part of the 80-instruction ancestral creature documented in \cite[app.C]{Ray1991}.

Emergence claimed in the three forms of \cite{Cariani1991}.

\emph{Amoeba} \parencite{Pargellis2001}

\emph{Avida} \parencite{Ofria2004}
``An approach to studying evolution...''

Avida summer of 1993--based on Tierra wth better metering and measuring, and parallel code execution.

Phenotypes--``The primary mode of environmental interaction is by inputting numbers from the environment, performing computations on those numbers, and outputting the results. The organisms receive a benefit for performing specific computations associated with resources''

``In principle, the only assumption made about these self-replicating automata in the core Avida software is that their initial state can be described by a string of symbols (their genome) and that they autonomously produce offspring organisms. However, in practice our work has focused on automata with a simple von Neumann architecture that operate on an assembly-like language inspired by the Tierra system.''
Instruction, read, write, and flow control heads for relative rather than absolute addressing--bit like a Turing tape machine. Many instructions grouped into instruction sets. Default set has 26 instructions, and by definition every program is valid.

New organisms are created asexually by the parent first allocating memory for a child. The parent's read-head is then placed at the beginning of its code, write-head placed at the start of the newly allocated memory and successive h-copy instructions copy the instruction from the read-head to the write-head and advance both. Either once all instructions have been copied (or perhaps before) h-divide splits the child from the parent (all instructions between read-head and write-head go to the child) and starts both executing in a clean state. Variation is introduced through mutations which can be introduced through either h-copy (the write-head writes a random instruction rather than the instruction at the read-head) or in h-divide (a single random instruction may be deleted or added from the child code). Both forms of mutation happen with a fixed probability set by the inventor: COPY\_MUT\_PROB, INS\_MUT\_PROB, and DEL\_MUT\_PROB for h-copy, and DIVIDE\_INS\_PROB, DIVIDE\_DEL\_PROB for h-divide. However, there is a second, evolvable source of mutations during replication--the replication process itself is embedded in the organism, as a set of instructions, and so changes to this algorithm during the copy will persist in the child. The self-replication algorithm is initially defined in the ancestral organism used to seed a run, and as documented in \cite[A1.3]{Ofria2004} consists of 15 instructions.

``The quest to halt adaptation is only one example of a special feature in Avida; many more have been explored, and are continuously being added to the source code. The most successful features are all fully described in the documentation that comes with the software.''

All very configurable, and complicated, but why? What rationale behind choices? More of a testbed for experiments, \eg `` in one experiment we wanted to study a population that could not adapt, but that would nevertheless accumulate deleterious or neutral mutations through drift''

\cite{Dittrich1998}:
A simulation approach towards ``dynamic phenomena, especially on the emergence of prebiotic evolution'', based on an artificial chemistry.

Introduction of \textless{}\emph{S},\emph{R},\emph{A}\textgreater{} classification scheme for artificial chemistry, elaborated in \parencite{Dittrich:2001zr}, where in this work \emph{S} are `` binary strings with a constant length of 32 bits'', \emph{R} are of the form $s1+s2 \rightarrow s3$, and \emph{A} ''simulates a well-stirred tank reactor with mass-action kinetics, which assures that the probability of a collision is proportional to the product of the concentration of the colliding objects'' (based on earlier work by Fontana and Kauffman.)

A=``1. Select two objects s1,s2 from the soup randomly, without removing them. 2. If there exists a reaction s1 + s2 to s3 and the filter condition f (s1,s2,s3) holds, replace a randomly selected object of the soup by s3.'', s1 and s2 are not consumed, rather they act as catalysts. Chosen as this shown capable of hypercyclic organisation

Asn automata reaction with a set of operations (six common logic operations, \eg OR, and nine computational instructions), represented as 4-bit sequences, to generate s3 from s1, s2. Automata is a deterministic FSA, running s1 on s2 to produce s3. As Dittrich observes ``The first noticeable property is that the structure of the product s3 is similar to its 'parents' s1; s2. This indicates that there is a correlation between s1, s2, and s3 that is a prerequisite for evolution.''

Passive self-replicators ($s1 + s2 \rightarrow s2$) are relatively common (approx. 30\% of randomly generated strings), while active self-replicators ($s1 + s2 \rightarrow s1$) are very rare (around 0.004\%).

\subsection{Other}
\emph{StringMol} \parencite{Hickinbotham2011}


\emph{GraphMol} \parencite{Nellis2012, Nellis2014} 

``Our aim is to improve novelty-generation algorithms by making their biological models richer''

Computational novelty through embodiment. Comparing StringMol and GraphMol
Novelty-generation as goal/theme for meta-evolution. No measure for novelty--not even sure is possible. But informal definition that says more novelty as result of more embodiment (this seems circular?) p87 Embodiment as mechanism. 

Operates (like StringMol) at level of proteins/enzymes \eg replicases, DNA, genotypes, template copying.

Design is graph based. ``The world defined by GraphMol contains chemicals (represented as graphs) that bind to each other via multiple binding sites, and then run simple computer programs (encoded in the graphs) that modify the binding of these chemicals.''. Why? No explicit rationale presented. Presumably StringMol starting point meant programs, copying, then graphs? 

States that binding model needs to be rich--empirical evidence presented (StringMol) only
Runtimes in weeks to months.

Template copying refers to process of copying genotype from one generation to the next (imperfect digital copying as opposed to analog or compositional copying).

Mechanism of evolution must be itself evolvable; functions such as template copying must be embodied mechanisms in the world--so can be affected and evolved.
Individuals and environment interact to give new ways of producing new individuals.
Stringmol and Graphmol have embodied template copying, done in different ways. Different computational models result in different properties--``Stringmol exhibits macro-mutation and two chemical copying; GraphMol exhibits two types of quasispecies, cooperative and parasitic. These two systems use the same domain (emergent evolution) and metamodel (machines copying strings), but different computational models.''

%\begin{verbatim}
%i := start(string B)
%while i not at-end(string B) do
%	string A(i) := char-copy(string B(i))
%	i := next(i)
%\end{verbatim}

\begin{algorithm}[ht]
$i=start(\text{string B})$\;
\While{$\text{i} not at-end(\text{string B})$}{
	$\text{string A(i)} \leftarrow char-copy(\text(string B(i)))$\;
    $\text{i} \leftarrow next\text{i}$\;
}
\caption{Algorithm for template copying, taken from \cite{Nellis2014}, used in both StringMol and GraphMol}
\end{algorithm}

Each of these four functions--\emph{start}, \emph{at-end}, \emph{char-copy} and \emph{next}--can either be ``crisp'' (\ie perfect) or embodied (variable, the subject of evolution). Replicases are elements in the population that can copy themselves using this algorithm.

Copying is a phenomenon, expressed through mechanisms at different levels of the AChem. Explored through embodied copying mechanism built in GraphMol, with antecedent in StringMol \parencite{Hickinbotham2011}
StringMol includes an embodied start and at-end, crisp next, and stochastic char-copy. 

GraphMol has embodied start, at-end and next, with crisp char-copy. At-end uses Smith-Waterman matching algorithm, which opens ability for evolution to modify the function of at-end \parencite[p.143]{Nellis2012}. 
\end{NOTES}

\section{Discussion}
Although the advantages of a distinction between genome and phenome are discussed by many, including \parencite[section 7.2.3]{Taylor1999} and indirectly \cite{VonNeumann1966}; there is no inherent dependency on this in \gls{ens}. Early evolution may have involved the inheritance of complete portions, or components, of the phenome before the advent of a distinct genome, while research into \gls{hgt} (\eg \cite{Ochman2000,Pace:2008vi,Ragan2009}) has shown that not only was component transfer between species a major driver of early evolution, but a horizontal component-based mechanism continues to exist even in many of today's organisms that have a genome built from DNA. 

So in discussing inheritance we can already distinguish between two forms--holistic and digital, based on the absence or presence of a genome (respectively)--and direction, either horizontal or vertical, where horizontal inheritance does not involve reproduction or replication (and so can cross between species), while vertical inheritance does (and cannot). Typically we refer to holistic inheritance as compositional inheritance, digital horizontal inheritance as \gls{hgt},  while digital vertical inheritance is the mechanism usually assumed when discussing \gls{ens}.

\begin{NOTES}
The EvoEvo project \footnote{\url{http://evoevo.liris.cnrs.fr/about-evoevo-project/})} an Information and Communication Technologies initiative funded by the European Commission, begins at a higher level biological starting point (genotype-phenotype mappings). The project presupposes microbial evolution, ``at the level of genomes, biological networks and populations'', with a focus on four specific properties of a genotype-phenotype mapping--Variability, Robustness, Evolvability and Open-endedness. Later work is planned to remove the biological specificity to provide a framework for applying EvoEvo to ICT problems. Along with development of a model founded on the ``genotype-to-phenotype mapping and the fitness landscape'', the project states that make use of \emph{Aevol} \parencite{Knibbe:2006vn,Knibbe:2007kx} to model developmental processes in microorganisms.

More generally, it is clear that most works lack an overall theoretical background. This observation has been made many times from the earliest days of \gls{alife}--``simulations that are dependent on ad hoc and special-purpose rules and constraints for their mimicry cannot be used to support theories of life''  \parencite{Pattee1988}--through to relevantly recent times: ``This weakness is not specific to Tierra, but is shared by most, if not all, of the other Tierra-like systems which have emerged over the last decade\ldots{}'' \parencite{Taylor2001}
\end{NOTES}

\chapter{Methods}\label{methods}

The field of artificial life is synonymous with simulation \parencite[chap.2]{Aicardi2010}. In other forms of science however practitioners make use of a number of other tools, including experiments and mathematical models. Each method is well suited to some types of questions, and inappropriate for others. Is the presumption of simulation justified for our research questions?

\section{Research questions}\label{research-questions}

\vspace{0.3cm}
\begin{minipage}[l]{0.95\textwidth}
	\begin{enumerate}[label=RQ\arabic*:]
		\item Can evolution act on the inheritance mechanism to tune it for varying environmental conditions?
		\item Does inheritance still emerge from variation when the fitness-environment relationship is not fixed?
		\item Is there a plausible implementation of an erroneous copy mechanism, that is compatible with what we know is needed for OEE, in a software system?
	\end{enumerate}
\end{minipage}
\vspace{0.3cm}

\section{Experiments}\label{experiments}

In the biological sciences, experiments are clearly a source of empirical data (that is, derived from the subject of investigation.) This is not so clear in artificial systems as our subject is instead a program; a model or simulation. Whether this remains a source of empirical data rather depends on your interpretation of the epistimological meaning of a simulation or model, as discussed in the next subsection.

\section{Models, and Simulations}\label{models}

\quote{It is seldom the case in biology that a model is derived deductively from a more fundamental quantitative theory, with the possible exception of population genetics which has its foundations in evolutionary theory.}{\parencite{Krakauer2011}}

Models can be ``useful stop-gaps'' towards a theory, by providing a testable body of data for experiments and predictions \parencite{Krakauer2011}, and may be constructed either bottom-up or top-down, increasing in specificity by the successive application of constraints \parencite{Krakauer2011}, and fall into two main groups, although there are many types and forms (for example, eleven types in ecology according to \parencite{Jorgensen2008}):

Mathematical models, based on reduction, abstraction and simplifying assumptions (\eg Fisher's famous equation describing the changes in allele distribution under selection assumes independent genes--although extending this to realistic cases remains an open problem \parencite{Schuster2011}). Emergence and dynamic behaviours are important, and yet they are hard to capture with mathematical models relying on reduction \parencite{Ferrer:2008hv}

Simulations by contrast are holistic and bottom-up, and encompass variability so that the diversity of the results is closer to that seen in real systems \parencite{Ferrer:2008hv}. They have a unique ability to explore systems encompassing emergence and self-organization. Biology, and by plausible extension, biologically-based systems, stand alone in the pervasiveness of emergence \parencite{Bersini:2006ve}, and the interconnection of levels of analysis, \eg behaviour can influence gene expression, and genes can affect behaviour \parencite{Krakauer2011}.

\section{The epistemological nature of simulations}\label{the-epistemological-nature-of-simulations}

Simulations seem to fall somewhere in between thought experiments or abstract models, and experiments. They are also relatively novel; common use has only come with increased access to digital computers. Consequently the nature of simulation--what can be claimed as a result of simulation, and what role may be played legitimately by simulation in scientific discovery--is a hot topic for philosophers of science. As might not be unexpected, two opposing positions have been commonly taken, plus a synthesis that claims the middle ground.

\emph{Simulations are only programs}

That is, a computational means to solve analytically intractable equations \parencite[31]{Winsberg2010}, ``...a high-speed generator of the consequences that some theory assigns various antecedent conditions'' \parencite[quoting from Dennett]{Eldridge}, producing nothing new (just consequences of what is ``fed in''\parencite{DiPaolo2000}). In this sense, simulations are not empirical.

In this view simulations are aimed at answering specific questions, or analysing particular scenarios. The more accurate the simulation however, and hence the more valuable the results, the harder it is to generalize to other cases. It is hard to understand the behaviour of complicated simulations, and the causes of particular behaviours of interest may be unclear if there are many variables in play. For this reason \parencite{MaynardSmith1974} prefers the use of simple models, designed to illuminate the ``causes of differences of behaviour between different species or systems'' rather than ``assertions which are true of all systems or of all species.''

\emph{Simulations are themselves an instance of the thing}

That is, the thing is not a shadow but the object. The Animats are actually alive, and therefore instances of biology.
\footnote{And this way leads us to the claims of Strong Alife--the simulation is actually alive.}
The simulation is a stand-in for the real world, and you can perform experiments on it as would any other system \parencite[31]{Winsberg2010}. Simulations certainly have elements of uncertainty and error, like experiments. As \parencite{Adami2002} says, describing Avida, \quote{These organisms, because they are defined by the sequence of instructions that constitute their genome, are not simulated. They are physically present in the computer's memory and live there. The world to which these creatures adapt, on the other hand, is simulated\ldots}{\parencite{Adami2002}}

\emph{Simulations are model builders}

\parencite[31]{Winsberg2010} or an ``Opaque Thought Experiment" \parencite{DiPaolo2000}. A common view, among others Dowling 1999, 264: simulation is like theory as about ``manipulating equations'' and ``developing ideas'' but like experiments as ``fiddling with machines'', ``trying ideas out'', ``watching to see what happens.'' 

In this view, simulation is a form of Kuhn's theory articulation or ``model building''--making principles apply to local, concrete systems in the real world: \quote{Simulation is a process of knowledge creation.}{\parencite[6]{Winsberg2010}} Following this third way, simulations might be seen as a source of new hypotheses \parencite{Eldridge}. Similarly, Taylor as summarized in \parencite{Webb2009}, argues for ``pure exploration'' or ``exploratory tools'' that do not need justification, and that may be used to generate ``new questions to ask, new terms to employ, or different models to construct''.

\section{Approach}
\begin{NOTES}

``With this in mind, the strategy of endogenising can be understood has explaining variables which have previously been taken for granted in a model (such as reproduction and inheritance), by reference to other, more fundamental variables present in the model.'' \parencite[p.129]{Bourrat2015}

\end{NOTES}
