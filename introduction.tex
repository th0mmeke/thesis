\chapter{Introduction}

Evolutionary systems are commonly described in terms of three foundational elements, usually some form of variation, selection and heredity\footnote{Other related formalisms exist, as discussed in  \cref{evolution-by-natural-selection}; however, none alter these elements fundamentally.}. Selection is the mechanism by which possibilities are pruned, and focus is maintained. Selection guides evolution by directing the search into promising areas, acting upon the phenome, or the form developed from a genome under the influence of the environment. However, it is not a generator of new ideas. Novelty instead is the outcome of the second element, variation. Variation extends the search into different areas, and creates new alternatives for selection to evaluate. The final element, inheritance, elevates evolution beyond random search. Instead of starting afresh at each generation, inheritance causes the search to be cumulative, with gains preserved. Variation and inheritance together are the source of new forms; each variation is a modification of the previous generation, forming a spreading tree of related entities when viewed over time. Unlike selection, variation and inheritance are processes that act upon the genome directly.

An open-ended evolutionary system, capable of ongoing evolution without practical limit, needs these components to be themselves subject to evolution, change and adaptation\footnote{This relates this work to evolvability; see for example \textcite{Pigliucci2008,Wagner:1996kc,Wagner:2008mi}.}. A system where variation, selection and heredity emerge endogenously from lower-level elements appears to be a promising approach to open-ended evolution in artificial systems. After all, this is the approach taken by life itself.

However, creating the conditions under which evolution emerges endogenously has proved to be extremely difficult in artificial systems, and remains an open problem\footnote{See recent review in \cite{BanzhafBaumgaertnerBeslonEtAl2016}}. Instead of directly addressing this broader problem, therefore, our focus is on only one of the necessary elements for \gls{oe}, the mechanism for heredity within artificial evolutionary systems.

In this work we explore two related aspects of an endogenous mechanism for heredity:

\begin{enumerate}
\item In what way does selective pressure drive changes in heredity in a population of evolving replicators?
\item Can variable replicators emerge from a molecular artificial chemistry?
\end{enumerate}

\section{Context - the emergence of biological replicators}\label{context}

Biological evolution has produced ecosystems of astonishing variety and range, occupying essentially every viable niche on, above, and within the Earth from a common origin in the prebiotic world many millions of years ago. This has been far more than a working out of a single theme; instead a hugely impressive radiation of form and function has left that original ancestor far behind. The only connection that remains is the unbroken lineage of genes that links that earliest ancestor to every descendent organism alive today.

The origin of life was almost certainly contingent, and there is an absence of evidence from early stages \parencite{Pross2013}. There are many possible pathways, and unless some record remains somewhere (either geological or phylogenetic), the actual path is essentially lost to history.

However, a consensus is forming that early life began with chemoautotrophs fuelled by energy from inorganic redox couples and biomass from CO\textsubscript{2}, and that innovations in carbon-fixation created the main branches in the tree-of-life \parencite{Braakman2012}. 

The initiation of selection is marked by the advent of the \gls{ida}, probably from an RNA world, followed substantially later by the \gls{luca} \parencite{Yarus2011}. It is important to note for clarity that \gls{luca} was almost certainly not a single entity or even species, but is rather a construct of evolutionary genetics because of the likely predominance of \gls{hgt} in archaic biology \parencite{Doolittle2007}. Under \gls{hgt}, also known as Lateral Gene Transfer, genetic material is incorporated into an organism's genome by methods other than by reproduction along the vertical line of descent.

\Gls{hgt} is thought to have been so common in early life that there was no single common ancestor; instead genes from multiple lineages intermixed during this early stage into all lineages today \parencite{Ragan2009}. The starting point for the development of modern replicators might therefore have begun with horizontal inheritance, although the changes can then be heritable in a vertical sense: in organisms with genes, by definition under \gls{hgt} the change becomes part of the target’s genome and hence heritable. In entities without genes, there are forms where the horizontal change can be subsequently inherited vertically\footnote{Mechanisms for horizontal transfer don’t require replication (by definition). Therefore it’s possible that they can act as a precursor for the development of replication. That is, horizontal inheritance plus selection might be sufficient for replication, rather than replication being required for inheritance.}. 

Although the advantages of a distinction between genome and phenome are discussed by many, including \parencite[section 7.2.3]{Taylor1999} and indirectly \textcite{VonNeumann1966}; there is no inherent dependency on this in \gls{ens}. Early evolution may have involved the inheritance of complete portions, or components, of the phenome before the advent of a distinct genome, while research into \gls{hgt} (\eg \textcite{Ochman2000,Pace:2008vi,Ragan2009}) has shown that not only was component transfer between species a major driver of early evolution, but a horizontal component-based mechanism continues to exist even in many of today's organisms that have a genome built from DNA. 

Two alternative models exist for the step from the prebiotic world  to \gls{ida} (\cref{major-stages-early-life}): replication- or genes- or RNA-first, and metabolism- or protein-first. Both metabolism and replication were almost certainly required for \gls{ida}, however. Self-replicating RNA enzymes are described in \textcite{Lincoln2009}, forming the basis of a selective system (also see \textcite{Cheng2010,Powner2009} for formation of RNA in prebiotic conditions). 

Some elements of \gls{ida}  are thought to still be with us in lineages of informational (for protein synthesis and RNA transcription) and operational genes (for some standard cellular processes) \parencite{Ragan2009}, for example the ribosome and ribonuclease P (RNase P) \parencite{Wilson2009}. The next major transition was to the protein world, although predominance of RNA transcripts leads to suggestions that it should more accurately be called the RNA-Protein world \parencite{Altman2013}. 

A self-sustaining autocatalytic network\footnote{Perhaps in the form of a \gls{raf} set, a ``set of molecules and reactions which is collectively autocatalytic in the sense that all molecules help in producing each other (through mutual catalysis, and supported by a food set)'' \parencite{Hordijk2011}.} is generally considered essential \parencite{Pross2013}, but not sufficient \parencite{Hordijk2011}. Both competing models---replication-first and metabolism-first---build on this. In the case of replication-first, through autocatalysis as expressed by self-replication of oligomeric compounds; in metabolism-first, by cycles and networks. From another perspective, metabolism-first privileges function, while replication-first privileges descent.

The main difficulty with the replication-first model concerns the sizeable step required from abiotic compounds to template-based, or information-based, replication (although ribonucleotides conceivably could form in pre-life conditions \parencite{Powner2009}). Templates encode information in biology, so template-based replication requires an encode/decode mechanism to store information in the template and to later retrieve it, as well as an information code. This is significantly more complex than simple multiplication. By contrast, the main issue with the metabolism-first model concerns the necessary shift from composomal or holistic\footnote{See discussion in \cref{variable-replicators}.} inheritance to template-based, and the ability of holistic systems to represent a sufficient range of stable states for unrestricted evolution \parencite{Vasas2010}.

In summary, the origin of life can be seen as the transition from chemistry to biology, and this transition seems tantalizingly similar to the artificial evolutionary goal of moving from simple, uninteresting, systems to creative systems which evolve. 

\begin{figure}
	\begin{center}
		\begin{tikzpicture}
		\node (prebiota) at (0,0) {prebiota};
		\node (metabolism-first) at (2,-1) {metabolism-first} edge [<-] (prebiota);
		\node (replication-first) at (2,1) {replication-first} edge [<-] (prebiota);
		\node (ida) at (4,0) {IDA} edge [<-] (replication-first) edge [<-] (metabolism-first);
		\node (luca) at (7,0) {LUCA} edge [<-] (ida);
		\end{tikzpicture}
	\end{center}
	\caption{Some of the stages proposed in the evolution of early life}
	\label{major-stages-early-life}
\end{figure}

\subsection{Replicators in evolutionary theory}\label{replicators-in-evolutionary-theory}

Although artificial systems are the main focus of this thesis, there is a natural overlap with research in biology into the origins of life. In particular the transition from chemistry to biology has several central concerns in common with our field of emergent replication in artificial systems. For example, how does the interaction of lower-level elements can form long-lived composite structures? What are the necessary and sufficient conditions for evolution? How does an evolutionary process begin in a non-evolutionary system? This overlap means that much of the most relevant previous work is to be found in origins-of-life research. 

In this particular \namecref{replicators-in-evolutionary-theory} we adopt a \textit{biological} classification of replicators from \textcite{Zachar2010} to structure our review of \textit{artificial} replication, and in other sections of this thesis we shall extend our scope as needed to include pertinent results from biology. However, it's important to stress that we are informed by biology, but do not hope or intend to contribute to biology in return. This remains a work concerned primarily with \emph{artificial} systems. 

In the transfer from the prebiotic world to the biotic one, the proportion of information held by a predecessor that could be passed on to its successor increased, over many generations, from ``none'' to ``nearly all''. \Textcite{Vasas2012a} relate heritability to the correlation between the parent and child entities. Heredity is therefore a matter of degree, rather than being a binary relationship (related or not-related), and that opens up the possibility that a series of gradual changes might over time transform a very poor replicator into a very good one. Of course, one possible process for this transformation might well be \gls{ens}.

But what exactly does it mean for something to be a replicator? Is a rock that erodes to form grains of sand a replicator\footnote{In \textcite{Bourrat2015} rocks are given as examples of \emph{persistors}, unable to reproduce and subject to only a ``weak'' form of selection for hardness.}? Is a set of autocatalytic reactions that splits into two replicating? \Textcite{Dawkins1976} was the first to define replicators, including a range from biological genes to non-biological ideas (memes) in the scope of the definition. Many other definitions and formulations followed as various properties or features were examined. 

%\textcite{Hogeweg1998} describes attractor-based heredity (inheritance of state) and storage-based. 
%
%Heredity by \textcite{MaynardSmith1999} is modular or holistic--if module changed only that module changes in descendants, holistic change part changes whole. Believe it true that unlimited heredity implies modular. \textcite{Szathmary1999} calls these digital and holistic, and adds phenotypic replicators whereby ``phenotype or function of one object is translated to the other, without any modular copying effect” 
%
%Modular/template heredity has advantages of: mutations hereditary; problems of correct copying \parencite{Eigen1977}

Relatively recently, \textcite{Zachar2010} saw a need to reexamine the definition primarily to resolve issues of discrimination between entities which are clearly replicators or not replicators and those which are borderline, and between biological replicators and non-biological or cultural ones. 

%A regenerating/recreating entity can produce at least one entity equivalent to it. It is possible that the original entity immediately decomposes (that is, cannot be the subject of further turns of the cycle), causing sequential replacement, although this is the most simple of regenerating entities. If it can effectively increase the number of entities equivalent to itself, then it is autocatalytic and is a \emph{replicator}.

They conclude that a \textit{replicator} is ``any autocatalytic entity for which there is a selection process defined'', using autocatalysis in the usual sense of a reaction, generally cyclical, that increases a reactant (say $A$) $n$-fold, but in this case where the products are not necessarily \textit{identical} to the reactant $A$s, but instead \textit{equivalent} when subject to selection. Instead of producing more $A$s, replication produces something indistinguishable by selection but which is not identical - we can call these products $B$s to make the distinction clear. Selection is the mechanism used to determine if entities are equivalent. 

Replication therefore has the form $\Sigma x_i + A\rightarrow \Sigma y_j + \Sigma B_k$ (where some $n$ of the ${B_0, B_1...B_k}$ products are equivalent to $A$ under selection, $\rightarrow$ means ``yields'', and $x$ and $y$ are some reactants and products, respectively, as needed), and where selection has the fairly standard definition of ``a process, acting on a particular population of entities in a particular environment, which sorts entities according to their phenotypes.'' \parencite[p.21]{Zachar2010} 

Note that replicators in this definition are subsets of autocatalytic entities: replication implies multiplication, but replicators must also have some property (a phenotype) that is visible to an external process (selection.) \Citeauthor{Zachar2010} further discriminate between types of replicator based on two further factors: variability and heredity. If the replicator can change and yet still be equivalent under selection, then it is a variable replicator, which can exist in several equivalent states. An exact replicator on the other hand is one in which any change causes the entity to fail, or to respond differently under selection. Variability is the first stage towards metabolism and a genotype/phenotype distinction. Heredity describes which elements of variability are passed on to a descendent (the genotype.) If variability can be passed on, then the replicator is informational---the change in information can persist. If all changes are passed on, then the replicator is an \emph{ideal} replicator, where the genotype encompasses the entire entity, while if they are not, the replicator is \emph{real}.

Building on this, \citeauthor{Zachar2010}, extending earlier work by \textcite{Szathmary1999,Szathmary:2006ty}, go on to develop the following general classification of replicators as a logical sequence of forms \parencite[p.21, line breaks and numbering added for emphasis]{Zachar2010}:  

\begin{enumerate}
	\item ''The simplest of replicators is the \emph{exact replicator}, which is \emph{non-informational}, and any change made to it causes a change in the phenotype. 
	\item If a variation can arise in the structure in such a way that it does not change equivalence of the entity, then it is a \emph{variable} replicator, with more than one stable state.
	\item If such changes can be passed on to the offspring then the replicator is \emph{informational}. 
	\item If the non-heritable part is constructed by a developmental process, then the replicator is a \emph{reproducer}.'' 
\end{enumerate}

An alternative hierarchy, from the same source \parencite{Zachar2010}, is shown in simplified form in \cref{fig:replicators}. Here the hierarchy is by a cumulative arrangement of features from basic embodiment through to heredity; the main discriminators from the earlier definition are arranged to the right of the figure.

\begin{figure}[t]
	\begin{center}
		\vspace{10pt}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm, thick,main node/.style={circle,fill=blue!20,draw, font=\sffamily\Large\bfseries,minimum size=15mm}]
		\draw [->] (-5.9,5.9) -- (-5,5);
		\draw [->] (-4.9,4.9) -- (-4,4);
		\draw [->] (-3.9,3.9) -- (-3,3);
		\draw [->] (-2.9,2.9) -- (-2,2);
		\node [left,font=\itshape] at (-5.5,5.25) {Embodiment};
		\node [left,font=\itshape] at (-4.5,4.25) {Multiplication};
		\node [left,font=\itshape] at (-3.5,3.25) {Variability};
		\node [left,font=\itshape] at (-2.5,2.25) {Heredity};
		\draw [<->] (-1,4.9) --node[left]{Exact} (-1,4);
		\draw [<->] (-1,3.9) --node[left]{Variable} (-1,2);
		\draw [<->] (0,4.9) --node[right]{Non-Informational} (0,3);
		\draw [<->] (0,2.9) --node[right]{Informational} (0,2);
		\end{tikzpicture}
		\caption[Replicator systems according to the hierarchy of Zachar and Szathm\'ary (2010)]{Replicator systems according to the hierarchy of \citeauthor{Zachar2010}. Diagram redrawn from \cite[Fig.13]{Zachar2010}.}
		\label{fig:replicators}
	\end{center}
\end{figure}

\section{Previous work}\label{previous-work}

Many modern artificial replication systems trace their intellectual ancestry back to one of two main starting points---\cite{Kauffman1986}, and \cite{Bagley1991}---both motivated by the goals of origins-of-life research.

\Citeauthor{Kauffman1986} describes a binary polymer model to investigate the formation of autocatalytic sets, and in particular how this is affected by the probablity of catalysis. In \citeauthor{Kauffman1986} polymers are modelled as strings of binary digits of maximum length, $n$, and molecules catalyse randomly chosen reactions for ligation or cleavage, with a constant probability $P$ that a molecule will catalyse any given reaction.

\Citeauthor{Bagley1991} investigates Auto-Catalytic Metabolisms with catalysts included as the mechanism to provide the permanently elevated concentrations required.

\emph{RBN-World} \parencite{Faulconbridge2011} is an \gls{achem} where the entities take the form of \gls{rbn} \parencite{Kauffman:1969ne}, with the addition of a bonding mechanisms to allow for their composition and decomposition. The resulting form of \gls{rbn} is called a bonding \gls{rbn} or bRBN.  Larger structures are formed by ``bonding'' two independent bRBNs at each bRBNs bonding node. ``All reactions are between two reactants; it is assumed that more complicated reactions can be expressed as a series of two-reactant reactions with intermediate structures.'' The choice of reactants is described as ``Gillespie-like'', and essentially random, uncorrelated in any way with reaction energies or rates \parencite[chap.8]{Faulconbridge2011}.

Each bRBN is a synchronous RBN, made up of a number of nodes, each with an initial state (\emph{true} or \emph{false}) assigned randomly and with an input/output matrix assigned randomly. Finally k(=2) inputs are established per node. The bonding method uses ``cycle length as the bonding property and equality as the bonding criterion....bonds only exist between bRBNs that have the same cycle length.'' After initial bond formation the algorithm recalculates cycle lengths, and checks again for equality. This might result then in decomposition (records are kept of composition operations so that the reverse decomposition can be easily done.)

A number of parameters affect the behaviour of the chemistry, and so a series of experiments sampled from the parameter-space, and then used a GA, to search for interesting variants as measured by non-catalysed ``loops'' (as the preferred measures of auto-catalytic sets and \glspl{hypercycle} are too rare for use as a measure) \parencite[chap.8]{Faulconbridge2011}. 

The development of RBN-World involved many design choices, some essentially adhoc, such as the choice of \gls{rbn}: ``...the choice to use RBNs as the sub-symbolic representation in RBN-World was based on limited information. As a discrete dynamical system that is computationally tractable yet also spans a wide range of behaviours, RBNs met the appropriate criteria. It is not expected that RBNs are the best representation however; others may be more suitable for particular emergent properties.'' \parencite[p. 192]{Faulconbridge2011}

\subsection{Replication without self-replication}

The model for \emph{Chemical Evolution by Natural Selection} in \textcite{Fernando:2007pf, Fernando:2008xy} is driven by origin-of-life objectives (``the evolution of chemical networks that lead to autonomous systems''), and takes the form of a simulation of laboratory experiments of lipid aggregates (``phase separated ‘individuals’, e.g. liposomes'') in a reactor. The molecules and food molecules (that make up an autocatalytic cycle) share a common representation and underlying chemistry, while replication, unlike the (rare) autocatalytic cycles in \textcite{Faulconbridge2011}, is by `` division by externally imposed agitation, i.e. replication rather than self-replication.''.

Mutations in cycles are generally not heritable as mutant copies are rarely functional in autocatalysis \parencite{Vasas2012a}. Mutation is thus problematic as a source of variation in these autocatalytic systems; one alternative to mutations, introduced in \textcite{Fernando:2007pf},  is ``avalanches'', to form new cycles from temporarily-preferred side-products of the base networks. Two existing species are chosen at random, tested to see if a reaction between them is possible by thermodynamics, and then the resulting products seeded in the reactor at low concentrations. These new reactions may be autocatalytic, or the products may complete a food-set for another autocatalytic reaction, or they may enable a side-reaction from an existing autocatalytic one. Introducing these new species into the reactor therefore can trigger the rapid formation of a series of novel products---a chemical avalanche.

\subsection{Exact replicators}\label{non-informational-exact-replicators}

Autocatalysis by definition is replication; if the entities are molecules, the autocatalytic reaction $\Sigma x_i + A\rightarrow \Sigma y_j + \Sigma A_k$ replicates the molecule $A$ (\eg \textcite{Lifson1997}). An exact replicator is where the $A$s on the left-hand side of the equation and the right-hand side are identical; any change results in a functionally different entity (that is, different under selection), and so each entity exists in only one stable state. This fundamentally limits the evolutionary potential of an exact replicator as there is no heritable variation.

\subsection{Limited heredity replicators}\label{variable-replicators}

If states are to be a store of information for a replicator, they must be capable of maintaining information from generation to generation. The number of alternative stable states forms an upper bound on the total information held by a variable replicator.

\Textcite{Ganti:2003hl} and  \textcite{Eigen1971} showed that distinct, organisationally different alternative autocatalytic networks in the same environment might compete, and the fittest would prevail. A number of models have been proposed since where autocatalytic networks form stable components that can be inherited in a modular fashion in a process called compositional inheritance. All these models are analytical in nature, in many cases based on the \gls{ode} model of \cite{Farmer1986}.

%\emph{Reflexively Autocatalytic Polymer Networks} (RAPN) \parencite{Kauffman1986} are evolvable. First, likelihood of such networks higher than expected (Hordijk and Steel) and second, in \textcite{Vasas2012} putting these networks into compartments (so not well-stirred) then can do directional selection.

In the most well-known of these models, the Graded Autocatalysis Replication Domain (\emph{GARD}) model \parencite{Segre1998}, highly catalytic molecules determine the properties of the compotype (compositional genotype), and these are not necessarily inherited equally. Instead a child may, or may not, inherit one of these molecules and so its properties may be similar to or very different from its parent \parencite{Vasas2015, Vasas2012, Vasas2012a}. Information fidelity varies widely; the Eigen threshold \parencite{Eigen1971} applies, and mutation rates overwhelm selection \parencite{Vasas2015, Vasas2012, Vasas2012a}.

% Any molecule in the core will produce the remaining species in both the core and periphery \parencite{Vasas2012a} and so reconstitute the core,

The model of \textcite{Vasas2015, Vasas2012, Vasas2012a}, derived from \textcite{Farmer1986}, tests the GARD hypothesis that compositional inheritance is possible where there is a parent-offspring correlation in molecular composition. The mechanism is autocatalytic cores made up of one or more linked autocatalytic loops to provide the compotype. The core forms an attractor, where one core equals one attractor, but multiple cores are required of course for selection. Multiple cores, produced by inhibition \cite{Vasas2012a}, provide multiple attractors, but the attractors must be stable for selection to be stable and meaningful. Unlike GARD, which generates only single-core networks, the model in Vasas is capable of multiple cores, but as cores are the equivalent of a single bit of heritable information, it's hard to see core-based inheritance being capable of unrestricted heredity---there are practical limits to the number of stable cores that can co-exist in a system. 

\subsection{Unlimited heredity replicators with shortcut replication mechanism}

A \emph{shortcut} is where the replication mechanism is directly implemented by the experimenter rather than being an emergent property \parencite{BanzhafBaumgaertnerBeslonEtAl2016}. As the mechanism is external to the entity it is not under selection; shortcut replicators are not, by our definition, open-ended. One of the most well-known systems with a shortcut replication system is \emph{Squirm3} \parencite{Hutton2007,Hutton2002}, an artificial system capable of life-like \gls{oe} (creativity), initially developed with the goal of testing the hypothesis of \textcite{Taylor2001} \parencite[p.341]{Hutton2002}.

All elements in Squirm3 are constructed from atoms defined by \emph{types} (e.g., a, b, c\dots) and \emph{states} (e.g., 0, 1, 2\dots). Atoms and hence molecules are located on a 2D grid, and molecules cannot overlap or pass through each other. All reaction rules, such as \emph{R1: e8 + e0 $\rightarrow$ e4e3}, are pre-specified (\textcite[p.4]{Hutton2007} and \textcite[p.49]{Faulconbridge2011}), and a shortcut consisting of a set of eight rules in \textcite{Hutton2002} is sufficient to replicate single molecules. As all reaction rules, including those responsible for replication and hence inheritance, are exogenous to the model, the inheritance mechanism in Squirm3 is not evolvable. 

Individual entities in \textcite{Hutton2002} are simply single molecules. \Textcite{Hutton2007} introduces cells made up of a collection of molecules and bounded by a membrane of a particular atom type of limited reactivity; the membrane is intended to allow individuals to benefit from innovations by protecting their internal reactions from others. With a greatly increased set of predefined reaction rules (34 rules in \textcite{Hutton2007} for the cell replication shortcut, extended again in \textcite{Lucht2012}), each cell has the capacity for division and mutation.  Selection is purely by indirect competition for the raw materials (atoms in the environment) required by the reactions in a cell; interactions between individuals are purely through this indirect competition (niche construction without direct interaction). Cells in \textcite{Hutton2007} are incapable of making use of resources from other cells (as they are effectively protected by non-reactant membranes) and so an intermittent exogenous mechanism (``floods'') is used to return the atoms in a number of randomly chosen cells to the environment.

\subsection{Unlimited heredity replicators}
Replication in these systems emerges from the base rules (or \textit{level-0} rules in the terminology of \textcite{BanzhafBaumgaertnerBeslonEtAl2016}) without being directly specified by the experimenter or designer. However, even here most systems still shortcut this by providing a seed or universal ancestor (\eg \textcite{Ofria2004}) that contains a working module for replication that can be then modified (for good or ill) in each subsequent generation.

\subsubsection{String-manipulation systems}

A new object, $h$, in Fontana's Algorithmic Chemistry, or \emph{AlChemy} \parencite{Fontana1992}, is formed by the composition of two parent functions, $f$ and $g$: $h(x)=f(g(x))$. More formally, replication is defined as the interaction expression, $h$, of two randomly chosen objects $f$ and $g$, if, and only if, the interaction expression contains at least one variable and one primitive operator, and is shorter than some maximum length \parencite[p.173--p.180]{Fontana1992}. New objects in AlChemy are therefore the children of two parents.

How then is the interaction expression $(('f)('g))$ between $f$ and $g$ evaluated to produce $h$? AlChemy is a form of pure LISP (with some ``minor idiosyncrasies''), based on toyLISP, with six primitive operators defined in \textcite[p.205]{Fontana1992}. The interaction expression is defined in \textcite[definition A.9, p.204]{Fontana1992} as $V[(('f)('g)),()] = (V[f,(a\leftarrow g)])$, using the notation $V[e,L]=v$ to mean the expression $e$ with the ``association list'' $L$ (a list of value assignments between atoms and expressions) evaluates to $v$. The result $h$ is described as $f(g)$ and the process as $f+g \rightarrow (('f)('g)) \rightarrow h + f + g$.

Clearly reproduction in AlChemy is self-referential and endogenous: the process to construct a child object is defined in the code of the parent objects. However, inheritance doesn't follow straightforwardly as the reproduction process is unusual in some important ways. Producing new objects as a function of two parents means that the relationship between parents and child is not a straightforward mutation or other syntactic difference, but rather a complex functional relationship. What this means for the relationship between the parent's fitness and the child's fitness is not obvious. It seems that the fitness differences in AlChemy might be more extreme than in other systems where parent and child have a more straightforward relationship.

%\begin{DRAFT}
%\parencite{Fenizio2000}:
%
%Original AlChemy reactions of form $A+B\rightarrow C$ where $C$ replaces an existing element.
%
%This system generates $A+B\rightarrow C_1+C_2...C_n$ where $C$ is a multiset of size $n$. Done by modifying the original K rule to detach x2 and eliminate both original elements (like reactants in chemistry)
%
%Uses combinators rather than lambdas
%
%To prevent from stopping (out of elements) added modification where randomly add/remove some elements
%
%Combinator first combines (appends) elements, each element other than first bracketed. Then each 1-term combinator applied to string, where it makes specific changes \eg K x1x2s0-\textgreater{}x1s0 (s0 is remaining substring, may be null). Apply until no further reductions possible (that is, in normal form). Two combinators are equivalent if can be reduced to same combinator (and previously noted that order is not important--same results regardless of order).
%
%Free pool of atoms for conservation of ``mass''
%
%\parencite{Fenizio2001}:
%
%Experiment to show spontaneous formation of autopoietic cells, with a focus on ``identity as an entity separated from its environment'', that is, membrane formation. Graph used to model spatial structures: ``an artificial chemistry (AC) is embedded in a graph, with each molecule being a vertex of the graph and possible interactions being allowed only along the edges of the graph''. Molecules are composed of atoms taken from a 
%
%``Molecules are built from a substrate of elements called atoms. There are seven types of atoms ($I, K, W, R, B, C, S$), each with a different function. The total number of atoms in the reactor is kept constant during a run. Free atoms (not bounded in molecules) are separately stored and form a global pool.''
%
%As the rules for the combinations of two molecules are predetermined (the reaction mechanisms are described in \textcite{Fenizio2000}), this model is not by our definition open-ended.
%\end{DRAFT}
\subsubsection{Automata}

\emph{Coreworld} \parencite{Rasmussen1990}, inspired by the early computer game ``Core War''\footnote{See \url{corewar.co.uk}}, set segments of simplified assembly code into competition in core memory. The assembly command to copy values from one memory location to another can spontaneously introduce errors into the copying, and hence can introduce evolutionary variation. However, as reviewed by \textcite{Ofria2004}, the system ``collapsed into a non-living state'' perhaps because organisms could copy over each other in the shared system memory \parencite{Ofria2004}.

In \emph{Tierra} \parencite{Ray1991} mutations are introduced during replication by randomly flipping bits during the copy operation (at a given rate of generally between 1 bit flip per 1,000 and 2,500 instructions copied). This rate is set by the experimenter, and is not evolvable. Mutations can also be introduced by the copy algorithm itself; as it is an algorithm defined in the organism in standard Tierra instructions (and hence fully embedded), mutations in the algorithm during a copy will be inherited by the child. The initial copy algorithm is part of the 80-instruction ancestral creature documented in \textcite[app.C]{Ray1991}.

In Ray's words, ``...this approach involves engineering over the early history of life to design complex evolvable organisms, and then attempting to create conditions that will set off a spontaneous evolutionary process of increasing diversity and complexity of organisms'' \parencite[p.3]{Ray1991}. As Taylor criticises though, the problem with ``engineering over'' is that we don't understand the natural examples well enough to engineer them at all \parencite{Taylor2001}

Tierra has been the testbed for a number of other works. For example, \textcite{SugiuraSuzukiShioseEtAl2003} converted Tierra into a string manipulation systems, introducing a set of 140 regular-expression based rewriting rules where each rule encoded one or more of the original 32 Tierran instructions. The initial rewriting ruleset was manually generated by the experimenters, although details are unclear. Unlike in Tierra where the instruction set is fixed during a run, the rewriting ruleset for each organism itself could evolve through a separate genetic algorithm. This algorithm removed the least applied rules and inserted the same number of new rules generated by mutating (through duplication, removal and addition of operations) a selection of the most applied rules. Although results support the claim that the ruleset as well as the genome evolves, the use of a separate genetic algorithm for ruleset evolution artificially separates the ruleset from the genome; the feedback loop from genome back to ruleset is broken.

Tierra was also the starting point for \textcite{Taylor2001, Taylor:1999sc} to explore the creation of \gls{alife}, by adding cell regulation, parallel processes and energy modelling.

% Seed (proto-DNA) must itself be an indefinite heredity replicator {[}assumes that this is minimal starting point, rather than that this itself may evolve{]} \parencite{Taylor2001}
%Assume that early stages see A+B implicitly encoded in the environment, essentially as simpler than explicit mechanism, but little justification given beyond ``At the early stages of an evolutionary process, however, we would not expect there to be mechanisms for explicitly decoding the proto-DNA\ldots{}'' \parencite{Taylor2001}

\emph{Avida} \parencite{Ofria2004}, introduced in the summer of 1993, is based on Tierra with improvements including better metering and measuring, and a 2D lattice or well-stirred reaction vessel topography (unlike the shared linear memory of Tierra, for example). ``In principle, the only assumption made about these self-replicating automata in the core Avida software is that their initial state can be described by a string of symbols (their genome) and that they autonomously produce offspring organisms. However, in practice our work has focused on automata with a simple von Neumann architecture that operate on an assembly-like language inspired by the Tierra system.''

Like Tierra, the automata engine in Avida is based on a Turing tape-like metaphor, with instruction, read, write, and flow control heads that can be moved forward and backwards through memory using relative rather than absolute addressing. Instructions are grouped into instruction sets, with the default set containing 26 instructions, and by definition every program is valid. Each organism runs on its own virtual automata; the only interaction between organisms is via resources in the shared environment and through competition for virtual machine CPU cycles based on ``merit'' or fitness. Direct Tierra-style interactions by insertion of code into another organism is not enabled by default, but is possible through configuration. 

Phenotypes take the form of computations (entities take in resources, perform computations that result in merit, and perhaps produce output or by-product resources): ``\ldots by inputting numbers from the environment, performing computations on those numbers, and outputting the results. The organisms receive a benefit for performing specific computations associated with resources'' \parencite{Ofria2004}. Crucially, the resources in the environment are not the same as the elements of the organisms (instructions from an instruction set.) Avidan organisms are not fully embedded in their environment.

New organisms are created asexually by the parent first allocating memory for a child. The parent's read-head is placed at the beginning of its code, the write-head placed at the start of the newly allocated memory and successive \url{h-copy} instructions copy the instruction from the read-head to the write-head and advance both. After all instructions have been copied, \url{h-divide} splits the child from the parent (all instructions between read-head and write-head go to the child) and start execution in both parent and child from a clean state. Variation comes through mutations which can be introduced through either \url{h-copy} (the write-head writes a random instruction rather than the instruction at the read-head) or in \url{h-divide} (a single random instruction may be deleted or added from the child code). Both forms of mutation happen with a fixed probability set by the inventor: COPY\_MUT\_PROB, INS\_MUT\_PROB, and DEL\_MUT\_PROB for \url{h-copy}, and DIVIDE\_INS\_PROB, DIVIDE\_DEL\_PROB for \url{h-divide}. However, there is a second, evolvable source of mutations during replication: the replication process itself is embedded in the organism, as a set of instructions, and so changes to this algorithm during the copy will persist in the child. The self-replication algorithm is initially defined in the ancestral organism used to seed a run, and as documented in \textcite[A1.3]{Ofria2004} consists of 15 instructions.

Avida is extremely configurable, but provides little guidance or theoretical justification for any particular configuration. Indeed this variability allows it to function most usefully as a general testbed for experiments, \eg ``in one experiment we wanted to study a population that could not adapt, but that would nevertheless accumulate deleterious or neutral mutations through drift'' \parencite{Ofria2004}.

\emph{Amoeba-II} \parencite{Pargellis2001} shares similar features to Tierra and Avida in that it is an instruction-set based automata, but unlike in those systems, replication spontaneously emerges in Amoeba-II. The replication process requires four steps: ``register initiation, memory allocation, copying of the parent's instructions to the child (embryo), and division where the child is initiated as a cell on its own'' \parencite[p.69]{Pargellis2001}. Two specific instructions in the parent's genome are required at a minimum. The MALL command allocates memory, and a virtual CPU to the child, and DIVD performs the division. Register initiation and copying of the parent's instructions can be done in a variety of different ways, and a good deal of the interest of the Amoeba-II system lies in the evolvability of these mechanisms. Selection is by efficiency of replication, where faster and more efficient replicators replace less efficient ones in the population (as \textcite{Pargellis2001} says, ``Amoeba has only one task: replication'') and so there is selective pressure from the least efficient, but functioning, mechanisms in the direction of improved replication. To complement selection and inheritance, variability is provided by the DIVD instruction, which introduces a mix of instruction substitutions, deletions and insertions into the child's program at a fixed but low rate.

Inheritance in Amoeba-II is almost too effective. Fit organisms rapidly evolve into extremely rapid reproducers and out-replicate all other entities, leaving a mono-culture \parencite{Pargellis2001}.

%\begin{DRAFT}
%\textcite{Dittrich1998}:
%A simulation approach towards ``dynamic phenomena, especially on the emergence of prebiotic evolution'', based on an artificial chemistry.
%
%Introduction of \textless{}\emph{S},\emph{R},\emph{A}\textgreater{} classification scheme for artificial chemistry, elaborated in \parencite{Dittrich:2001zr}, where in this work \emph{S} are `` binary strings with a constant length of 32 bits'', \emph{R} are of the form $s1+s2 \rightarrow s3$, and \emph{A} ''simulates a well-stirred tank reactor with mass-action kinetics, which assures that the probability of a collision is proportional to the product of the concentration of the colliding objects'' (based on earlier work by Fontana and Kauffman.)
%
%A=``1. Select two objects s1,s2 from the soup randomly, without removing them. 2. If there exists a reaction s1 + s2 to s3 and the filter condition f (s1,s2,s3) holds, replace a randomly selected object of the soup by s3.'', s1 and s2 are not consumed, rather they act as catalysts. Chosen as this shown capable of hypercyclic organisation
%
%Asn automata reaction with a set of operations (six common logic operations, \eg OR, and nine computational instructions), represented as 4-bit sequences, to generate s3 from s1, s2. Automata is a deterministic FSA, running s1 on s2 to produce s3. As Dittrich observes ``The first noticeable property is that the structure of the product s3 is similar to its 'parents' s1; s2. This indicates that there is a correlation between s1, s2, and s3 that is a prerequisite for evolution.''
%
%Passive self-replicators ($s1 + s2 \rightarrow s2$) are relatively common (approx. 30\% of randomly generated strings), while active self-replicators ($s1 + s2 \rightarrow s1$) are very rare (around 0.004\%).
%\end{DRAFT}
\subsubsection{StringMol and GraphMol}

The related automata \emph{StringMol} \parencite{Hickinbotham2011} and \emph{GraphMol} \parencite{Nellis2012, Nellis2014} explore computational novelty through embodiment: ``Our aim is to improve novelty-generation algorithms by making their biological models richer.'' No measure is proposed for novelty. The authors state that they're not even sure it is possible, but an informal definition is used that sees novelty as the outcome of increasing embodiment \parencite[p.87]{Nellis2012}.

A persistent theme in Alife attributes the differences in richness between biology and Alife to the grounding of biology in the physical world, or embodiment. \Textcite{Nellis2012} examines a pre-existing definition of embodiment, concerning the relationship that exists between a ``system'' and an external ``environment'', before suggesting a modification based on the specifics of biological genome-copying where the complexity and subtleties of the copying derive directly from the embodiment of an abstract concept (copying) in physical-world mechanisms. The modification suggested by \textcite{Nellis2012} is to define embodiment in terms of a world, encompassing both environment and system, in which exists mechanisms of interest (such as a template-copying replicase) that produce abstract phenomenon (/eg copying.)

The base elements in StringMol are single-character symbols, each representing a microcode instruction. These combine to form strings representing molecular microprograms (the strings of the name). The general arrangement feels very similar to that in Avida or Tierra, as seen for example in the various pointers, or indexes, into the code (instruction, read, write, and flow for iterations).

GraphMol replaces the strings in StringMol by graphs: ``[t]he world defined by GraphMol contains chemicals (represented as graphs) that bind to each other via multiple binding sites, and then run simple computer programs (encoded in the graphs) that modify the binding of these chemicals.''. No explicit rationale for graphs is presented, other than as a natural extension from StringMol given the stated importance of a rich binding mechanism. 

An underlying principle in both systems is that the mechanism of evolution must be itself evolvable; functions such as template copying must be embodied mechanisms in the world so that they can be affected by evolution, and so evolved.  Crucially both StringMol and GraphMol have embodied template copying, where a ``replicase'' molecule can copy another by an algorithm such as in \cref{alg:stringmolgraphmol}.

Although the algorithm itself is unremarkable, the underlying functions allow StringMol and GraphMol to explore various forms of embodiment. Each of the four functions referenced in \cref{alg:stringmolgraphmol} (\emph{start}, \emph{at-end}, \emph{char-copy} and \emph{next}) can be either ``crisp'' (\ie perfect or precise) or embodied (variable or fuzzy, and subject to evolution). As an example of an embodied function, StringMol's \emph{start} function uses pattern-matching to determine the binding region between the replicase and the other string where the replicase should begin copying. By changing the subsequences in either string the strength of bind can be varied, with a corresponding shift to the beginning of the copy region even though the pattern-matching algorithm itself does not change (it is a ``level-0'' component in the terminology of \textcite{BanzhafBaumgaertnerBeslonEtAl2016}). The same pattern-matching is used in StringMol's \emph{at-end} function to determine the end of the region to be copied.

\begin{algorithm}[ht]
	$\text{i} \leftarrow \text{start(string B)}$\;
	\While{$\text{i not at-end(string B)}$}{
		$\text{string A(i)} \leftarrow \text{char-copy(string B(i)))}$\;
		$\text{i} \leftarrow \text{next i}$\;
	}
	\caption[The canonical algorithm for template copying used by StringMol and GraphMol]{The canonical algorithm for template copying used by StringMol and GraphMol, from \textcite{Nellis2014}.}
	\label{alg:stringmolgraphmol}
\end{algorithm}

StringMol includes an embodied \emph{start} and \emph{at-end}, crisp \emph{next}, and stochastic \emph{char-copy}; GraphMol has an embodied \emph{start}, \emph{at-end} and \emph{next}, with a crisp \emph{char-copy}. The primary difference between the two is opposite approaches to \emph{next} (``in order to investigate a method of embodying the copying process that would be completely different from Stringmol's.'' \parencite[p.145]{Nellis2012})

These mechanism differences (the choices of which functions are crisp and which are embodied) result in different outcomes for the overall system: ``Stringmol exhibits macro-mutation and two chemical copying; GraphMol exhibits two types of quasispecies, cooperative and parasitic. These two systems use the same domain (emergent evolution) and metamodel (machines copying strings), but different computational models.'' Other combinations would presumably show different behaviour again.

Despite the use of the term ``embodied'', those functions that aren't ``crisp'' are not in fact fully self-referential as the pattern-matching algorithm itself remains unaffected by evolution. There is also a disconnect between the properties of the targets of the matches and the functioning of the algorithm. The algorithm matches on the symbol, and is completely unaffected by the meaning or properties of those symbols, the underlying microcode. In this it differs significantly from a completely endogenous system such as a biological replicase, where the match or bind is actioned by the same chemical rules that construct and maintain the replicase from component atoms.

\begin{table}
	\scriptsize
	\begin{center}
		\caption[\Gls{achem} replicators in selected previous works, categorized according to Zachar and Szathm\'ary (2010).]{\Gls{achem} replicators in selected previous works, categorized according to \textcite{Zachar2010}. ODE-based models such as GARD and \textcite{Vasas2012} are not included as they are not \gls{constructive} and hence incapable of unlimited evolution; RBN-World \parencite{Faulconbridge2010} is not included as self-replication has not been reported.}
		\label{tbl:previous-work}
		\begin{tabular}{@{}p{3.5cm}p{1.5cm}p{3.5cm}p{3.5cm}p{2cm}@{}}
			\toprule
			Artificial replicator            						& Model form					& Multiplication					& Variability						& Heredity\\ 
			\midrule
			\emph{Squirm3} \parencite{Hutton2002}                   & Molecular						& Exogenous rules					& Exogenous (hand-crafted)			& Unknown---depends on rules\\
			\emph{AlChemy} \parencite{Fontana1992}					& $\lambda$-calculus			& Endogenous (function composition)	& Variable (functional equivalence)  & Holistic\\
			\emph{StringMol} \parencite{Hickinbotham2012}           & Automata, encoded as strings	& Endogenous (algorithmic)			& Variable (functional equivalence)	& Endogenous\\
			\emph{GraphMol} \parencite{Nellis2014}					& Automata, encoded as graphs	& Endogenous (algorithmic)			& Variable (functional equivalence)	& Endogenous\\
			\emph{Coreworld} \parencite{Rasmussen1990} 				& Automata						& Endogenous (algorithmic)			& Variable (functional equivalence)	& Unknown\\
			\emph{Tierra} \parencite{Ray1991} 						& Automata						& Endogenous (algorithmic)			& Variable (functional equivalence)	& Endogenous\\
			\emph{Avida} \parencite{Ofria2004} 						& Automata						& Endogenous (algorithmic)			& Variable (functional equivalence)	& Endogenous\\
			\emph{Amoeba-II} \parencite{Pargellis2001}				& Automata						& Endogenous (algorithmic)			& Variable (functional equivalence)	& Endogenous\\
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}

Of the systems discussed in \cref{previous-work} (summarised in \cref{tbl:previous-work}), the most successful approach to date has been through automata. In these systems, multiplication is by an algorithmic process where code within the parent, when executed, repeatedly copies the instructions from parent's code to a child using a specific copy operator (\eg \url{h-copy} in Avida.) Deliberate errors introduced during copying by the operator (erroneous copying, see \textcite[p.16]{Zachar2010} for the biological equivalent) provide one source of variation; another comes directly from algorithms where there can be several different instruction sequences that are functionally equivalent, so providing variability as defined by \citeauthor{Zachar2010}.

The initial multiplication process in each of the reviewed automata copies all instructions from the parent; therefore the entity's genotype is the same as its instruction set. Heredity is thus holistic and in the notation of \citeauthor{Zachar2010}, $H=V$ (discussed further in \cref{ch:models-of-inheritance}). For example, in Tierra, the 80-instruction ancestral creature includes code to determine its beginning and end in memory and then to copy everything between the two to a child entity. However, this multiplication code is part of the entity and subject to variation; it is itself evolvable and in principle at least capable of evolving towards a model where only a proportion of the entity is copied.

\section{Research questions}\label{research-questions}

Of the forms of replicators defined by \textcite{Zachar2010} and described in \cref{previous-work}, only unlimited heredity informational replicators provide both the representational range and the evolutionary flexibility for open-ended evolution:

\begin{itemize}[noitemsep]
	\item Exact replicators lack heredity as they cannot pass on variability to their descendents.
	\item Limited heredity replicators are capable of only a limited number of distinct states and so suffer from a restricted representational range.
	\item Informational replicators based on replication ``shortcuts'' are in practice still limited as their inheritance/heredity mechanism is not evolvable.
\end{itemize} 

This thesis is therefore motivated by the following research questions:

\begin{enumerate}[label=RQ\arabic*:]
	
	\item \emph{In what way does selective pressure drive changes in heredity in a population of evolving replicators??} This is driven by two considerations. First, existing work in evolutionary theory (see \cref{ch:models-of-inheritance}) has suggested that heritability is the result of selection and variation under constant selective pressure. There is also a broad body of work in biology exploring aspects of the connection between fitness (the counterpart to selection) and environmental variability (for example, canalization). We are interested in a model of heredity that incorporates environmental variability as variable environments are the superset of fixed ones, and as a response to variability appears to be a factor in shaping the inheritance mechanism in biology. We believe that the factors underlying this relationship between heredity and variability also apply in artificial systems. Second, the response of heredity to selection is clearly evolutionary, and our hypothesis is that heredity can emerge through evolution in a molecular \gls{achem}. A coherent model would illuminate the mechanism by which this may be achieved in practice in an artificial system. Therefore, we investigate a model for the response of heredity to selective pressure in \cref{ch:models-of-inheritance}.
	
	\item \emph{Can variable replicators emerge from a molecular artificial chemistry?} Although replicators have been studied extensively, previous models have provided, or assumed, the provision of a replication mechanism rather than having the mechanism evolve. We instead will test the position that replicators can in fact emerge from lower-level reactions between molecules in an artificial chemistry. We begin our examination of this hypothesis with a review chapter to introduce \glspl{achem} in \cref{introduction-to-achems}, then in \cref{ch:toyworld} we introduce a molecular \gls{achem}, modularized for experimentation, and show that certain configurations are capable of reaction cycles. We then investigate the emergence of multiplication, the simplest form of replication, from cycles in \cref{ch:multiplication}, and conclude by examining variability in the sense of \textcite{Zachar2010} in \cref{ch:variability}.

\end{enumerate}

\section{Methods}\label{methods}

In this \namecref{methods} we explain the methods used in the remainder of this work. For each research question we follow a common process:
\begin{enumerate}
	\item Relevant previous work is used to identify areas where the research question is well understood, and those areas where further work would be beneficial.
	\item We construct a simulation model that attempts to capture our understanding of the problem for the areas where further work is needed.
	\item Based on the context formed by the research question and the previous work, we form a hypothesis of how the simulation should function if our understanding is correct.
	\item We then proceed to test this hypothesis by experiment using the simulation.
\end{enumerate}

Each simulation model is parameterised. Parameters are elements in the simulation model that can take different possible values, where the different values may (or may not) lead to quite distinct behaviour of the simulation. The purpose is two-fold: first, to allow for the investigation of a range of models simply by changing parameter values (rather than changing entire models) so as to broaden the \emph{scope} and hence the applicability of the results, and second, to permit us to test the \emph{sensitivity} of the simulation to different parameters overall. The combination of these two allows us to robustly justify the scope and strength of any claims that arise from the experiments.

As each parameter may take any of a range of values, and given that there will be a number of parameters, we need a way to limit the size of the parameter space for experimentation.

We do this by first testing the response of the model to each parameter and identifying those that do not make a statistically significant difference; the set of these parameters, those to which the model is insensitive, allows us to establish the scope over which all claims will hold. Those to which the model is on the other hand sensitive, or responsive, are tested separately in all later experiments; any claim must be made conditional on the particular level of each of these parameters.

Second, we use statistical ``design of experiments'' (\eg \cite{Montgomery2009}) methods to simplify the number of separate experiments needed. There are many design of experiments strategies, but they mostly fall into two standard groups. 

The most common approach is via some form of factorial design, where each parameter of interest is represented by a factor taking some small number of discrete values, or levels (two levels being most common) and the analysis model constructed from runs that systematically work through a series of combinations of factors at different levels. The emphasis here is on the response given particular factor (and hence parameter) values. 

A variant of this is a fractional-factorial design, which takes a well-defined sample of factor levels to further reduce the number of level combinations while still maintaining an acceptable level of experimental strength. Latin square (and Graeco-Latin and Hyper-Graeco-Latin) designs are well-known forms \footnote{For example, see discussion at \url{http://www.itl.nist.gov/div898/handbook/pri/section3/pri3321.htm}} of fractional factorial design for the case of a single factor of primary interest combined with one or more ``nuisance'' factors which are of no interest to the experiment but have an effect on the result. However, in this work the relatively small number of representative levels required, combined with the reasonable speed of the simulation, is such that we can remain with a simpler full-factorial design.

Statistical analysis must be carefully considered in any multi-factorial experiment design as pair-wise tests of the mean such as Student's t-test cannot be extended to multiple groups (factors) without significant loss of accuracy. Instead we will use \gls{anova} when analysing the relative contribution of each factor, or combination of factors, to the observed values of the response variables.

Note that there are some differences between the design of experiments in the physical world and in simulations, with the most significant being the sources and understanding of experimental errors. In simulation, experimental runs are exactly reproduceable, absent of any dependency on factors external to the simulation. Variation is explicitly introduced usually through a random number generator, which can be seeded to produce the same sequence of numbers again and again. This means that the practice in real-world experiments of ``blocking'' to control external variation is not required in simulation experiments. However, \gls{replicate}s where the same combination of factor values is run several times each with a different random seed value, remain valuable, but in this case less to control for experimental error and more to record the variation across a series of runs and the sensitivity of the model to parameter settings.

\section{Contributions}\label{contributions}

This thesis makes the following novel contributions:

\begin{enumerate}
\item A model for the effect of selection pressure upon heritability, incorporating an exogenous property for fitness suggested by \textcite{Bourrat2015}.
\item A new and modular \gls{achem}, ToyWorld (\cref{ch:toyworld}), developed to facilitate experimental comparisons between \gls{achem} components, to a degree unusual in other experimental \glspl{achem} (\eg \cref{tab1}).
\item The evaluation of various reaction and product selection strategies in a molecular \gls{achem} (\cref{ch:toyworld}.)
\item A demonstration of the emergence of simple replicator forms from a molecular \gls{achem} (\cref{ch:multiplication,ch:variability}.)
\item An algorithm for reaction cycle detection based on sampling to generate a set of seed molecules \cref{alg:identify-cycles}.
\item An algorithm for the identification of exact multipliers from reaction cycles, based on a specific definition for exact multipliers as two or more copies of the same reaction cycle species, where the reaction cycle species has stoichiometry greater than one, and where each cycle in the multiplier is connected to at least one other multiplier cycle by a molecule that is a product of one cycle and a reactant in the other ()\cref{alg:discover-multipliers}.)
\item An algorithm for the identification of variable replicator candidates (without consideration of selection) from reaction cycles, where we define variable replicators as multipliers that can occupy any of a limited set of states without losing their underlying identity (\cref{alg:discover-variable-multipliers}.)
\end{enumerate}

A version of \cref{reactant-and-product-strategies} was published as \textcite{Young2015}, and material from \cref{model-validation} appears in \textcite{Young2013}.

The source code for all software developed for use in this work is available on GitHub under the GNU GPL v3 open source licence:
\begin{itemize}
	\item For ToyWorld, the \gls{achem} from \cref{ch:toyworld}, see \cite{toyworld}.
	\item For the updated version, ToyWorld2, used in the experiments in \cref{ch:multiplication,ch:variability}, see \cite{toyworld2}.
	\item Finally, the model source from \cref{ch:models-of-inheritance} is available at \url{http://github.com/th0mmeke/thesis-models}. 
\end{itemize}




