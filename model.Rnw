<<setup, include=FALSE>>=
library(knitr)
library(cowplot) # styling of plots, extension of ggplot2
library(gridExtra) # grid layouts for ggplot2
library(lattice) # needed for bwplot etc
library(english) # convert numbers to words
library(xtable) # required for print.xtable.bootabs function
opts_chunk$set(fig.path='generated_figures/')
knit_hooks$set(pdfcrop = hook_pdfcrop)

load.results.simple <- function(t) {
colClasses <- c("numeric","numeric","integer","integer","numeric","numeric","factor","factor","factor","factor","factor","factor","factor","factor")
read.csv(t, colClasses=colClasses)
}

load.results <- function(t) {
colClasses <- c("integer","integer","numeric","numeric","integer","integer","numeric","numeric","factor","factor","factor","factor","factor","factor","factor","factor")
df <- read.csv(t, colClasses=colClasses)
df$ecf <- factor(df$ecf,levels=c(0,1,5,10)) # place into natural order
df
}

# http://tex.stackexchange.com/questions/25575/how-can-i-use-a-table-generated-by-r-in-latex

print.xtable.booktabs <- function(x){

print(xtable(x),
floating=F,
hline.after=NULL,
add.to.row=list(pos=list(-1,0, nrow(x)),
command=c(
'\\toprule\n',
'\\midrule\n',
'\\bottomrule\n')))

}
@

\chapter{Models of inheritance}\label{models-of-inheritance}

This part of the work addresses our first research question: ``If we assume that for pragmatic reasons inheritance must itself be evolved from simple beginnings, rather than designed in, then what is the mechanism by which this might be achieved?"

\subsection{Previous work}\label{previous-work-p2}

Over the years a significant body of literature has accumulated on models of biological inheritance. While standard population genetics describes the dynamics over time of genotype frequencies, it remains deeply rooted in the biology of genotypes and alleles. Different forms of inheritance, such as acquired (or Lamarckian inheritance) characteristics have been compared and contrasted to the canonical non-acquired form in \gls{ens} by a number of authors (including for example \textcite{Jablonka1995, Paenke:2007ie,Gaucherel2012}), going back to the competing models for inheritance of Darwin and Lamarck. Early hypotheses in the metabolism-first or replicator-first debate led to the recognition of the significance of error threshold rates for mutations during copying \parencite{Eigen1971}, and later investigation of the interaction between inheritance (of genotypes, when non-acquired), selection (on the phenotype), and development (linking genotype to phenotype) inspired the theory of neutral landscapes \parencite{Kimura:1968uq}. 

In comparison, little explicit modelling of inheritance has been done in \gls{alife}. Most relevant work has already been reviewed in \cref{previous-work} where it generally forms one element of a wider investigation into \gls{oe}. However, in relation to \gls{ea}, many models for inheritance from variation and recombination have been proposed. These however are less relevant to our needs as they rely on exogenous, or external, predefined mechanisms rather than emerging from the properties of the genotypes. 

\Textcite{Paixao2015} sought common principles between population genetics and evolutionary computation with the goal of unifying the two fields, starting from a broad description of evolutionary processes as a ``population undergoing changes over time based on some set of transformations''. A transformation can be decomposed into a collection of (stochastic) operators, with an operator being a probability distribution of potential outcomes; some operators act on phenotypes, others on genotypes. Various operators drawn from evolutionary computing are defined: for selection (uniform, proportional, tournament, truncation, cut, replace); variation from mutation (uniform, single-point), and variation from recombination (one-point crossover, k-point crossover, uniform crossover, unbiased variation).

The evolutionary process is then a trajectory through a space of distributions; it can therefore be seen equally as a sequence of population transformations, and distribution transformations. When considered as a series of distribution transformations, \textcite{Paixao2015} sees a correspondence with Estimation Distribution Algorithms (EDA): ``In an Estimation Distribution Algorithm (EDA), the algorithm tries to determine the distribution of the solution features, e.g. probability of having a 1-bit at a particular position, at the optimum. Some EDAs can be regarded abstractions of evolutionary processes: instead of generating new solutions through variation and then selecting from these, EDAs use a more direct approach to refine the underlying probability distribution. The perspective of updating a probability distribution is similar to the Wright--Fisher model.''

\Textcite{Paixao2015} concludes by demonstrating how existing ``classical models in theoretical population genetics and in the theory of evolutionary computation'' can be mapped into the framework of classified and categorised operators. Most of the various population genetics models can be represented, with the exception of some topic-specific \gls{ea} models, while genetic programming models are omitted for reasons of balance between ``simplicity and inclusiveness.'' However, \textcite{Paixao2015} is of limited relevance for this work as it is in effect a constitutive framework, providing a series of tests to classify existing models based on a general meta-model of evolution, rather than a causative model which is where our interest lies. Variation, in the form of reproduction and mutation, is only one element of the framework, and \textcite{Paixao2015} does not specifically address the emergence of heredity from variation.

More specific models of inheritance and heredity can be found in three works comparing the adaptive value of acquired and non-acquired characteristics. In the first two works, \textcite{Jablonka1995,Paenke:2007ie}, the comparison is made with respect to an environment that alternates between two states, $E_0$ and $E_1$. Each environment is associated with a corresponding adapted phenotype $P_0$ and $P_1$, respectively.  In both works variation only affects the ratio of each phenotype in the population (directly in \textcite{Jablonka1995}, indirectly via a ``predisposition'' or tendency in \textcite{Paenke:2007ie}); no new phenotypes are created, and as inheritance is modelled only at a population level, that is without reproduction, we cannot use these models to investigate the emergence of heredity.

Inheritance however is modelled in \textcite{Gaucherel2012}, the third work, in relationship to individuals. Two models are presented, the first and simplest describing a non-spatial scenario conceptually similar to that in \textcite{Jablonka1995} and \textcite{Paenke:2007ie}, while the second examines a spatial world based on DaisyWorld \parencite{LovelockMargulis2011}. Focussing on the first and most relevant of the two models, reproduction is the middle of three repeated stages--first ``annihilation'' where the population size is adjusted to some practical level, then reproduction, and finally development. Concentrating on the second, reproduction, stage, individuals, represented by a single trait, or phenotype, value, are chosen for reproduction with some probability (based on the trait value), and the child given a trait value that slightly varies from the parent's value to model mutation (paraphrasing \textcite{Gaucherel2012}, $trait_{child} = trait_{parent} + \delta$, where $\delta$ is described as taken from a uniform distribution of given range around the parent's trait value. \footnote{although this appears to be an error and instead it should centred on $0$.})

The most relevant previous work is that of \textcite{Bourrat2015} who, in the course of examining the difference between evolution, natural selection and \gls{ens}, models the emergence of heredity in unchanging environments. \Textcite{Bourrat2015} demonstrates that imperfect inheritance is not compatible with \gls{ens} using an argument by contradiction \parencite[p.96]{Bourrat2015}: he lists the three conditions for a population to evolve solely by \gls{ens}, and then continues on to show that at least one of those conditions is incompatible with imperfect inheritance (as it happens, no production of new variants). The context is unequivocally related to biology; his examples involve genes, traits, phenotypes and drift.

The six applicable models in \textcite[chap.3]{Bourrat2015} are designed to explore the implications of bias on inheritance, where \emph{unbiased} means a trait is uncorrelated between child and parent, in practice it means that trait is taken as a random choice between some lower and upper bounds \parencite[p.153]{Bourrat2015}. \emph{Biased} inheritance is naturally the opposite: there is some correlation between parent and child values for a trait, and so some prediction of traits is possible--a parent can ``pass it on''. Note that \textcite[p.173]{Bourrat2015} expressly notes that his ``biased inheritance'' is not the ``transmission bias'' of the second term in the Price equation: ``The bias in ‘biased inheritance’ is in reference to the type of the parent(s) (biased toward the type of the parent), while the bias in ‘transmission bias’ refers to a departure from an event of perfect transmission.'' Bourrat unfortunately doesn't formalise his model descriptions; instead there is a reference \parencite[p.129]{Bourrat2015} to a NETLOGO 5.02 implementation, and textual narrative descriptions of each model and the results.

%\Textcite{Bourrat2015}
%\begin{itemize}
%\item Persistors - unable to reproduce, selection only in ``weak'' sense of granite grains for hardness
%\item Procreators can reproduce but without inheritance of any property (including ability to procreate) except ``fact of coming into existence and membership of that class'' (class is class of parents defined by ``those properties that do not vary in the population''...{[}acknowledged as loose, but has benefit that no varying traits included{]}) p137. Procreator's offspring is persistors
%\item Minimal reproducers - indefinite procreation - where procreation can be transmitted from parent to offspring (with some low degree of fidelity)
%\item Unreliable reproducers (low bias for ability to procreate- ability to procreate randomly chosen between 0 and parent's ability), reliable reproducers (high bias - ability to procreate is same as parent's ability)
%\item Replicator - all traits (including procreation) can be inherited
%\end{itemize}

Model 1 begins with a population of 5000 ``persistors'' (that is, entities without the ability to reproduce), each of which has a survival rate (viability or the likelihood of surviving at each time step) between 0 and 0.99. Unsurprisingly, all eventually die. Model 2 introduces a single ``procreator'', capable of reproduction with both survival and fertility rates (offspring per unit time), into the population of persistors. The traits of the offspring of the procreator are uncorrelated (that is, unbiased inheritance) to those of the procreator, and the model now consists of \emph{selection} $\rightarrow$ \emph{reproduction} $\rightarrow$ \emph{check-for-overcrowding} \parencite[p.141]{Bourrat2015} at each timestep. Again, all entities eventually die.

Model 3 begins to get interesting: \textcite{Bourrat2015} replaces the procreator by a ``minimal reproducer'' which differs from a procreator in that the ability to procreate is itself a heritable trait, although as ``minimal'' it is an unbiased trait. As such, the offspring of the minimal reproducer may be either minimal reproducers or persistors without the ability to reproduce. Now the population size drops then increases to maximum size with about 10\% of the population being minimal reproducers. However, the proportion of high fitness (that is, high viability) entities doesn't increase beyond about 0.05, so there is no cumulative adaptation.

Biased (in fact, perfect) inheritance of viability is introduced in Model 4; the offspring inherit the viability of their parent. The proportion of high fitness entities rapidly approaches the upper limit of $1.0$, as expected as high viability entities live longer and so produce more offspring while low viability entities die sooner and so produce less-- fertility random, but viability is heritable.

The most significant model is Model 5 which adds a variable ability to procreate to Model 4, while viability remains inherited with perfect fidelity from the parent. The variation is provided by the addition of a \emph{mutation} stage so that the model now consists of these stages at each timestep: \emph{mutation} $\rightarrow$ \emph{selection} $\rightarrow$ \emph{reproduction} $\rightarrow$ \emph{check-for-overcrowding} \parencite[p.153]{Bourrat2015}. At each mutation stage, there can be an increase or decrease in both the ability to transmit the ability to procreate, and in degree of bias (that is, relationship to parent's ability) in the ability to procreate. The first defines the proportion of offspring of the parent who are themselves able to procreate; a low trait value for the parent means a low proportion of siblings can procreate, while bias represents the correlation between the parent and offspring's abilities to transmit procreation--low bias means the offspring's ability is only weakly correlated with parents ability. The initial population contains entities with viability in the full range $[0,1)$, an ability to procreate in $[0,0.2)$ and initial bias of $0$. Both the ability to procreate and the bias \emph{increase} over time in the population towards the upper limit of $1.0$. The model is asymmetric with respect to the change of inheritance of ability to procreate: reductions lead to extinction of a line, while increases lead to increased population. Bourrat's conclusion is that an initial population of unreliable reproducers (a low proportion of procreating offspring, no bias) will evolve into one of reliable reproducers--that is, inheritance can emerge.

This is extended in the final Model 6, where Bourrat demonstrates the combination of inheritance of procreation with that of another trait, viability. The model begins with a population produced by the end of Model 5 - a set of entities that can reliably transmit the ability to procreate to their offspring. Using the same structure for trait inheritance as in Model 5, Model 6 shows that inheritance of viability or fitness can also emerge. In total then, the entities at the conclusion of Model 6 have full inheritance of multiple traits.

There are some limitations however in these otherwise insightful models. First, heredity and fitness (viability) are treated as independent traits. But the mechanism for heredity is the thing that copies the information that generates an offspring's traits, so in practice they are not independent.

Second, while Model 5 has perfect inheritance on viability and demonstrates emergent inheritance on procreation, Model 6 shows emergent inheritance on viability while beginning with perfect inheritance on procreation (as it begins with a shortcut population of entities assumed to have been produced by Model 5.) Thus Bourrat does not show in either model the simultaneous emergence of inheritance of both procreation and viability.

Finally, as seen by the trend of trait values towards the limit of $1.0$, the model assumes that the problem learnt by evolution is capable of perfect understanding, and that there is one and only one optimal solution. This is a corollary of the model design where fitness is absolute and unchanging--if fitness represents (as it does) an implicit relationship between an entity and its environment, then in Bourrat's model this relationship is also fixed and unchanging. Evolution is omniscient with full visibility into the world. However, in the real world and in the artificial domains of interest, the relationship between entity and environment is less sure. The environment itself may either change, or be uncertain. Under these conditions it is unlikely that values of $1.0$ would be possible, or indeed helpful, as a perfect bias value effectively is removing any source of variation from the population. This is unexplored by Bourrat.

The work of \textcite{Bourrat2015} partially addresses our second research question, with the following limitations:
\begin{itemize}
	\item Does not link heredity and fitness in the model.
	\item Does not show the simultaneous emergence of inheritance of procreation and viability.
	\item Most importantly, does not consider the effect of changing environments on inheritance.
\end{itemize}

\subsection{Simulation model of variation and inheritance}\label{base-model}

We now introduce a general model of the relationship between \emph{Variation}, \emph{Selection} and \emph{Inheritance} in a population of evolving abstract entities (\cref{base-model-algorithm}) where the key elements, such as fidelity and fitness, are represented as explicit parameters. This strategy of making otherwise derived variables explicit is also followed by Bourrat, who describes it as ``explaining variables which have previously been taken for granted in a model (such as reproduction and inheritance), by reference to other, more fundamental variables present in the model'' \parencite[p.129]{Bourrat2015}. Our model owes a direct debt to Bourrat in the representation of fidelity by an explicit parameter (related to the two parameters ``heredity of the ability to procreate'' and ''transmission of the ability to procreate'' in \textcite{Bourrat2015}). 

In other respects it resembles a fairly standard \gls{ea} (as briefly reviewed earlier in \cref{ea}). The model consists of a population of abstract entities, and two simple functions--\emph{Selection} and \emph{Variation}--that each take a population as input and output a transformed population. Each \gls{run} consists of a fixed number of time steps (generations), where at each step these two functions are applied in sequence to the current population to form a replacement population as documented in \cref{base-model-algorithm}. 

Let's look at each element in turn.

\begin{enumerate}
	\item \emph{Population} The population consists of $n$ entities, where $\lvert n\rvert\geq 0$.
	\item Each \emph{entity} is fully described by two properties -- \emph{fitness} and \emph{fidelity}.
	\item \emph{Fitness} represents the probability that an entity will survive and possibly also reproduce, and has the usual range for a probability of $[0,1]$.
	\item \emph{Fidelity} is the correlation between the child's and parent's values for a property. The range is $[0,1]$ where a value of $0$ means that the value for a child's property has no correlation with its parent's value for that property. High \emph{fidelity} values mean high correlation, and when $fidelity = 1.0$ the child's value is identical to the parent's.
	\item \emph{Selection} forms a new population by selecting entities from the current population, as defined in \cref{model-functions}. The probability of an element being included in the new population ($p_{selection}$ in the algorithm) may be either a fixed value, or equal to its \emph{fitness}. 
	\item The new population created by \emph{Variation} consists of a number of new entities (``children'') for each entity (``parent'') in the current population (see \cref{model-functions}). Each entity has children with probability $p_{reproduction}$, and if it does, the number of children it has is some random number between $0$ and $n_{children}$. The properties of each child are related to the properties of its parent by a mapping, represented in the algorithm by the function $Derive$, which maps the parent value to a value in a range with an expected value equal to the parent's value and some degree of correlation captured by the value of the function $Range$.
\end{enumerate}

The model is parameterised to make it easy to describe different specific models within this general structure; these parameters are defined in \cref{tbl:parameter_definitions}. In later chapters describing the series of experiments that use this model, these parameters will be mapped to experiment factors, with specific parameter values becoming factor levels.

\begin{table}
	\begin{center}
		\caption{Definitions for all parameters of the model}\label{tbl:parameter_definitions}
		\begin{tabular}{@{}llp{8cm}@{}}
			\toprule
			Parameter          	& Value                                	& Description\\
			\midrule
			$p_{reproduction}$ 	& $[0,1]$                               & Probability of reproduction\\
			$p_{selection}$   	& $[0,1]$                               & Probability of selection\\
			$n_{children}$     	& $n_{children}\in \mathbb{Z}_{\ge 0}$ 	& Maximum number of children per parent\\
			Reproduce           & $entity\mapsto entity$       			& Function to create a new entity based on an existing one\\
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}

\begin{algorithm}
	\For{each generation $\in [1\dots$number of generations]}{
		$population\leftarrow Selection(population)$\;
		$population\leftarrow population \cup Variation(population)$\;
		\BlankLine
		\lIf{$population$ size is too small}{break}
	}
	\caption{Algorithm for the inheritance and variation model}\label{base-model-algorithm}
\end{algorithm}

\begin{algorithm}
	\Def{Selection(population)}{
		$population_{new}\leftarrow \{\}$\;
		\For{each $entity \in population$} {
			\Prob($p_{selection}$:){
				Add $entity$ to $population_{new}$\;
			}
		}
		\Return $population_{new}$\;
	}
	\BlankLine
	\Def{Variation(population)}{
		$population_{new}\leftarrow \{\}$\;
		\For{each $entity$ with $fitness$ and $fidelity$ in $population$}{
			\BlankLine
			\Prob($p_{reproduction}$:){
				\For{some number of children $\in \mathcal{U}[0,n_{children}]$} {
					$child\leftarrow$ Reproduce($entity$)\;
					Add $child$ to $population_{new}$\;
				}
			}
		}
		\Return $population_{new}$\;
	}
	\caption{Definitions for the functions \emph{Selection} and \emph{Variation}}\label{model-functions}
\end{algorithm}

\subsection{Hypothesis}\label{h2}

Heredity describes the similarity of an offspring to its parent, and depending on the context, can refer to the correlation for either a single property or to a group of properties shared between offspring and parent. Heredity is related to variation: low variation implies high heredity and vice versa. There is a subtle difference between heredity and inheritance: inheritance is the process that results in heredity the measure (of correlation between entities in two generations.) As noted by \textcite{Griesemer2005}, ``[o]ne must clearly distinguish between heredity (a relation), heritability (a capacity), and inheritance (a process).'' 

For the single property case, when the correlation between the value for a parent's property and an offspring's property approaches an upper limit of $1.0$ we say we have complete or full inheritance. Conversely, if there is no correlation (at or near the lower limit of $0$) there is no inheritance and the entities are unrelated. We can extend the measure to a group of properties simply by taking the average of the individual correlations.

\Textcite{Bourrat2015} argues that heredity may in fact be a product of evolution rather than a precursor, or in other words, that the process of inheritance emerges from the action of selection and variation upon a population (\cref{previous-work-p2}.) In other words, \emph{variation and selection are sufficient for inheritance}.

The reasoning is as follows: heredity describes the correlation along a lineage, so a high fitness entity with high heredity is likely to have more high fitness descendants than low fitness descendents. Higher fitness entities will survive longer and reproduce more, and so high fitness/high heredity entities will slowly invade the population.

The degree of variation between generations is important; if there is no correlation it effectively means evolution is operating as an unguided, random, search while complete correlation means that each generation is a copy of the previous one, and there are no novelties. Interestingly, the optimal degree is unlikely to be fixed, but instead would be expected to vary depending on the predictability of the environment if we can extrapolate from the experiences of balancing exploration versus exploitation in \gls{ea} (\eg \cite{DeJong2006}.) The fundamental issue therefore is how to determine an appropriate degree of variation (or heredity) for each and all environments. We believe, and will show in the remainder of this \namecref{models-of-inheritance}, that an emergent inheritance mechanism can ``self-adjust'' to varying environmental conditions.

Our intuition is that the average fidelity of the population will be inversely related to the degree of environmental change. More specifically, if we consider evolution to be a means by which a population learns how to adapt to an environment, the degree of environmental change can be described as the degree to which it's possible to learn the environment. We intuit that this is related to predictability, and also to complexity. 

This seems a reasonable supposition. \textcite{Adami2002} recasts population fitness in terms of complexity, specifically his physical complexity measure: ``It is probably more appropriate to say that evolution increases the amount of information a population harbours about its niche (and therefore, its physical complexity)'' \textcite{Adami2002}. \textcite{Prokopenko2009} discusses the information-theoretic view of the benefits of complexity.

The initial hypothesis of \textcite{Bourrat2015} assumes a perfectly predictable environment that can be exactly ``learned'' by an evolutionary algorithm. If we assume that learnabilty is related to predictability, then we can restate and expand the hypothesis in terms of predictability:

\begin{hypothesis}
Variation and selection are sufficient for inheritance, where the degree and variance of inheritance is proportional to the predictability of the environment.
\end{hypothesis}\label{hypothesis-2} 

\section{Predictions}\label{predictions}

First we define the two distinct types of relationship between an entity and its environment--stable, and changing: 

A \emph{stable} environment is one where the relative fitness of a phenotype with respect to the environment is independent of time. This is similar to statistical stationarity: the phenotype's fitness is independent of when it is measured.  A \emph{changing} environment is therefore one in which the relative phenotypical fitness is time-dependent. In our model the environmental change only occurs between generations, and the phenotype of an entity remains constant over its lifespan. Only environmental changes can result in a fitness change: we do not model fitness changes as a result of processes that operate on a sub-generational timescale such as learning or development.

In a stable or unchanging environment our prediction is that:

\begin{enumerate}
\item Average inheritance will tend towards perfect inheritance,confirming a result of \textcite{Bourrat2015}.
\item The population variance of inheritance will decrease more than would be expected by chance alone.
\end{enumerate}

Our predictions for changing environments are:

\begin{enumerate}
	\item Fidelity is proportional to the predictability of the environment, that is at a minimum in conditions of maximum unpredictability, and at a maximum in stable conditions.
	\item The higher the variability in the environment, the higher the \gls{sd} of heredity. As a corollary, the \gls{sd} of heredity under changing conditions will be greater than that under stable conditions.
\end{enumerate}

\section[Model behaviour in stable conditions]{Experimental test of hypothesis under stable conditions}\label{experimental-test-of-h2-under-fixed-conditions}

Returning to the overall goals for these experiments, \cref{hypothesis-2} makes two predictions for stable environments:

\begin{enumerate}
	\item Average inheritance will tend towards perfect inheritance.
	\item The population variance of inheritance will decrease more than would be expected by chance alone.
\end{enumerate}

The first test therefore is to examine if inheritance emerges from low-fidelity and low-fitness initial conditions, and then the second test is whether the population variance for inheritance decreases as predicted. Remember that as discussed earlier, inheritance is the outcome of the relationship between parent and child traits, as represented by the measure of fidelity, and that fidelity ranges between $0$, for no correlation between parent and child, and $1.0$ for perfect correlation.

\subsection{Experimental design}\label{design}
<<pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
df_full <- subset(load.results('results/results-819350e-stable-environment.data'), truncate == 0 & correlation_correlation == 0) # correlation_correlation == 0 means TRUE in this dataset.
colnames(df_full)[13] <- "Distribution"
colnames(df_full)[14] <- "Reproduction"

df_full$n_offspring = factor(df_full$n_offspring, labels=c("2","5"))
df_full$p_reproduce = factor(df_full$p_reproduce, labels=c('Fitness','0.66'))
df_full$p_selection = factor(df_full$p_selection, labels=c('Fitness','0.66'))
df_full$Distribution = factor(df_full$Distribution, labels=c('Bounded','Sampled'))
#df_full$Reproduction <- factor(df_full$Reproduction, labels=c('Uncorrelated','Correlated'))

df <- subset(df_full, gen==500)
@

The factors and levels along with their mapping to model parameters are given in \cref{tbl:factor-levels-c7}. They closely follow those given in \cref{tbl:factor-levels-c6b} with the exception that  $p_{reproduction}$ and $p_{selection}$ only have one absolute level--$0.66$--instead of three. As the results in the previous \namecref{reducing-the-parameter-space-for-the-experiments} were qualitatively similar for all three, to reduce the number of experiment runs required only $0.66$ is included.

\begin{table}
	\caption{Factors mapped to model parameters, plus factor levels}\label{tbl:factor-levels-c7}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{2cm}p{6cm}@{}}
		\toprule
		Factor                 &Model parameter		&Number of Levels 	& Levels\\
		\midrule
		$p_{reproduction}$     &$p_{reproduction}$	&2                	& 0.66 or $fitness$\\
		$p_{selection}$        &$p_{selection}$		&2                	& 0.66 or $fitness$\\
		$n_{children}$         &$n_{children}$ 		&2                	& 2 or 5\\
		Reproduction		   &Reproduction		&1					& Correlated\\
		Distribution           &Reproduction		&2                	& Normal distribution ($\mathbb{N}$), either sampled or folded\\
		\bottomrule
	\end{tabular}
\end{table}

Each combination of factor levels has 10 replicates, to give a total of $2x2x2x1x2x10$ or 160 experiment runs.

\subsection{Sensitivity of the model to parameter values}\label{reducing-the-parameter-space-for-the-experiments}

In the absence of any restrictions on population size there is nothing to prevent a growing population eventually exceeding the capacity of the simulation system. This is unfortunately an unavoidable difficulty in experiments with exponential growth systems rather than a limitation of the theoretical model. 

The size of the population is determined by how population entities are introduced and removed. In standard Evolutionary Computation (\eg \textcite[50]{DeJong2006}) the choice of strategy is important to the performance and outcomes of the algorithm. New entities can be straight replacements, like-for-like, of their parent, or be placed in competition against entities in the parent population, or completely replace the parent population. Elements may be removed as a result of selection, or through fitness-independent sampling to maintain a particular population size, or through some end-of-life calculation. The population size limit may act as both upper and lower bound on population size to maintain a specific size, or solely as upper bound.

In \textcite{Gaucherel2012} the approach is to remove individuals from the population stochastically, with probability related to $e$ to the negative power of the population size multiplied by a configurable parameter, $\mu$. In the ``canonical'' Evolutionary Computation algorithm, a population limit results from selection where a set number of entities are extracted from the original population, chosen by one of a wide range of selection algorithms (among many sources, see overviews in \textcite[sect. 4.3.1]{DeJong2006} and \textcite[sect. 4.2]{Vose:1999di}.) Here though we separate the selection function from the population size limit in order to qualify the effect of the specific limiting mechanism used.

Translating model parameters into factors in the experiment design results in the factors in the first column of \cref{tbl:factor-levels-c7}. As is usual with exploratory experiments with a number of parameters, where each run of the model has some cost in time or other resources, the key problem is to understand the relationship between parameters and response variables at an acceptable cost. In this case, our main cost is time - each run of an evolutionary model is cheap in resources but takes a little time. Exhaustively sampling the entire parameter space is unrealistic. Therefore, we first reduce the search space by limiting the number of values that each parameter can take. By choosing these values appropriately, we can construct an analysis model from the results that is sufficiently accurate for our exploratory purposes at a greatly reduced cost in time.

The values of \emph{Distribution} and \emph{Reproduction} have a significant effect on $\overline{fidelity}_{end}$, while $\overline{fitness}_{end}$ is responsive to all parameter values with the exception of $n_{offspring}$. Therefore we can conclude that the model is sensitive to all parameters with the probable exception (see earlier discussion) of $n_{offspring}$, and that the response is driven by the values of \emph{Distribution} and \emph{Reproduction} and by the boundary between absolute and relative values for $p_{reproduction}$ and $p_{selection}$. This suggests that the sensitivity of the simulation model can in fact be described in simpler terms related to combinations of related values of these key drivers. As one example, models where \emph{Distribution} takes ``uniform'' form a single class of their own as the other factor levels are completely overridden by this level of this factor.

This has the following implications:

\begin{itemize}
	\item All claims resulting from the simulation model must be prefixed by a description of the particular parameter settings under which the claim applies.
	\item The model's response can be clustered according to the values of the key drivers, \emph{Distribution}, \emph{Reproduction}, $p_{reproduction}$ and $p_{selection}$.
\end{itemize}

The factor levels used in this analysis, as mentioned earlier, include some values and combinations of values that are unlikely in practice, although they are still valuable in establishing the overall scope of the model. For example, all models where \emph{Reproduction} takes the value ``uncorrelated'' are, as described earlier, un-evolutionary and so of secondary interest in a work on evolutionary theory, as are models where \emph{Distribution} is ``uniform'' and models where $p_{selection}$ takes an absolute value. Eliminating these factor levels from the experiment leaves the following factors and levels, the basis for all remaining experiments:

\begin{table}
	\caption{Factors mapped to model parameters, plus factor levels}\label{tbl:factor-levels-c6b}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{2cm}p{6cm}@{}}
		\toprule
		Factor                 &Model parameter		&Number of Levels 	& Levels\\
		\midrule
		$p_{reproduction}$     &$p_{reproduction}$	&4                	& 0.33 or 0.66 or 1.0 or $fitness$\\
		$p_{selection}$        &$p_{selection}$		&1                	& $fitness$\\
		$n_{children}$         &$n_{children}$ 		&2                	& 2 or 5\\
		Reproduction		   &Reproduction		&1					& Correlated\\
		Distribution           &Reproduction		&2                	& Normal distribution ($\mathbb{N}$), either sampled or folded\\
		\bottomrule
	\end{tabular}
\end{table}

Finally, from the discussion around the effect of $p_{reproduction}$, these factors and levels can be clustered into only two intra-related groups: group one where $p_{reproduction}$ takes the level ``$fitness$'' and group two where it takes any of the remaining, absolute, levels.

\subsection{Does average inheritance approach perfect inheritance?}\label{does-average-inheritance-approach-perfect-inheritance}

We start with the following null and alternative hypotheses:

\begin{itemize}[label={}]
	\item H$_0$: fidelity does not approach 1.0 during a run, irrespective of factor values, or \newline
 $\vert \overline{fidelity}_{end}-\overline{fidelity}_{start} \vert = 0$
	\item H$_1$: fidelity increases to near 1.0 during a run, for some factor values, or \newline
 $\overline{fidelity}_{end}-\overline{fidelity}_{start} > 0$ and $1.0-\overline{fidelity}_{end} < \delta$ for some $\delta$ and for some factor values.
\end{itemize}

\subsubsection{Response variables}

From the hypothesis the main property of interest is \emph{fidelity}, or the correlation between parent and child property values. \emph{Fidelity} therefore is our response variable. Specifically we require $\overline{fidelity}_{start}$ and $\overline{fidelity}_{end}$, or the mean value for \emph{fidelity} (across all replicates) at the beginning and end of each run.

\subsubsection{Results and discussion}

%df <- subset(load.results.simple('results/results-53f6b74.data'), environment_change_frequency == 0 & truncate==0)
%<<popoverall, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Not all runs in stable environments can maintain a substantial population size over time. The horizontal line at the top of the figure is from runs that were capped by the population upper-bound. The extreme case represented by the almost vertical set of points to the far left followed by steady increases is discussed in the text.'>>=
%ggplot(df_full) + geom_point(aes(x=gen,y=pop),size=0.25) + labs(x="Generation", y="Population size")
%@

% \Sexpr{nrow(subset(df_full, gen==max(df_full['gen'])))}
Of the \Sexpr{nrow(subset(df_full,gen==0))} experiment runs, all reached the experiment limit of \Sexpr{max(df_full['gen'])} generations. 

Our interest is in the final values for fidelity under fixed-environment conditions. Therefore, the data in the following analysis is from the final generation of each run, unless otherwise noted.

<<lowstart, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Summary results, showing on the left-hand side an overview for the final mean fidelity ($\\overline{fidelity}_{end}$) for each run and a density plot showing the distribution of $\\overline{fidelity}_{end}$. The right-hand side shows the corresponding plots for final mean fitness ($\\overline{fitness}_{end}$)'>>=
ap <- qplot(row.names(df),ave_cor, geom="point", data=df, xlab='Experiment run',ylab="Final mean fidelity") + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank())
bp <- qplot(row.names(df),ave_fit, geom="point", data=df, xlab='Experiment run',ylab="Final mean fitness") + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank())
cp <- qplot(ave_cor, geom="density", data=df, xlab="Final mean fidelity",ylab="")
dp <- qplot(ave_fit, geom="density", data=df, xlab="Final mean fitness",ylab="")
grid.arrange(ap,bp,cp,dp,nrow=2,ncol=2)
@

<<lowstartbyfactor, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Summary results, this time averaged across all replicates of each unique combination of factor levels (that is, grouped by factor level). Dark-coloured points represent values at end of run; light-coloured points in a horizontal line are for initial values, reflecting averaged initial conditions.'>>=
ap <- ggplot(subset(df_full,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=ave_cor, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='Factor combination', y='Mean fidelity') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
bp <- ggplot(subset(df_full,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=ave_fit, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='Factor combination', y='Mean fitness') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
cp <- ggplot(subset(df_full,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=sd_cor, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='', y='Standard deviation of fidelity') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
dp <- ggplot(subset(df_full,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=sd_fit, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='', y='Standard deviation of fitness') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
grid.arrange(ap,bp,cp,dp,nrow=2,ncol=2)
@

<<mean-fidelity-fitness, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Ranges by generation of the mean fidelity (top) and mean fitness (bottom) for all levels of all factors.'>>=
ap <- ggplot(df_full) + geom_line(aes(x=gen,y=ave_cor,group=run)) + labs(x="Generation", y="Mean fidelity")
bp <- ggplot(df_full) + geom_line(aes(x=gen,y=ave_fit,group=run)) + labs(x="Generation", y="Mean fitness")
grid.arrange(ap,bp,nrow=2,ncol=1)
@

The first hypothesis prediction is that average fidelity will tend towards exact inheritance, or $1.0$. A simple visual inspection of this data in \cref{fig:lowstart} reveals that the fidelity measure has a strong peak as predicted at $1.0$, with final mean fidelity greater than approximately $0.96$ for all remaining runs. Fitness is bimodal, with peaks around final mean fitness values of approximately $0.45-0.55$ and $1.0$. From \cref{fig:lowstartbyfactor,fig:mean-fidelity-fitness} it seems that the initial peak in fitness is associated with a subset of factor-levels. Closer examination shows that these runs, and only these runs, have the level $0.66$ for both factors $p_{reproduction}$ and $p_{selection}$. This supports the earlier observation in \cref{reducing-the-parameter-space-for-the-experiments} concerning the importance of the distinction between absolute and relative (\eg fitness-based) values for these two factors.

From inspection it seems clear that fidelity does approach $1.0$ as predicted by the hypothesis. In conclusion, H$_0$ can be rejected, and H$_1$ accepted. Inheritance increases regardless of the model design.

\subsection{Does the variance of inheritance decrease over time in the population?}\label{variance-of-inheritance-stable}

The second prediction of the hypothesis is that the population variance for inheritance ($\sigma_{fidelity}$) should decrease over time towards a limit of $0$ in fixed environments.

\begin{itemize}[label={}]
	\item H$_0$: $\sigma_{fidelity_{end}}-\sigma_{fidelity_{start}} >= 0$, for all factor values.
	\item H$_1$: $\sigma_{fidelity_{end}}-\sigma_{fidelity_{start}} < 0$, for some factor values.
\end{itemize}

\subsubsection{Response variables}

Once again, the main property of interest, and so our response variable, is \emph{fidelity}. From the hypothesis we require $\sigma_{fidelity_{end}}$ and $\sigma_{fidelity_{start}}$, the standard deviation of fidelity at the beginning of each run, and at the end.

\subsubsection{Results and discussion}
<<sd-fidelity-fitness, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Ranges by generation of the standard deviation of fidelity on the top row, and standard deviation of fitness below.'>>=
ap <- ggplot(df_full) + geom_line(aes(x=gen,y=sd_cor,group=run)) + labs(x="Generation", y="Standard deviation of fidelity")
bp <- ggplot(df_full) + geom_line(aes(x=gen,y=sd_fit,group=run)) + labs(x="Generation", y="Standard deviation of fitness")
grid.arrange(ap,bp,nrow=2,ncol=1)
@

Data is all generations for those fixed-environment runs that reached completion at generation \Sexpr{max(df['gen'])}; \Sexpr{nrow(unique(df['run']))} runs out of the full dataset of \Sexpr{nrow(unique(df_full['run']))} runs.

In a similar fashion to the procedure in \cref{does-average-inheritance-approach-perfect-inheritance}, by visual inspection of \cref{fig:sd-fidelity-fitness}, the variance (square of the standard deviation) does decrease towards zero in all cases. Once again, the runs appear to fall into two distinct groups based on the speed of convergence towards zero, as seen in \cref{fig:sd-fidelity-fitness}. The upper group is exclusively associated with runs where both factors $p_{reproduction}$ and $p_{selection}$ are set to $0.66$; these levels are also responsible for the two uppermost groups of final standard deviation of fitness in the lower section of \cref{fig:sd-fidelity-fitness}. The distinction between these two uppermost groups however is due to a third factor, \emph{Distribution}: the uppermost group has level ``Bounded'' and the lowermost (or the middle group of the three) has level ``Sampled.''

In conclusion, from visual inspection, the variance of fidelity does approach $0$, for all combinations of factor levels except where both $p_{reproduction}$ and $p_{selection}$ are set to $0.66$. Therefore H$_0$ is rejected and H$_1$ accepted.

\section{Model behaviour in changing environments}\label{model-behaviour-in-changing-environments}

In this chapter we describe an appropriate experimental design and model to describe environmental changes; test the predictions of \cref{hypothesis-2} using the model; and finally discuss the results of the experiment. The conceptual basis for these steps is shown in \cref{fig:conceptual-model-for-environmental-change}. 

\begin{figure}
	\begin{center}
	\resizebox{0.8\textwidth}{!}{
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm, font=\sffamily\Large\bfseries, thick,
		main node/.style={circle,fill=blue!20,draw, align=center,text width=4cm,minimum size=15mm}]
		\node[main node] (evo) at (0,10) {Evolutionary model};
		\node[main node] (env) at (0,0) {Environmental model};
		\node[main node] (pop) at (6,10) {Population};
		\node[main node] (ts) at (6,0) {Time series of fitness changes};
		\node[main node] (r1) at (12,10) {Metrics};
		\node[main node] (r2) at (12,0) {Metrics};
		\node[main node] (test) at (12,5) {Hypothesis test};
		\node at (4,14) {Simulation};
		
		\path[every node/.style={font=\sffamily,fill=white,inner sep=1pt}]
		(env) edge [->] (ts)
		(evo) edge [->] (pop)
		(pop) edge [->] (r1)
		(ts) edge [->] node[text width=2.5cm,right,xshift=5pt]{Apply at each generation} (pop)
		(r1) edge [->] (test)
		(r2) edge [->] (test)
		(ts) edge [->] (r2);
		\draw [every node] (3,13) rectangle (9,-3);
		\end{tikzpicture}
	}
	\caption{Conceptual model for experiments incorporating environmental change}
	\label{fig:conceptual-model-for-environmental-change}
	\end{center}
\end{figure}

\subsection{Environmental model}\label{environmental-model}

Alongside the evolutionary model from \cref{base-model} we now add an environmental model to describe the changing fitness relationship between entities and the environment at each step of the evolutionary model. 

What does it mean in the context of this hypothesis for an environment to be ``predictable''? \Textcite{Jablonka1995} and \textcite{Paenke:2007ie} share a simple model for environmental change, with abrupt switches between two defined environments, with the time between switches either being fixed or stochastic according to some probability. \Textcite{Gaucherel2012} also describes a single model for environmental change--a period of ``smooth'' change (either according to a form of $sine$ curve or unchanging) followed by an abrupt change, repeated--with variation in the length and degree of each period. By contrast, \textcite[79]{Schuster2011}, when describing the relationship between fitness landscapes and error thresholds, details five distinct models of change: ``(i) the single-peak landscape corresponding to a mean field approximation, (ii) the hyperbolic landscape, (iii) the step-linear landscape, (iv) the multiplicative landscape, and (v) the additive or linear landscape.''

Returning to first principles, any model must describe two particular elements of the environmental change: the \emph{scope} of the change, and the \emph{shape} of the change. First, we discuss the \emph{scope} of change. Our evolutionary model (\cref{base-model}) provides the scope to group entities at three different levels:
\begin{enumerate}
	\item The group of all entities.
	\item A group for each set of ``related'' entities, where the most natural and obvious relation is that between parent and child; this is unambiguous and straightforward in our model where each entity has only one parent. We refer to a group of entities related by inheritance as a \emph{lineage}.
	\item A single-member group for each entity.
\end{enumerate}

In this work environmental changes may be applied to either of the first two of these three levels, with a consistent level applying throughout a run; the first level because it is the simplest application of environmental change, and the second as it represents the familiar scenario where we expect similar entities to react in similar ways to change, and where similarity is a result of descent: entities that share a common ancestor are more similar to each other than they are to other lineages. We do not address the third possibility in this work as it implies that each entity has a unique response to environmental changes. This seems problematic; environmental response is a function of phenotypes, and we would expect related entities to have related phenotypes\footnote{In general, although biological mutations of the genome can sometimes cause significant phenotypical differences between related entities.}. Thus instead of single-member groups we would expect lineage-related groups, or in other words, the second level.

The \emph{shape} of change is less constrained, and the space of all potential changes at any timestep effectively limitless: in fact, the potential change $\delta$ at timestep $t$ is $\delta_t\in R$. Simply taking a random sample from this space at each step is unlikely to result in enough resolution to test any relevant hypothesis. At the other extreme, taking only a small number of predetermined changes is likely to lead to a sampling fallacy where the choices bias the conclusions.

Instead, we need a way to parameterise the set of interesting environmental changes so we can sample from a constrained but not predetermined parameter space. The range covered by the parameter space should include both predictable and unpredictable changes as the difference between the two is core to our hypothesis.

Our chosen method is to represent environmental change as a parameterised time-series\footnote{A \emph{time series} is a set of observations $x_i$, each one being recorded at a specific time $t$ \textcite{Brockwell:2002dq} where an observation $x_i \in$ some set $\{X\}$, assumed to be $\mathbb{R}$.} of particular form. Statistical techniques are commonplace for time-series predictions \textcite{Brockwell:2002dq}. ARMA models are used for \emph{stationary} series, that is a time-series whose joint probability distribution (and hence whose statistical properties such as mean and variance) do not change over time, equivalent to saying the series does not demonstrate concept drift. ARIMA models apply for non-stationary series where the difference between two sequential values of the original series can be shown to produce a stationary series. The I or ``Integrated'' component of the model provides the differencing. Seasonality, a particular form of recurring concept drift, may be modelled with both ARMA and ARIMA models by incorporating a seasonality component in the model (\eg \cite{Brockwell:2002dq}.)

Although time-series modelling provides techniques for describing time-series data in terms of an underlying model, the process can also be reversed to produce a time-series from the model; in other words, if the variety of environmental change required to test our hypothesis can be described by a standard time-series model, the parameters that determine that model can also serve as our summary measure for environmental change.

Environmental change is modelled as an enhanced AR(1) or first-order autoregressive time-series, with each timestep corresponding to one evolutionary generation. Specifically, we can describe the evolutionary change at each timestep as a function of the previous timestep:

$x_t = \Theta x_{t-1} + e_t + \delta$ \label{ar-1-time-series}

where $x_t$ is the change at timestep $t$, $\Theta$ is the AR coefficient, $e_t$ is a random, normally distributed, error component around a mean of $0$, where $e_t\stackrel{iid}{\sim}N(0,\sigma^{2}_e)$, and $\delta$ is a fixed bias value.

This series allows us to represent a broad range of environmental changes:

\begin{itemize}
	\item Each time-series is completely specified by three parameters, $\Theta$, $\sigma_e$ and $\delta$.
	\item $\Theta$ in an autoregressive time-series can be interpreted as specifying stability or smoothness, while $\delta$ is a fixed change. We use $\delta$ to model a fitness trend - environments with a positive $\delta$ will see the fitness of each entity improved at each generation, with the opposite of course true of negative $\delta$. Note that with this formulation we can model linear trends in fitness from a fixed bias in the environment produced by the $\delta$ term. This is not the same as a ARI model where the environment time-series itself would show a trend.
	\item The time-series is defined by three independent elements, two predictable (driven by $\Theta$ and $\delta$) and the other ($\sigma_e$) random and unlearnable. By changing the ratio between the predictable and unpredictable we can examine the performance of the evolutionary algorithm on some continuum of predictability.
	\item An AR time-series has the property of stationarity, with the implication that the mean of the series is constant through time. However, as we apply the series values as deltas to element fitness, fitness can be non-stationary, and so may show a long term trend. This allows a simple non-differencing time-series to describe a steady improvement, or worsening, in fitness.
	\item As a corollary of stationarity, the range of the series is determined by the initial parameters. This is a useful property as it means that with appropriate parameter choices no scaling of the range is required. 
\end{itemize}

We claim that, for an environmental model defined according to \cref{ar-1-time-series}, the combination of $\Theta$, $\sigma_e$ and $\delta$ provides one measure of \emph{environmental predictability}.

<<factorialthetasigma, pdfcrop=TRUE, echo=FALSE, warning=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Visualisation of the fitness changes at each time interval (top facet) and cumulative fitness change (bottom facet) that result from our environmental model for delta=0 with two values of sigma (left and right), and three values of theta (each facet row.)'>>=
library(reshape2)
library(ggplot2)
library(cowplot) # styling of plots, extension of ggplot2
library(gridExtra)

t1 <- read.csv('results/environments-factorial.csv', header=FALSE, colClasses=c("numeric","numeric","numeric"))

t1$run <- 1:nrow(t1)
names(t1)[1:3]<-c("theta", "sigma", "delta")
t2 <- melt(t1,id=c('run','theta','sigma','delta'))
t2$theta <- round(t2$theta,3)
t2$sigma <- round(t2$sigma,3)
t2$delta <- round(t2$delta,3)

for (r in unique(t2$run)) {
t2[t2$run==r,'t'] <- 1:50 # tag with timestamp

fitness <- 0.5
for (t in 1:50) {
fitness <- max(0,min(1,fitness + t2[t2$run==r & t2$t==t,'value']))
t2[t2$run==r & t2$t==t,'fitness'] = fitness
}
}
ap <- ggplot(subset(t2,delta==0)) + geom_line(aes(x=as.numeric(variable),y=value)) + facet_grid(theta~sigma, labeller='label_both') + labs(x="t", y="Fitness change")
bp <- ggplot(subset(t2,delta==0)) + geom_line(aes(x=t,y=fitness)) + facet_grid(theta~sigma, labeller='label_both') + labs(x="t", y="Fitness change")
grid.arrange(ap,bp,nrow=2,ncol=1)
@

<<factorialsigmadelta, pdfcrop=TRUE, echo=FALSE, warning=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Visualisation of the fitness changes at each time interval (top facet) and cumulative fitness change (bottom facet) for theta=0 with three values of delta (columns), and two values of sigma (each facet row.)'>>=
ap <- ggplot(subset(t2,theta==0)) + geom_line(aes(x=as.numeric(variable),y=value)) + facet_grid(sigma~delta, labeller='label_both') + labs(x="t", y="Fitness change")
bp <- ggplot(subset(t2,theta==0)) + geom_line(aes(x=t,y=fitness)) + facet_grid(sigma~delta, labeller='label_both') + labs(x="t", y="Fitness change")
grid.arrange(ap,bp,nrow=2,ncol=1)
@

<<sampleenvironment, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Example time-series produced by our environmental model for a sample of theta, sigma and delta values. These are incremental fitness changes, rather than cumulative ones.'>>=
t1 <- read.csv('results/environments.csv', header=FALSE, colClasses=c("numeric","numeric","numeric"))
t1$run <- 1:nrow(t1)
names(t1)[1:3]<-c("theta", "sigma", "delta")
t2 <- melt(t1,id=c('run','theta','sigma','delta'))
t2$theta <- round(t2$theta,3)
t2$sigma <- round(t2$sigma,3)
t2$delta <- round(t2$delta,3)
ggplot(t2) + geom_line(aes(x=as.numeric(variable),y=value)) + facet_wrap(~theta+sigma+delta, labeller='label_both') + labs(x="t", y="Fitness change")
@

% Needs sampleenvironment
<<cumulativefitness, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.scap=NA, fig.cap='Cumulative time-series examples for samples of theta, sigma and delta.'>>=
for (r in unique(t2$run)) {
t2[t2$run==r,'t'] <- 1:50 # tag with timestamp

fitness <- 0.5
for (t in 1:50) {
fitness <- max(0,min(1,fitness + t2[t2$run==r & t2$t==t,'value']))
t2[t2$run==r & t2$t==t,'fitness'] = fitness
}
}

ggplot(t2) + geom_line(aes(x=t,y=fitness)) + facet_wrap(~theta+sigma+delta, labeller='label_both') + theme(strip.text.x = element_text(size = 6))
@

%% Needs sampleenvironment
%<<sampleentropy, pdfcrop=TRUE, echo=FALSE, warning=FALSE, cache=TRUE, fig.pos='htp', fig.scap=NA, fig.cap='Approximate entropy of each example environment.'>>=
%library(pracma)
%library(ggplot2)
%library(cowplot) # styling of plots, extension of ggplot2
%
%t2 <- t1[,1:3]
%names(t2)[1]<-"theta"
%names(t2)[2]<-"sd"
%names(t2)[3]<-"delta"
%for(n in 1:nrow(t1)) {t2[n,'sample_entropy'] <- sample_entropy(unlist(t1[n,4:52],use.names=FALSE))}
%for(n in 1:nrow(t1)) {t2[n,'approx_entropy'] <- approx_entropy(unlist(t1[n,4:52],use.names=FALSE))}
%
%#summary(lm(sample_entropy~theta+sd,data=t2)) # can error as some sample_entropy values may be Inf
%ggplot(t2, aes(sd,approx_entropy)) + geom_point() + geom_smooth(method='lm') # formula not required
%
%#summary(lm(approx_entropy~theta + sd, data = t2)) #  SIGNIFICANT
%@

\subsection{Experimental design}

\Cref{hypothesis-2} makes these predictions for changing environments:

\begin{enumerate}
	\item Fidelity is proportional to the predictability of the environment, that is at a minimum in conditions of maximum unpredictability, and at a maximum in stable conditions.
	\item The higher the variability in the environment, the higher the \gls{sd} of heredity. As a corollary, the \gls{sd} of heredity under changing conditions will be greater than that under stable conditions.
\end{enumerate}

As all three independent variables for our experiment, $\Theta$, $\sigma_e$ and $\delta$, are continuous in $\mathbb{R}$, and as we wish to test the specific relationship of fidelity across a range of these variables without being restricted to the initial choice of fixed levels, we shift from the fixed-effect factorial designs used earlier to a random effects model \parencite[chap.13]{Montgomery2009}. The independent variables in each run are the parameters to the environmental model, with values taken from a uniform random sample from their range. Or in other words, a series of random samples with uniform probability from a cube formed by a parameter on each of the three axes (see \cref{fig:cube}.)

\begin{figure}
	\begin{center}
	\resizebox{0.8\textwidth}{!}{
		\begin{tikzpicture}[>=stealth',shorten >=1pt,auto,node distance=3cm, thick,font=\LARGE]
		\draw (-4,3) rectangle (4,-5);
		\draw (-4,3) -- (-1,6) -- (7,6) -- (7,-2) -- (4,-5);
		\draw (7,6) -- (4,3) ;
		\draw [dashed] (-1,6) -- (-1,-2) -- (7,-2);
		\draw [dashed] (-1,-2) -- (-4,-5);
		\draw [densely dotted] (1,-5) -- (2,-4) -- (5,-4);
		\draw [densely dotted] (2,-4) -- (2,1.5) node[above] {$\Theta,\delta,\sigma_e$} ;
		\node at (-5,-1) {$\delta$};
		\node at (0,-6) {$\Theta$};
		\node at (6.5,-4) {$\sigma_e$};
		\end{tikzpicture}
	}
	\caption{The cube formed by the ranges of the three parameters to the environmental model, $\Theta$, $\sigma_e$ and $\delta$.}
	\label{fig:cube}
	\end{center}
\end{figure}

We create a set of independent datasets by sampling from different four parameter cubes, as defined in \cref{tbl:range-of-independent-variables}. The extremes of the ranges see a lower proportion of the runs (representing more significant environmental changes or more rapid changes) reach completion than was seen in the centre (where the environment was stable.) The range of each variable (the length of a cube side) is adjusted from dataset to dataset to balance an adequate density of coverage across the overall range against the total run time.

\begin{table}
	\begin{center}
		\caption{Range of independent variables $\Theta$, $\sigma_e$ and $\delta$}
		\label{tbl:range-of-independent-variables}
		\begin{tabular}{@{}llll@{}}
			\toprule
			Dataset   	 	&  $\Theta$		& $\sigma_e$	& $\delta$\\
			\midrule
			Dataset no.1	& $[-0.4, 0.4]$	& $[0, 0.2]$ 	& $[-0.1, 0.1]$\\
			Dataset no.2	& $[-0.2, 0.2]$	& $[0, 0.1]$	& $[-0.05, 0.05]$\\
			Dataset no.3	& $[-0.2, 0.2]$	& $[0, 0.1]$	& $[-0.05, 0.05]$\\
			Dataset no.4	& $[-0.4, 0.4]$	& $[0, 0.4]$	& $[-0.04, 0.04]$\\
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}

The other factors and levels along with their mapping to model parameters are given in \cref{tbl:factor-levels-c8}. Once again, they are based on those in \cref{tbl:factor-levels-c6b} and identical to those in \cref{tbl:factor-levels-c7}.

\begin{table}
	\caption{Factors mapped to model parameters, plus factor levels}\label{tbl:factor-levels-c8}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{2cm}p{6cm}@{}}
		\toprule
		Factor                 &Model parameter		&Number of Levels 	& Levels\\
		\midrule
		$p_{reproduction}$     &$p_{reproduction}$	&2                	& 0.66 or $fitness$\\
		$p_{selection}$        &$p_{selection}$		&2                	& 0.66 or $fitness$\\
		$n_{children}$         &$n_{children}$ 		&2                	& 2 or 5\\
		Reproduction		   &Reproduction		&2				 	& Correlated and Uncorrelated\\
		Distribution           &--					&2                	& Folded normal distribution or sampled normal distribution\\
		\bottomrule
	\end{tabular}
\end{table}

Finally, the dependent or response variables, driven by the hypothesis predictions, are mean population fidelity and mean population fitness.

%\begin{table}\label{reproduction-distribution-factors-c8}
%	\caption{Levels for the factor \emph{Reproduction}}
%	\begin{tabular}{@{}p{2.5cm}p{3cm}p{7cm}@{}}
%		\toprule
%		Reproduction&Child entity parameter					&Distribution shape\\
%		\midrule
%		\multirow{2}{*}{Correlated}		&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
%										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=1-fidelity$\\
%		
%		\multirow{2}{*}{Uncorrelated}	&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
%										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=\mathcal{U}[0, 1.0]$\\
%		\bottomrule
%	\end{tabular}
%\end{table}


\subsection{Results}

<<figure23, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.scap=NA, fig.cap='Final mean fidelity against the environmental model\'s sigma parameter (top), delta parameter (middle) and theta parameter (bottom) for all experimental runs.'>>=
# BY_LINEAGE	CORRELATED	N_OFFSPRING	P_REPRODUCE	P_SELECTION	RESTRICTION	delta	sigma	theta	ave_fid	ave_fit	experiment	gen	pop	run	sd_fid	sd_fit
colClasses <- c("factor","factor","factor","factor","factor","factor","numeric","numeric","numeric","numeric","numeric","factor","integer","numeric","integer","numeric","numeric")
r1 <- read.csv('results/results-0c267bcd2-a.csv', colClasses=colClasses)
r2 <- read.csv('results/results-0c267bcd2-b.csv', colClasses=colClasses)
r3 <- read.csv('results/results-cc648a0a9.csv', colClasses=colClasses)
r4 <- read.csv('results/results-996060f.csv', colClasses=colClasses)
results = rbind(r1,r2,r3,r4)
colnames(results)[c(7,8,9)] <- c("delta","sigma","theta")

results$BY_LINEAGE = factor(results$BY_LINEAGE, labels=c("By Population","By Lineage"))

ap <- ggplot(subset(results,gen==500)) + geom_point(aes(sigma,ave_fid)) + labs(x='sigma parameter to environmental model', y='Final mean fidelity')
bp <- ggplot(subset(results,gen==500)) + geom_point(aes(delta,ave_fid)) + labs(x='delta parameter to environmental model', y='Final mean fidelity') 
cp <- ggplot(subset(results,gen==500)) + geom_point(aes(theta,ave_fid)) + labs(x='theta parameter to environmental model', y='Final mean fidelity')
grid.arrange(ap,bp,cp,nrow=3,ncol=1)

#anova(lm(ave_fid ~ theta*sigma*delta, data=subset(results,gen==500))) # theta not significant
#anova(lm(ave_fid ~ sigma*delta, data=subset(results,gen==500))) # bias and sd:bias most important, then sd
#anova(lm(sd_fid ~ sigma*delta, data=subset(results,gen==500 & -0.001<delta & delta<0.001))) # Remove effect of bias, then sigma 0.001
@

<<figure22, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.scap=NA, fig.cap='Distribution of maximum generation reached for all runs for dataset no.1 (top) through dataset no.4 (bottom). Axes are to the same scale. Runs (along the x-axis) are ordered by final generation reached.'>>=
t1 <- aggregate(r1$gen,by=list(r1$run),max)
t2 <- aggregate(r2$gen,by=list(r2$run),max)
t3 <- aggregate(r3$gen,by=list(r3$run),max)
t4 <- aggregate(r4$gen,by=list(r4$run),max)
max_nrow <- max(nrow(t1),nrow(t2),nrow(t3),nrow(t4))
ap <- ggplot(t1,aes(1:nrow(t1),t1[order(t1[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
bp <- ggplot(t2,aes(1:nrow(t2),t2[order(t2[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
cp <- ggplot(t3,aes(1:nrow(t3),t3[order(t3[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
dp <- ggplot(t4,aes(1:nrow(t4),t4[order(t4[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
grid.arrange(ap,bp,cp,dp,nrow=4,ncol=1)
@

%<<figure25, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.scap=NA, fig.cap='Final mean fidelity against final mean fitness (top) and final mean fidelity against final standard deviation of fidelity (bottom).'>>=
%ap <- ggplot(subset(results,gen==500),aes(ave_fit,ave_fid)) + geom_point() + geom_smooth(method='lm') + labs(x='Final mean fitness',y='Final mean fidelity')# and relationship between these two
%# Relationship between sd_fid and ave_fid!
%bp <- ggplot(subset(results,gen==500)) + geom_point(aes(sd_fid,ave_fid)) + labs(x='Final standard deviation of fidelity',y='Final mean fidelity')
%grid.arrange(ap,bp,nrow=2,ncol=1)
%#anova(lm(sd_fid~ave_fid, data=subset(results, gen==500))) # 0.001
%@

A summary of the results from each of the four datasets is given in \cref{tbl:summary-for-changing-datasets}, and a visualisation of all four datasets combined given in \cref{fig:figure23}. Note that the difference in the proportion of completed runs to total runs reflects the respective ranges of the independent variables (as seen in \cref{tbl:range-of-independent-variables}), shown graphically in \cref{fig:figure22}.

\begin{table}
	\begin{center}
		\caption{Summary of results for changing environments}
		\label{tbl:summary-for-changing-datasets}
		\begin{tabular}{@{}lll@{}}
			\toprule
			Dataset    		& $n$ (total runs) 				& Completed runs\\
			\midrule
			Dataset no.1	& \Sexpr{max(r1$run)+1}			& 	\Sexpr{nrow(r1[r1$gen==500,])+1}\\
			Dataset no.2	& \Sexpr{max(r2$run)+1}			& 	\Sexpr{nrow(r2[r2$gen==500,])+1}\\
			Dataset no.3	& \Sexpr{max(r3$run)+1}			& 	\Sexpr{nrow(r3[r3$gen==500,])+1}\\
			Dataset no.4	& \Sexpr{max(r4$run)+1}			& 	\Sexpr{nrow(r4[r4$gen==500,])+1}\\
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}

\subsection{Is fidelity proportional to the predictability of the environment?}\label{mean-fidelity-predictability}

Remembering that a function of $\Theta$, $\sigma_e$ and $\delta$ provides a measure of environmental predictability, our null and alternate hypotheses are:

\begin{itemize}[label={}]
	\item H$_0$: $\overline{fidelity}_{end}$ is not proportional to $f(\Theta,\sigma_e,\delta)$ for all functions $f()$.
	\item H$_1$: $\overline{fidelity}_{end}$ is proportional to $f(\Theta,\sigma_e,\delta)$ for some function $f()$.
\end{itemize}

Because only $\Theta$ and $\delta$ are predictable, and hence learnable, we would not expect $\sigma_e$ as a parameter to any $f().$ 

By visual inspection of \cref{fig:figure23}, $\overline{fidelity}_{end}$ is related to $f(\delta)$; this is partially supported by the results of an \gls{anova} analysis, which finds both $\delta$ and $\Theta$ to be highly significant (p\textless 0.001). Therefore $\overline{fidelity}_{end}$ is proportional to either $f(\delta)$ or $f(\Theta,\delta)$ (and incidentally meets our expectation that $\sigma_e$ is not a potential parameter to $f()$ as it is not learnable by an evolutionary system.)

<<echo=FALSE>>=
temp <- subset(results,gen==500)
colnames(temp)[10] <- "mean_fidelity"

a <- with(temp,anova(lm(mean_fidelity~sigma+delta+theta)))
@
<<results='asis',echo=FALSE>>=
print.xtable.booktabs(a)
@

As a result, we can reject H$_0$ and accept H$_1$: fidelity is proportional to the predictability of the environment (as measured by some function $f(\Theta,\delta)$.)

%<<figure24, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.scap=NA, fig.cap='Subset of results where $0.002 < \\lvert delta\\rvert$, again showing final mean fidelity (top) and final standard deviation of fidelity (bottom) against sigma parameter.'>>=
%results_low_bias <- subset(results, -0.002<delta & delta<0.002)
%ap <- ggplot(subset(results_low_bias,gen==500),aes(sigma,ave_fid)) + geom_point() + geom_smooth(method='lm') + labs(x='sigma parameter to environmental model', y='Final mean fidelity')
%bp <- ggplot(subset(results_low_bias,gen==500),aes(theta,ave_fid)) + geom_point() + geom_smooth(method='lm') + labs(x='theta parameter to environmental model', y='Final mean fidelity')
%grid.arrange(ap,bp,nrow=2,ncol=1)
%@
%
%<<figure24a, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.scap=NA, fig.cap='Subset of results where $0.002 < \\lvert delta\\rvert$, again showing final mean fidelity (top) and final standard deviation of fidelity (bottom) against sigma parameter.'>>=
%results_low_bias <- subset(results, -0.002<delta & delta<0.002)
%ap <- ggplot(subset(results_low_bias,gen==500),aes(sigma,sd_fid)) + geom_point() + geom_smooth(method='lm') + labs(x='sigma parameter to environmental model', y='Final standard deviation of fidelity')
%bp <- ggplot(subset(results_low_bias,gen==500),aes(theta,sd_fid)) + geom_point() + geom_smooth(method='lm') + labs(x='theta parameter to environmental model', y='Final standard deviation of fidelity')
%grid.arrange(ap,bp,nrow=2,ncol=1)
%@

\subsection{Does the standard deviation of fidelity vary in proportion to the variability in the environment?}\label{sd-fidelity-predictability}

\begin{itemize}[label={}]
	\item H$_0$:  $\sigma_{fidelity_{end}}$ is not proportional to $f(\Theta,\sigma_e,\delta)$ for all functions $f()$.
	\item H$_1$:  $\sigma_{fidelity_{end}}$ is proportional to $f(\Theta,\sigma_e,\delta)$ for some function $f()$.
\end{itemize}

An \gls{anova} model evaluating a linear relationship between the standard deviation of fidelity, and the parameters $\delta$, $\sigma_e$ and $\Theta$ to the environmental model suggests that all three parameters have some effect on the \gls{sd} of fidelity, with the influence of $\delta$ and $\Theta$ being highly significant (p\textless 0.001) and that of $\sigma_e$ significant (p\textless 0.01).  Unlike in the previous \namecref{mean-fidelity-predictability}, here we are interested in the variability, or unpredictability, of the environment. As $\sigma_e$ is fundamentally unpredictable, it does not contribute to predictability but it does affect unpredictability. Therefore it is not unexpected that it contributes to the relationship between the unpredictability of the environment and the variance of fidelity.

<<echo=FALSE>>=
temp <- subset(results,gen==500)
colnames(temp)[16] <- "sd_fidelity"

a <- with(temp,anova(lm(sd_fidelity~sigma+delta+theta)))

@
<<results='asis',echo=FALSE>>=
print.xtable.booktabs(a)
@

<<sd-fidelity, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.scap=NA, fig.cap='Final standard deviation of fidelity against the environmental model\'s sigma parameter (top), delta parameter (middle) and theta parameter (bottom) for all experimental runs.'>>=
ap <- ggplot(subset(results,gen==500)) + geom_point(aes(sigma,sd_fid)) + labs(x='sigma parameter to environmental model', y='Final sd of fidelity')
bp <- ggplot(subset(results,gen==500)) + geom_point(aes(delta,sd_fid)) + labs(x='delta parameter to environmental model', y='Final sd of fidelity') 
cp <- ggplot(subset(results,gen==500)) + geom_point(aes(theta,sd_fid)) + labs(x='theta parameter to environmental model', y='Final sd of fidelity')
grid.arrange(ap,bp,cp,nrow=3,ncol=1)
@

The corollary of this prediction is that the \gls{sd} of fidelity will be greater in unpredictable environments than in stable environments (when all three parameters are near zero). As a first approach, we note that in \cref{variance-of-inheritance-stable} we showed that in stable environments the variance of inheritance tended towards zero. As $\sigma_e$ is by definition unpredictable (see \cref{environmental-model}) we can provide some support for the corollary if we can show that variance remains above zero for all $\sigma_e>0$ (incorporating all necessary uncertainties): 

\begin{itemize}[label={}]
	\item H$_0$:  $\sigma_{fidelity_{end}}$ is close to $0$, for all clearly non-zero combinations of $\Theta$,$\delta$ and $\sigma_e$.
	\item H$_1$:  $\sigma_{fidelity_{end}}$ is not close to $0$, for some clearly non-zero combinations of $\Theta$,$\delta$ and $\sigma_e$.
\end{itemize}

It is clear from a visual inspection of \cref{fig:sd-fidelity} that we can reject H$_0$ in favour of H$_1$: $\sigma_{fidelity_{end}}$ is greater under unpredictable conditions than it is under stable environmental conditions.

This could be greatly strengthened if we had a single measure of predictability (but see suggestion in \cref{information-based-measure}): our conjecture is that the \gls{sd} of fidelity is related also to the degree of predictability, that is $\sigma_{fidelity_{end}} \approx $predictability$^{-1}$. 

Unfortunately, we require a consistent ordering from ``least'' to ``most'' predictable across the three parameters $\Theta$,$\delta$ and $\sigma_e$, although we could:
\begin{itemize}
\item Empirically construct a linear regression model relating $\Theta$,$\delta$ and $\sigma_e$ to $\sigma_{fidelity_{end}}$ but this would not provide a measure of predictability (other than a circular one derived from fidelity.) 
\item Use $\sigma_e$, which is inherently unpredictable, as a proxy however this would ignore the contributions of $\Theta$ and $\delta$ to overall unpredictability.
\end{itemize}

Instead a better approach would be to extend our environmental model to map $\Theta$,$\delta$ and $\sigma_e$ to predictability and to then use that to confirm this conjecture, as suggested in \cref{information-based-measure}).

%<<echo=FALSE>>=
%a<-with(temp,lm(sd_fidelity~sigma*theta*delta))['coefficients']
%t1 <- read.csv('results/environments-factorial.csv', header=FALSE, colClasses=c("numeric","numeric","numeric"))
%
%t1$run <- 1:nrow(t1)
%names(t1)[1:3]<-c("theta", "sigma", "delta")
%t2 <- melt(t1,id=c('run','theta','sigma','delta'))
%t2$theta <- round(t2$theta,3)
%t2$sigma <- round(t2$sigma,3)
%t2$delta <- round(t2$delta,3)
%t3<-unique(t2[,c(2,3,4)])
%predictions <- cbind(t3,sd=predict(a,newdata=t3))
%predictions[order(predictions$sd),]
%
%with(temp,temp[order(sd_fidelity),c("sd_fidelity","delta","sigma","theta")])
%@

\subsection{Is there a difference between changes applied by lineage and changes applied across an entire population?}
Although not a prediction of the hypothesis, it is interesting to examine if the scope of change, as discussed in \cref{environmental-model}, is in fact significant to the results.

<<echo=FALSE>>=
temp <- subset(results,gen==500)
colnames(temp)[10] <- "mean_fidelity"
colnames(temp)[16] <- "sd_fidelity"
colnames(temp)[1] <- "Scope"

a <- with(temp,anova(lm(mean_fidelity~Scope)))
b <- with(temp,anova(lm(sd_fidelity~Scope)))
@
<<results='asis',echo=FALSE>>=
print.xtable.booktabs(a)
@

Applying a unique change to each lineage as opposed to the entire population is only weakly significant (0.05\textless p\textless 0.1) with respect to final mean fidelity, and not significant (p\textgreater 0.1) with regards to final standard deviation of fidelity:

<<results='asis',echo=FALSE>>=
print.xtable.booktabs(b)
@

Therefore we can conclude that there is no significant difference between these two options for the scope of environmental change.

%<<figure26, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.scap=NA, fig.cap='Subset of results where $\\lvert delta\\rvert > 0.002$, showing the effect of lineage. Final mean fidelity (top) and final standard deviation of fidelity (bottom) against sigma parameter. Very little difference is observed between applying an environmental change uniformly across all entities, or applying different changes to each lineage.'>>=
%ap <- ggplot(subset(results,gen==500 & -0.002<delta & delta<0.002),aes(sigma,ave_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE)+ labs(x='sigma parameter to environmental model', y='Final mean fidelity')
%bp <- ggplot(subset(results,gen==500 & -0.002<delta & delta<0.002),aes(sigma,sd_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE) + labs(x='sigma parameter to environmental model', y='Final standard deviation of fidelity')
%ap <- ggplot(subset(results,gen==500 & -0.002<delta & delta<0.002),aes(sigma,ave_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE)+ labs(x='sigma parameter to environmental model', y='Final mean fidelity')
%bp <- ggplot(subset(results,gen==500 & -0.002<delta & delta<0.002),aes(sigma,sd_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE) + labs(x='sigma parameter to environmental model', y='Final standard deviation of fidelity')
%ap <- ggplot(subset(results,gen==500),aes(delta,ave_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE)+ labs(x='sigma parameter to environmental model', y='Final mean fidelity')
%bp <- ggplot(subset(results,gen==500),aes(delta,sd_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE) + labs(x='sigma parameter to environmental model', y='Final standard deviation of fidelity')
%grid.arrange(ap,bp,nrow=2,ncol=1)
%@

%<<figure27, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.scap=NA, fig.cap='Sample entropy.'>>=
%library(pracma)
%library(ggplot2)
%library(cowplot) # styling of plots, extension of ggplot2
%
%t2 <- t1[,1:3]
%names(t2)[1]<-"theta"
%names(t2)[2]<-"sd"
%names(t2)[3]<-"bias"
%for(n in 1:nrow(t1)) {t2[n,'sample_entropy'] <- sample_entropy(unlist(t1[n,4:52],use.names=FALSE))}
%for(n in 1:nrow(t1)) {t2[n,'approx_entropy'] <- approx_entropy(unlist(t1[n,4:52],use.names=FALSE))}
%
%ggplot(t2, aes(sd,approx_entropy)) + geom_point() + geom_smooth(method='lm') # formula not required
%@

%\begin{DRAFT}
%The unbiased sample variance with Bessel's correction is \todo{reference}:
%\[
%s^2 = \frac {1}{n-1} \sum_{i=1}^n  \left(x_i - \overline{x} \right)^ 2 = \frac{\sum_{i=1}^n \left(x_i^2\right)}{n-1} - \frac{\left(\sum_{i=1}^n x_i\right)^2}{(n-1)n}.
%\]
%
%Let us assume that the upper bound on fidelity of 1.0 has no effect on $s^2$.
%Then we can divide the fidelity values at time $t$ into those below the mean and those above; arrange the sample values so that the first $m$ fall below the mean and the remainder above. The sample variance can now be written as:  
%
%\[
%s^2 = \frac {1}{n-1} \sum_{i=1}^n  \left(x_i - \overline{x} \right)^ 2 = \frac {1}{n-1} \sum_{i=1}^m  \left( \left(x_i - \overline{x} \right)^ 2 + \sum_{i=m}^n  \left(x_i - \overline{x} \right)^ 2 \right)
%\]
%
%As $\overline{x}$ approaches 1.0 (the upper bound on fidelity) from below:
%
%\[
%s^2 = \frac {1}{n-1} \left( \sum_{i=1}^m   \left(x_i - 1 \right)^ 2 + \sum_{i=m}^n  \left(x_i - 1 \right)^ 2 \right)
%\]
%
%But by our initial statement, $s^2$ remains unchanged, therefore...
%
%\[
%\frac {1}{n-1} \left( \sum_{i=1}^m   \left(x_i - 1 \right)^ 2 + \sum_{i=m}^n  \left(x_i - 1 \right)^ 2 \right) = \frac{\sum_{i=1}^n \left(x_i^2\right)}{n-1} - \frac{\left(\sum_{i=1}^n x_i\right)^2}{(n-1)n}.
%\]
%\end{DRAFT}


\section{Conclusions}\label{part2-future-work}
In this chapter we have shown by experiment that, as predicted, in stable environments our model of inheritance emerging from variation and selection results in:
\begin{itemize}
	\item Inheritance increasing towards an upper limit of $1.0$, or perfect inheritance.
	\item The variance of inheritance decreases towards a lower limit of $0$.
\end{itemize}

This is encouraging, and the first point confirms the main result from the exploration by \textcite{Bourrat2015}. However, from the viewpoint of a creative open-ended evolutionary process, this is not in fact what is desired: perfect inheritance means an absence of novelty. As hypothesised earlier in \cref{h2} though, this should be different in systems where the environment changes, and in the following \namecref{model-behaviour-in-changing-environments} we shall put this to the test.

The previous \namecref{model-behaviour-in-changing-environments} has tested our hypothesis predictions from \cref{h2} for changing environments. First we defined what we mean by environmental change. In \cref{environmental-model} we described an environmental model based on a AR(1) timeseries defined by three independent parameters, $\Theta$, $\delta$ and $\sigma_e$. Specifically, the change in fitness at each timestep $t$ is given by the function $\Theta x_{t-1} + e_t + \delta$, where $e_t$ is an error term related to $\sigma_e$ by $e_t\stackrel{iid}{\sim}N(0,\sigma^{2}_e)$. From this description it is clear that of these three parameters, two--$\Theta$ and $\delta$--are more discoverable by an evolutionary learner than the other, $\sigma_e$.

\Cref{h2} made these predictions:

\begin{enumerate}
	\item Fidelity is proportional to the predictability of the environment, that is at a minimum in conditions of maximum unpredictability, and at a maximum in stable conditions.
	\item The higher the variability in the environment, the higher the \gls{sd} of heredity. As a corollary, the \gls{sd} of heredity under changing conditions will be greater than that under stable conditions.
\end{enumerate}

In \cref{mean-fidelity-predictability} we constructed a random-effects factorial experiment where the simulation model from \cref{base-model} was combined with the environmental model to confirm the first prediction: fidelity in changing environments is indeed related to environmental predictability. However, this conclusion would be strengthened by an ordering of predictability based on $\Theta$, $\delta$ and $\sigma_e$, as suggested below in future work.

The second prediction was also confirmed in similar fashion in \cref{sd-fidelity-predictability} with a similar caveat. Although we can show a clear difference between stable and changing environments, without an absolute ordering over $\Theta$, $\delta$ and $\sigma_e$ it is difficult to show a proportional relationship.

Overall this \namecref{model-behaviour-in-changing-environments} provides good support for our hypothesis that an effective inheritance mechanism can not only emerge from a low-heredity environment through evolution, but that it can be tuned and optimised by evolution to suit the population environment. This is a foundational requirement for a practical open-ended evolutionary system.

There are some obvious extensions of the model from \cref{base-model} that for reasons of scope have been left for future work. First, the model currently assumes only single-parent inheritance, whereas many biological species have two parents. Extending to two parents would be a useful enhancement to increase the model's scope. Second, the model does not include any influence from development (the production of the phenome from the genome). However, it is unclear at this stage what effect development would have on the model as its effects are bundled into the overall \emph{fitness} parameter. Finally, although outside of the overall scope of this work in evolutionary systems, the effect of acquired characteristics would be interesting to explore. Others (\eg \textcite{Gaucherel2012,Paenke:2007ie,Sasaki:2000dq}) have studied the differences between general models based on acquired and non-acquired characteristics, finding a difference between models in changing environments. This would be another area of exploration for the future.

Two other topics for possible future work are abrupt environmental change, and an information-based measure for change, as explained below.

\subsection{Abrupt environmental change}\label{abrupt-environmental-change}
	
Although the generator described earlier produces a time series for environmental change with the property of stationarity, the $\delta$ term makes the evolutionary model of fitness non-stationary. However, any change is steady and gradual. An extension would be to co-opt the idea of concept drift from time series analysis to induce an abrupt change with probability $p$ at each generation. Each change would therefore form a new `concept`. Instead of the environment changing in a predictable and describable way from one generation to another, the change could not be predictable from the earlier history.

Stationarity is inherently a constraint for applying statistical methods to the analysis of evolutionary models, where almost by definition, the outcomes change over time. One common approach is be to assume approximate stationarity over short(ish) periods, along the lines of moving window or local kernel methods in time-series analysis. Alternatively, we could reformulate the problem so that out of all the possible message channels, we choose to investigate only those that meet the stationarity assumption. It's hard to see though how we can effectively examine an evolving system by discarding most of the relevant information.

Another broad approach might be to modify the method to reduce its dependence on stationarity. For example, taking one part of the problem, \textcite{LingFengLiu2014} develops a modification of the well-known Shannon entropy formula for non-stationary processes. The method though assumes that the process moves between a number of states with the series output following a known distribution in each state. Although this approach does provide an upper-bound to the information entropy of the process output, identifying the states and the accompanying distributions from a black-box process is likely to prove a challenge. Fundamentally, non-stationarity remains a problem for most methods.

\subsection{An information-based measure}\label{information-based-measure}

Predictability is related to information entropy, and to compression; a mechanism for pattern-discovery.  \textcite{Shalizi2001} identifies patterns (pattern $P$ of an object $O$) with the ability to predict (given $P$, can infer $O$) or compress (given $O$, can compress to $P$). Compression doesn't imply Prediction. There is a related concept in algorithmic complexity theory--the difference between easily solvable (P) (prediction) and easily verifiable (NP) (compression). A problem may be decidable without being easily solvable. 

In a time-independent way we can identify patterns in an image, for example, that allows us to substitute the pattern for the raw data. It is thus related to algorithms - compression is the discovery of a specific algorithm to take raw data and produce patterned data, with the goal of increasing the information content and reducing the information entropy of the patterned data. The algorithm is the patterned data. Information entropy can then, in theory at least, be measured by the Kolmogorov entropy or algorithmic complexity--the length of the algorithm. In practice various other entropy measures, such as Shannon, sample, and approximate entropy, are commonly used for time-series characterisation.

\textcite[Appendix 1]{Edmonds1999} contains a thorough review of complexity measures. More recently see \textcite{Prokopenko2009}, \textcite{Ladyman2011} and \textcite{Lloyd2001}.

Statistical Complexity \parencite{Crutchfield1989}, or $C_\mu$, based on causality, is fundamentally time-dependent: one dimension plus time, although an extension to two spatial dimensions has been done by Shalizi with a more general extension to multi-dimensions still open although a mapping method for multi-dimensional data has been proposed by \textcite{Nerukh2002}, and a dimension reduction approach by fuzzy-clustering can be found in \textcite{Young2005}.

The benefits of $C_{\mu}$ are that it matches our intuition of complexity (better than most alternatives), it has strong theoretical support, and it makes no major assumptions about the underlying data other than stationarity - it is domain agnostic. \textcite{Shalizi2001} provides the best theoretical explanation of $C_{\mu}$ and epsilon-machines; Shalizi's Ph.D. thesis \textcite{Shalizi2001a} provides further context. 

$C_{\mu}$ has been applied to a number of domains including random boolean networks \parencite{Gong2012}, spin \parencite{Vrabic2012,Shalizi2007,Nerukh2002,Feldman1998}, estimation of cortical thinning from brain MRI data \parencite{Young2008}, autonomy of protocells \parencite{Krakauer2008} and detection of anomalies (such as imminent crankshaft failure) directly from the causal states \parencite{Xiang2008}.

The canonical formulation of $C_{\mu}$ depends on two assumptions--discrete values and discrete time \parencite[p.24]{Shalizi2001}, and exact joint probabilities--which are unproblematic in our domain, and another, conditional stationarity, which poses a problem. Conditional stationarity, or time-invariant transition probabilities \parencite[p.25]{Shalizi2001} means $P(\overrightarrow{S}_t^L = s^L) = P(\overrightarrow{S}_0^L = s^L)$ for all $t \in \mathbb{Z}$ or ``the distribution of futures, conditional on histories, must be independent of when the history comes to an end'' \parencite[p.119]{Shalizi2001}. Note this issue with stationarity is similar to the difficulty identified in \cref{abrupt-environmental-change}, and a solution to one might be applicable to the other.
