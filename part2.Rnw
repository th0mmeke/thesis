<<setup, include=FALSE>>=
library(knitr)
library(cowplot) # styling of plots, extension of ggplot2
library(gridExtra) # grid layouts for ggplot2
library(lattice) # needed for bwplot etc
library(english) # convert numbers to words
opts_chunk$set(fig.path='generated_figures/')
knit_hooks$set(pdfcrop = hook_pdfcrop)

load.results.simple <- function(t) {
colClasses <- c("numeric","numeric","integer","integer","numeric","numeric","factor","factor","factor","factor","factor","factor","factor","factor")
read.csv(t, colClasses=colClasses)
}

load.results <- function(t) {
colClasses <- c("integer","integer","numeric","numeric","integer","integer","numeric","numeric","factor","factor","factor","factor","factor","factor","factor","factor")
df <- read.csv(t, colClasses=colClasses)
df$ecf <- factor(df$ecf,levels=c(0,1,5,10)) # place into natural order
df
}
@

% # Filter(Negate(is.factor),z[[gen]]) # quantile values for each combination of factor levels at gen
% # levels <- unique(interaction(Filter(is.factor,y))) # all unique combinations of factor levels in y

\chapter{Introduction}

%Models (not simulations) for the emergence of heredity, for the purpose of strengthening the theoretical basis for any simulation. Goal is a causal, rather than constitutive, model for the emergence of heredity from variation and inheritance.

%		\item Can evolution act on the inheritance mechanism to tune it for varying environmental conditions?
%		\item Does inheritance still emerge from variation when the fitness-environment relationship is not fixed?

This part of the work addresses our second research question: ``If we assume that for pragmatic reasons inheritance must itself be evolved from simple beginnings, rather than designed in, then what is the mechanism by which this might be achieved?"

\section{Previous work}\label{previous-work-p2}

Over the years a significant body of literature has accumulated on models of biological inheritance. While standard population genetics describes the dynamics over time of genotype frequencies, it remains deeply rooted in the biology of genotypes and alleles. Different forms of inheritance, such as acquired (or Lamarckian inheritance) characteristics have been compared and contrasted to the canonical non-acquired form in \gls{ens} by a number of authors (including for example \textcite{Jablonka1995, Paenke:2007ie,Gaucherel2012}), going back to the competing models for inheritance of Darwin and Lamarck themselves. Early hypotheses in the metabolism-first or replicator-first debate led to the recognition of the significance of error threshold rates for mutations during copying \parencite{Eigen1971}, and later investigation of the interaction between inheritance (of genotypes, when non-acquired), selection (on the phenotype), and development (linking genotype to phenotype) inspired the theory of neutral landscapes \parencite{Kimura:1968uq}. 

In comparison, little explicit modelling of inheritance has been done in \gls{alife}. Most relevant work has already been reviewed in \cref{previous-work} where it generally forms one element of a wider investigation into \gls{oe}. However, in relation to \gls{ea}, many models for inheritance from variation and recombination have been proposed, but are less relevant to our needs as they rely on exogenous, or external, predefined mechanisms rather than emerging from the properties of the genotypes. 

\Textcite{Paixao2015} sought common principles between population genetics and evolutionary computation with the goal of unifying the two fields, starting from a broad description of evolutionary processes as a ``population undergoing changes over time based on some set of transformations''. A transformation can be decomposed into a collection of (stochastic) operators, with an operator being a probability distribution of potential outcomes; some operators act on phenotypes, others on genotypes. Various operators drawn from evolutionary computing are defined: for selection (uniform, proportional, tournament, truncation, cut, replace); variation from mutation (uniform, single-point), and variation from recombination (one-point crossover, k-point crossover, uniform crossover, unbiased variation).

The evolutionary process is then a trajectory through a space of distributions; it can therefore be seen equally as a sequence of population transformations, and distribution transformations. When considered as a series of distribution transformations, \textcite{Paixao2015} sees a correspondence with Estimation Distribution Algorithms (EDA): ``In an Estimation Distribution Algorithm (EDA), the algorithm tries to determine the distribution of the solution features, e.g. probability of having a 1-bit at a particular position, at the optimum. Some EDAs can be regarded abstractions of evolutionary processes: instead of generating new solutions through variation and then selecting from these, EDAs use a more direct approach to refine the underlying probability distribution. The perspective of updating a probability distribution is similar to the Wright--Fisher model.''

\Textcite{Paixao2015} concludes by demonstrating how existing ``classical models in theoretical population genetics and in the theory of evolutionary computation'' can be mapped into the framework of classified and categorized operators. Most of the various population genetics models can be represented; some topic-specific \gls{ea} models could not be, while genetic programming models were omitted for reasons of balance between ``simplicity and inclusiveness.'' However, \textcite{Paixao2015} is of limited relevance for this work as it is in effect a constitutive framework, providing a series of tests to classify existing models based on a general meta-model of evolution, rather than a causative model which is where our interest lies. Variation, in the form of reproduction and mutation, is only one element of the framework, and \textcite{Paixao2015} does not specifically address the emergence of heredity from variation.

%Most evolutionary models are seen to satisfy five mathematical properties:
%\begin{itemize}
%\item V1--variation (either mutation or recombination) is uniformity preserving: no change to distribution if uniformly distributed.
%\item M1--mutation acts on individuals.
%\item M2--mutation can generate the whole search space \ie an ergodic operator (the defining characteristic of mutations).
%\item R1--recombination preserves allele frequencies (in expectation).
%\item S1--selection doesn't change individuals.
%\end{itemize}

More specific models of inheritance and heredity can be found in three works comparing the adaptive value of acquired and non-acquired characteristics. In the first two works, \textcite{Jablonka1995,Paenke:2007ie}, the comparison is made with respect to an environment that alternates between two states, $E_0$ and $E_1$. Each environment is associated with a corresponding adapted phenotype $P_0$ and $P_1$, respectively.  In both works variation only affects the ratio of each phenotype in the population (directly in \textcite{Jablonka1995}, indirectly via a ``predisposition'' or tendency in \textcite{Paenke:2007ie}); no new phenotypes are created, and as inheritance is modelled only at a population level, that is without reproduction, we cannot use these models to investigate the emergence of heredity.

Inheritance however is modelled in \textcite{Gaucherel2012}, the third work, in relationship to individuals. Two models are presented, the first and simplest describing a non-spatial scenario conceptually similar to that in \textcite{Jablonka1995} and \textcite{Paenke:2007ie}, while the second examines a spatial world based on DaisyWorld \parencite{LovelockMargulis2011}. Focussing on the first and most relevant of the two models, reproduction is the middle of three repeated stages--first ``annihilation'' where the population size is adjusted to some practical level, then reproduction, and finally development. Concentrating on the second, reproduction, stage, individuals, represented by a single trait, or phenotype, value, are chosen for reproduction with some probability (based on the trait value), and the child given a trait value that slightly varies from the parent's value to model mutation (paraphrasing \textcite{Gaucherel2012}, $trait_{child} = trait_{parent} + \delta$, where $\delta$ is described as taken from a uniform distribution of given range around the parent's trait value. \footnote{although this appears to be an error and instead it should centered on $0$.})

The most relevant previous work is that of \textcite{Bourrat2015} who, in the course of examining the difference between evolution, natural selection and \gls{ens}, models the emergence of heredity in unchanging environments. \Textcite{Bourrat2015} demonstrates that imperfect inheritance is not compatible with \gls{ens} using an argument by contradiction \parencite[p.96]{Bourrat2015}: he lists the three conditions for a population to evolve solely by \gls{ens}, and then continues on to show that at least one of those conditions is incompatible with imperfect inheritance (as it happens, no production of new variants). The context is explicity in relationship to biology; his examples involve genes, traits, phenotypes and drift.

The six applicable models in \textcite[chap.3]{Bourrat2015} are designed to explore the implications of bias on inheritance; in \textcite{Bourrat2015}, unbiased means a trait is uncorrelated with parent, in practice as a random choice between lower and upper bound \parencite[p.153]{Bourrat2015}. Biased inheritance is naturally the opposite: there is some correlation between parent and child values for a trait, and so some prediction of traits is possible--a parent can ``pass it on''. Note that \textcite[p.173]{Bourrat2015} expressly notes that his ``biased inheritance'' is not the `transmission bias` of the second term in the Price equation: ``The bias in ‘biased inheritance’ is in reference to the type of the parent(s) (biased toward the type of the parent), while the bias in ‘transmission bias’ refers to a departure from an event of perfect transmission.'' Bourrat unfortunately doesn't formalize his model descriptions. Instead there is a reference \parencite[p.129]{Bourrat2015} to a NETLOGO 5.02 implementation, and textual narrative descriptions of each model and the results.

%\Textcite{Bourrat2015}
%\begin{itemize}
%\item Persistors - unable to reproduce, selection only in ``weak'' sense of granite grains for hardness
%\item Procreators can reproduce but without inheritance of any property (including ability to procreate) except ``fact of coming into existence and membership of that class'' (class is class of parents defined by ``those properties that do not vary in the population''...{[}acknowledged as loose, but has benefit that no varying traits included{]}) p137. Procreator's offspring is persistors
%\item Minimal reproducers - indefinite procreation - where procreation can be transmitted from parent to offspring (with some low degree of fidelity)
%\item Unreliable reproducers (low bias for ability to procreate- ability to procreate randomly chosen between 0 and parent's ability), reliable reproducers (high bias - ability to procreate is same as parent's ability)
%\item Replicator - all traits (including procreation) can be inherited
%\end{itemize}

Model 1 begins with a population of 5000 ``persistors'' (that is without reproduction), each of which has a survival rate (viability) between 0 and 0.99 (the likelihood of surviving at each time step). Unsurprisingly, all eventually die. Model 2 introduces a single ``procreator'', capable of reproduction with both survival and fertility rates (offspring per unit time), into the population of persistors. The traits of the offspring of the procreator are uncorrelated (that is, unbiased inheritance) to those of the procreator, and the model now consists of \emph{selection} $\rightarrow$ \emph{reproduction} $\rightarrow$ \emph{check-for-overcrowding} \parencite[p.141]{Bourrat2015} at each timestep. Again, all entities eventually die.

Model 3 begins to get interesting: \textcite{Bourrat2015} replaces the procreator by a ``minimal reproducer'' which differs from a procreator in that the ability to procreate is itself a heritable trait, although as ``minimal'' it is an unbiased trait. As such, the offspring of the minimal reproducer may be either minimal reproducers or persistors without the ability to reproduce. Now the population size drops then increases to maximum size with about 10\% of the population being minimal reproducers. However, the proportion of high fitness (that is, high viability) entities doesn't increase beyond about 0.05, so there is no cumulative adaptation.

Biased (in fact, perfect) inheritance of viability is introduced in Model 4; the offspring inherit the viability of their parent. The proportion of high fitness entities rapidly approaches the upper limit of $1.0$, as expected as high viability entities live longer and so produce more offspring while low viability entities die sooner and so produce less-- fertility random, but viability is heritable.

The most significant model is Model 5 which adds a variable ability to procreate to Model 4, while viability remains inherited with perfect fidelity from the parent. The variation is provided by the addition of a \emph{mutation} stage so that the model now consists of these stages at each timestep: \emph{mutation} $\rightarrow$ \emph{selection} $\rightarrow$ \emph{reproduction} $\rightarrow$ \emph{check-for-overcrowding} \parencite[p.153]{Bourrat2015}. At each mutation stage, there can be an increase or decrease in both the ability to transmit the ability to procreate, and in degree of bias (that is, relationship to parent's ability) in the ability to procreate. The first defines the proportion of offspring of the parent who are themselves able to procreate; a low trait value for the parent means a low proportion of siblings can procreate, while bias represents the correlation between the parent and offspring's abilities to transmit procreation--low bias means the offspring's ability is only weakly correlated with parents ability. The initial population contains entities with viability in the full range $[0,1)$, an ability to procreate in $[0,0.2)$ and initial bias of $0$. Both the ability to procreate and the bias \emph{increase} over time in the population towards the upper limit of $1.0$. The model is asymmetric with respect to the change of inheritance of ability to procreate: reductions lead to extinction of a line, while increases lead to increased population. Bourrat's conclusion is that an initial population of unreliable reproducers (a low proportion of procreating offspring, no bias) will evolve into one of reliable reproducers--that is, inheritance can emerge.

This is extended in the final Model 6, where Bourrat demonstrates the combination of inheritance of procreation with that of another trait, viability. The model begins with a population produced by the end of Model 5 - a set of entities that can reliably transmit the ability to procreate to their offspring. Using the same structure for trait inheritance as in Model 5, Model 6 shows that inheritance of viability or fitness can also emerge. In total then, the entities at the conclusion of Model 6 have full inheritance of multiple traits.

There are some limitations however in these otherwise insightful models. First, heredity and fitness (viability) are treated as independent traits. But the mechanism for heredity is the thing that copies the information that generates an offspring's traits, so in practice they are not independent.

Second, while Model 5 has perfect inheritance on viability and demonstrates emergent inheritance on procreation, Model 6 shows emergent inheritance on viability while beginning with perfect inheritance on procreation (as it begins with a shortcut population of entities assumed to have been produced by Model 5.) Thus Bourrat does not show in either model the simultaneous emergence of inheritance of both procreation and viability.

Finally, as seen by the trend of trait values towards the limit of $1.0$, the model assumes that the problem learnt by evolution is capable of perfect understanding, and that there is one and only one optimal solution. This is a corollary of the model design where fitness is absolute and unchanging--if fitness represents (as it does) an implicit relationship between an entity and its environment, then in Bourrat's model this relationship is also fixed and unchanging. Evolution is omniscient with full visibility into the world. However, in the real world and in the artificial domains of interest, the relationship between entity and environment is less sure. The environment itself may either change, or be uncertain. Under these conditions it is unlikely that values of $1.0$ would be possible, or indeed helpful, as a perfect bias value effectively is removing any source of variation from the population. This is unexplored by Bourrat.

\section{Methods}\label{methods-p2}

The work of \textcite{Bourrat2015} partially addresses our second research question (the focus of this \nameref{part2}.) However, Bourrat as identified in \cref{previous-work-p2}:
\begin{itemize}
	\item Does not link heredity and fitness in his model.
	\item Does not show the simulataneous emergence of inheritance of procreation and viability.
	\item Most importantly, does not consider the effect of changing environments on inheritance.
\end{itemize}

Addressing these limitations becomes the driver for the work in this \nameref{part2}. The method follows that outlined in \cref{approach}: 

\begin{enumerate}
	\item Construction of a parameterized simulation model [\cref{base-model}]
	\item Forming a hypothesis [\cref{h2}]
	\item Characterizing the sensitivity of the simulation model to parameter ranges [\cref{reducing-the-parameter-space-for-the-experiments}]
	\item Testing the hypothesis under unchanging environmental conditions [\cref{experimental-test-of-h2-under-fixed-conditions}]
	\item And finally, testing the same under changing environments [\cref{model-behaviour-in-changing-environments}]
\end{enumerate}

\section{Simulation model of variation and inheritance}\label{base-model}

We now introduce a general model of the relationship between \emph{Variation}, \emph{Selection} and \emph{Inheritance} in a population of evolving abstract entities (\cref{base-model-algorithm}) where the key elements, such as fidelity and fitness, are represented as explicit parameters. This strategy of making otherwise derived variables explicit is also followed by Bourrat, who describes it as ``explaining variables which have previously been taken for granted in a model (such as reproduction and inheritance), by reference to other, more fundamental variables present in the model'' \parencite[p.129]{Bourrat2015}. Our model owes a direct debt to Bourrat in the representation of fidelity by an explicit parameter (related to the two parameters ``heredity of the ability to procreate'' and ''transmission of the ability to procreate'' in \textcite{Bourrat2015}). 

In other respects it resembles a fairly standard \gls{ea} (as briefly reviewed earlier in \cref{ea}). The model consists of a population of abstract entities, and two simple functions--\emph{Selection} and \emph{Variation}--that each take a population as input and output a transformed population. Each \gls{run} consists of a fixed number of time steps (generations), where at each step these two functions are applied in sequence to the current population to form a replacement population as documented in \cref{base-model-algorithm}. 

Let's look at each element in turn.

\begin{enumerate}
	\item \emph{Population} The population consists of $n$ entities, where $\lvert n\rvert\geq 0$.
	\item Each \emph{entity} is fully described by two properties -- \emph{fitness} and \emph{fidelity}.
	\item \emph{Fitness} represents the probability that an entity will survive and possibly also reproduce, and has the usual range for a probability of $[0,1]$.
	\item \emph{Fidelity} is the correlation between the child's and parent's values for a property. The range is $[0,1]$ where a value of $0$ means that the value for a child's property has no correlation with its parent's value for that property. High \emph{fidelity} values mean high correlation, and when $fidelity = 1.0$ the child's value is identical to the parent's. There is a subtle difference between fidelity and inheritance: inheritance is the process that results in fidelity, the degree of correlation between two generations. In other words, fidelity captures the same idea as heredity: ``One must clearly distinguish between heredity (a relation), heritability (a capacity), and inheritance (a process)'' \autocite{Griesemer2005}
	\item \emph{Selection} forms a new population by selecting elements from the current population, as defined in \cref{model-functions}. The probability of an element being included in the new population ($p_{selection}$ in the algorithm) may be either a fixed value, or equal to its \emph{fitness}. 
	\item The new population created by \emph{Variation} consists of a number of new entities (``children'') for each entity (``parent'') in the current population (see \cref{model-functions}). Each entity has children with probability $p_{reproduction}$, and if it does, the number of children it has is some random number between $0$ and $n_{children}$. The properties of each child are related to the properties of its parent by a mapping, represented in the algorithm by the function $Derive$, which maps the parent value to a value in a range with an expected value equal to the parent's value (see \cref{fig:correlation}) and some degree of correlation captured by the value of the function $Range$.
\end{enumerate}

The model is parameterized to make it easy to describe different specific models within this general structure; these parameters are defined in \cref{tbl:parameter_definitions}. In later chapters describing the series of experiments that use this model, these parameters will be mapped to experiment factors, with specific parameter values becoming factor levels.

\begin{table}
	\begin{center}
		\caption{Definitions for all parameters of the model}\label{tbl:parameter_definitions}
		\begin{tabular}{@{}llp{8cm}@{}}
			\toprule
			Parameter          	& Value                                	& Description\\
			\midrule
			$p_{reproduction}$ 	& $[0,1]$                               & Probability of reproduction\\
			$p_{selection}$   	& $[0,1]$                               & Probability of selection\\
			$n_{children}$     	& $n_{children}\in \mathbb{Z}_{\ge 0}$ 	& Maximum number of children per parent\\
			Reproduce           & $entity\mapsto entity$       			& Function to create a new entity based on an existing one\\
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.95\linewidth]{figures/model}
\end{figure}

\begin{algorithm}
	\For{each generation $\in [1\dots$number of generations]}{
		$population\leftarrow Selection(population)$\;
		$population\leftarrow population \cup Variation(population)$\;
		\BlankLine
		\lIf{$population$ size is too small}{break}
	}
	\caption{Algorithm for the inheritance and variation model}\label{base-model-algorithm}
\end{algorithm}

\begin{algorithm}
	\Def{Selection(population)}{
		$population_{new}\leftarrow \{\}$\;
		\For{each $entity \in population$} {
			\Prob($p_{selection}$:){
				Add $entity$ to $population_{new}$\;
			}
		}
		\Return $population_{new}$\;
	}
	\BlankLine
	\Def{Variation(population)}{
		$population_{new}\leftarrow \{\}$\;
		\For{each $entity$ with $fitness$ and $fidelity$ in $population$}{
			\BlankLine
			\Prob($p_{reproduction}$:){
				\For{some number of children $\in \mathcal{U}[0,n_{children}]$} {
					$child\leftarrow$ Reproduce($entity$)\;
					Add $child$ to $population_{new}$\;
				}
			}
		}
		\Return $population_{new}$\;
	}
	\caption{Definitions for the functions Selection and Variation}\label{model-functions}
\end{algorithm}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.95\linewidth]{figures/correlation}
\end{figure}\label{fig:correlation}

\section{Hypothesis: Correlated Variation and Selection are sufficient for Inheritance}\label{h2}

First we define the two distinct types of relationship between an entity and its environment mentioned in the previous \nameref{methods-p2}: stable, and changing environments. A stable environment is one where the relative fitness of each entity with respect to the environment does not change over time. An changing environment is the other case, where the relative fitness does change over time. These definitions of course assume that the phenotype of the entity remains constant over its lifespan, and hence that the only cause of a fitness change can be a change in environment rather than, for example, the entity learning or developing, which are both processes that change the phenotype on a shorter timescale than a lifespan.


Argument that heredity may in fact be a product of evolution rather than a precursor \autocite{Bourrat2015}

Heredity seen as method to maintain low entropy over much longer time than possible with non-biological systems: \quote{ Living systems can stay away from maximum entropy for much longer, indeed arbitrarily long (the biotic time scale is, for all we know, only limited by the existence of the biosphere). It is then this ability: to persist in a state of reduced entropy for biotic as opposed to abiotic time scales, that defines a set of molecules as living, and this set of molecules must achieve that feat via the self-replication of information.}{\autocite{Adami2015}}

``Context determines fitness'', where the environment is stable and affects the development of the entities

Degree of variation between generations important (no correlation means effectively unguided search, complete correlation means no source of novelties)

Problem is how can the optimal degree of variation (that is, inheritance) be established endogenously rather than as a model parameter?

Inheritance related to variation (between generations). Low variation implies high inheritance

Selection strengthens degree of inheritance

high fitness lineages more successful. Inheritance increases correlation along lineage, so high fitness more likely to be passed down. (Also low fitness, but they will suffer). On average then high inheritance increases average fitness over time. Higher fitness entities will survive longer and reproduce more; higher fidelity reduces variation in fitness and so results in higher fitness being preferred.

Inheritance comes from a copy mechanism under evolutionary control, such that the fidelity of the copy may be varied by interaction with the environment.

Inheritance describes the similarity of an offspring to its parent, and depending on the context, can refer to the correlation for either a single trait or to a group of traits shared between offspring and parent (perhaps all of them.)

For the single trait case, when the correlation between the value for a parent's trait and an offspring's trait approaches the upper limit of 1.0 we say we have complete or full inheritance. Conversely, if there is no correlation (near the lower limit of 0) there is no inheritance and the entities are unrelated. We extend the measure to a group of traits simply by taking the average correlation of the group.

\begin{hypothesis}
Variation, where there is some initial correlation between generations for a property, and Selection are sufficient for maximal Inheritance ($V'+S\rightarrow I$)
\end{hypothesis}\label{hypothesis-2}

\section{Predictions}\label{predictions}


In a stable or unchanging environment our prediction is that:

\begin{enumerate}
\item Average inheritance will tend towards perfect inheritance.
\item Population variance for inheritance will decrease more than chance.
\end{enumerate}

Under changing environmental conditions, where the fitness of an unchanging entity varies in response to environmental changes, we expect:

\begin{enumerate}
\item \emph{Fidelity} at the end of a run under changing conditions will be less than that under fixed conditions.
\item The \gls{sd} of final fidelity under changing conditions will be greater than that under stable conditions.
\item The higher the variability in the environment, the higher the \gls{sd} of \emph{Fidelity}.
%\item The final population \emph{Fitness} will be in the the range described by the distribution applied in the $tweakFitness$ function.
\end{enumerate}

\section{Alternative explanations}\label{alternative-explanations-1}

The three main alternatives, examined later in \cref{elimination-of-alternative-explanations} are:

\begin{enumerate}
\item Variation alone is sufficient for Inheritance ($V\rightarrow I$.)
\item Selection alone is sufficient for Inheritance ($S\rightarrow I$.)
\item \emph{Variation} and \emph{Selection}, without trait or property correlation, is sufficient for \emph{Inheritance}.
\end{enumerate}


\chapter{Practical considerations}\label{practical-considerations}

In the absence of any restrictions on population size there is nothing to prevent a growing population eventually exceeding the capacity of the simulation system. This is unfortunately an unavoidable difficulty in experiments with exponential growth systems rather than a limitation of the theoretical model. 

The size of the population is determined by how population elements are introduced and removed. In standard Evolutionary Computation (\eg \textcite[50]{DeJong2006}) the choice of strategy is important to the performance and outcomes of the algorithm. New elements can be straight replacements, like-for-like, of their parent, or be placed in competition against elements in the parent population, or completely replace the parent population. Elements may be removed as a result of selection, or through fitness-independent sampling to maintain a particular population size, or through some end-of-life calculation. The population size limit may act as both upper and lower bound on population size to maintain a specific size, or solely as upper bound.

Similar considerations apply to our model. Because we observe that the population size increases exponentially in many experimental runs (e.g., righthand side of \cref{fig:unboundedplot}), some restriction on population size is needed, and it's important that we eliminate the possibility of introducing bias to the results from the mechanism used to control population size.

In \textcite{Gaucherel2012} the approach is to remove individuals from the population stochastically, with probability related to $e$ to the negative power of the population size multiplied by a configurable parameter, $\mu$. In the ``canonical'' Evolutionary Computation algorithm, a population limit results from selection where a set number of elements is extracted from the original population, with elements chosen by one of a wide range of selection algorithms (among many sources, see overviews in \textcite[sect. 4.3.1]{DeJong2006} and \textcite[sect. 4.2]{Vose:1999di}.) Here though we separate the selection function from the population size limit in order to qualify the effect of the specific limiting mechanism used.

The goal of this section is to:

\begin{enumerate}
	\item Confirm that an upper bound on population size is required,
	\item Decide if the choice of method for maintaining the bound might significantly affect any conclusions from the hypothesis tests, and if it might:
	\item Determine which method to use for the remaining experiments.
\end{enumerate}

If there is an affect on the hypothesis tests attributable to the bound mechanism, then the conclusions from the test become contingent on the method. This reduces the scope somewhat, but without a change of investigative approach seems unavoidable.

\subsection{Effect of population limits}
<<pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
df <- subset(load.results('results/results-819350e-unrestricted.data'), ecf==0)
@

The environment is considered ``fixed'' (that is, each element's fitness value does not change); the initial population consists of \Sexpr{df[1,]['pop']} elements, and the model run with a maximum of \Sexpr{max(df['gen'])} generations with factors as follows:

The factors and levels along with their mapping to model parameters are given in \cref{tbl:factor-levels-c5}.

\begin{table}
	\caption{Factors mapped to model parameters, plus factor levels}\label{tbl:factor-levels-c5}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{2cm}p{6cm}@{}}
		\toprule
		Factor                 &Model parameter		&Number of Levels 	& Levels\\
		\midrule
		$p_{reproduction}$     &$p_{reproduction}$	&2                	& 0.66 or $fitness$\\
		$p_{selection}$        &$p_{selection}$		&2                	& 0.66 or $fitness$\\
		$n_{children}$         &$n_{children}$ 		&2                	& 2 or 5\\
		Reproduction		   &Reproduction		&2				 	& Correlated and Uncorrelated (see \cref{reproduction-distribution-factors-c5})\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}\label{reproduction-distribution-factors-c5}
	\caption{Levels for the factor \emph{Reproduction}}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{7cm}@{}}
		\toprule
		Reproduction&Child entity parameter					&Shape of normal distribution ($\mathbb{N}$)\\
		\midrule
		\multirow{2}{*}{Correlated}		&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=1-fidelity$\\
		
		\multirow{2}{*}{Uncorrelated}	&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=\mathcal{U}[0, 1.0]$\\
		\bottomrule
	\end{tabular}
\end{table}

<<unboundedplot, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.cap='The growth of population size grouped by replicate (that is, by common factor levels) showing rapid population growth before the population size exceeded the specified limit of 50,000 entities.'>>=
#ap <- ggplot(aggregate(df$gen,Filter(is.factor,df),max), aes(x))+geom_histogram(binwidth=1,boundary = .5) + labs(x="Final generation", y="Count of Runs") + scale_x_continuous(breaks=1:12) + scale_y_continuous(limits=c(0,2),breaks=c(0,1,2))

ggplot(df,aes(x=gen,y=pop,group=exp)) + geom_point() + scale_x_continuous(breaks=1:100) + labs(x="Generation", y="Population size") + geom_smooth(method="loess")
#grid.arrange(ap,bp,nrow=1,ncol=2)
@

Under these initial conditions, no experiment without an upper population bound continued for more than a handful of generations before the population size reached more than ten times the initial size. It is clear from \cref{fig:unboundedplot} that some form of upper bound is necessary.
s
\subsection[Choice of limit mechanism]{Is the choice of limit mechanism significant?}

Given then that an upper bound is needed for practicality, this section describes two possible approaches to the implementation of the \emph{Restriction} function in \cref{upper-bound-model-algorithm} and attempts to understand the form of the bias each introduces into the experimental results.

\begin{algorithm}
	\For{each generation $\in [1\dots$number of generations]}{
		$population\leftarrow Selection(population)$\;
		$population\leftarrow population \cup Variation(population)$\;
		$population\leftarrow Restriction(population)$\;
		\BlankLine
		\lIf{$population$ size is too small}{break}
	}
	\caption{Algorithm for the Model with an upper bound on population size. The \emph{Restriction} function is the only difference with the base model.}\label{upper-bound-model-algorithm}
\end{algorithm}

The first approach is to take a random sample of $n$ elements from the population, without regard for fitness (that is, fitness-independent sampling), while the other is to adopt the \emph{truncation} mechanism (described in \textcite[124]{DeJong2006} alongside others) as representative (although strongly elitist) of a fitness-based mechanism (henceforth called fitness-based selection).

It might be argued that \emph{truncation} is too extreme to make a fair comparison. However, without an accepted scheme to order selection algorithms along a dimension of interest, such as selection pressure, it's hard to justify oversetting it by an alternative. The key criteria is whether the conclusions drawn from any particular algorithm can be extended to a more general conclusion, independent of the specifics of the algorithm or algorithms used. The specificity of selection algorithms means this a difficult argument to make, and most likely only possible by examining a number of them, which is beyond the scope of this work.

Returning then to our examination of fitness-independent and fitness-based upper bounds against the unlimited control case, the null, H$_0$, and alternative hypothesis, H$_1$, are as follows (examined for both population mean fitness and fidelity) :

\begin{itemize}[label={}]
	\item H$_0$: the two samples are drawn from the same continuous distribution
	\item H$_1$: the two samples are not drawn from the same continuous distribution
\end{itemize}

\subsubsection{Fitness-independent sampling}\label{fitness-independent-sampling}

The bound is implemented by a fitness-independent sampling of $n$ elements from the population (as given in the $Restriction$ function in \cref{upper-bound-model-algorithm}), if and only if the pre-sampling population size is greater than $n$.

\begin{algorithm}
	\Def{Restriction(population,n)}{
		\Return $\text{random sample of }n\text{ elements from }population$\;
	}
	\caption{Restriction (Fitness-independent sampling)()}
\end{algorithm}

%If we compare fitness-independent sampling to the control case without limits, we conclude that fitness independent sampling does indeed make a difference to the results, confirming the earlier visual assessment from the box and \gls{qq} plots (\cref{}.) This is somewhat unexpected as the average fitness before and after the application of the mechanism is, within sampling error, unchanged. It seems that the difference between limited and unlimited populations might come instead from the differences in population size in the selection and reproduction steps of the model rather than from any fitness-modifying actions of the restriction mechanism.

\subsubsection{Fitness-based selection}

The fitness-based population limit is based on \emph{truncation} from \textcite[124]{DeJong2006}, chosen as it is reasonably representative of methods used in Evolutionary Algorithms, and as a highly-elitist algorithm should provide useful contrast to the effectively uniform mechanism of \cref{fitness-independent-sampling}. If the two mechanisms produce similar results then it might be argued that other mechanisms are likely to be similar also.

It also recognizes that in both Evolutionary Computation and natural populations, the population limit is a function of the carrying capacity of the environment and fitness determines the selection.

\begin{algorithm}
	\Def{Restriction(population,n)}{
		$sortedPopulation\leftarrow$ sorted population by element fitness, in decreasing order \;
		\Return $\text{first }n\text{ elements from }sortedPopulation$\;
	}
	\caption{Restriction (Fitness-based selection)()}
\end{algorithm}

\subsection{Experimental design}

<<echo=FALSE, cache=TRUE>>=
df <- subset(load.results.simple('results/results-53f6b74.data'), environment_change_frequency == 0)
runs <- nrow(subset(df,gen==0))
factors <- nrow(unique(Filter(is.factor,df)))
replicates <- runs / factors
df_completed <- subset(df, gen==500)
@

Data is from \Sexpr{nrow(subset(df,gen==0))} runs -- \Sexpr{factors} unique sets of factors, each with \Sexpr{replicates} replicates--with settings from \cref{tbl:factor-levels-c5}, of which we are exclusively concerned with the subset of \Sexpr{nrow(df_completed)} runs that reached completion at \Sexpr{max(df['gen'])} generations.

\subsection{Results and discussion}

The runs that reached completion are evenly distributed between the two methods, fitness-independent (\Sexpr{nrow(df_completed[df_completed['truncate']==0,])} runs) and fitness-based (\Sexpr{nrow(df_completed[df_completed['truncate']==1,])} runs), indicating that the two methods at least appear comparable with respect to their affect on population size.

<<limitcomparisonplots, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Summary plots for fitness-independent sampling ("Independent") and fitness-based or dependent selection ("Dependent"), where the top line contains density plots and the bottom line boxplots showing ranges for both final mean fidelity (on the left-hand side) and final mean fitness (on the right).'>>=
df_completed$truncate <- factor(df_completed$truncate, labels=c("Independent","Dependent"))
ap <- qplot(ave_cor, facets=truncate ~ ., geom="density", data=df_completed, xlab="Fidelity", ylab="Density")
bp <- qplot(ave_fit, facets=truncate ~ ., geom="density", data=df_completed, xlab="Fitness", ylab="Density")
cp <- qplot(truncate, ave_cor, geom="boxplot", data=df_completed, xlab="",ylab="Fidelity")
dp <- qplot(truncate, ave_fit, geom="boxplot", data=df_completed, xlab="",ylab="Fitness")
grid.arrange(ap,bp,cp,dp,nrow=2,ncol=2)
@

<<limitqqplots, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='\\Gls{qq} plots comparing fitness-independent and fitness-based or dependent results for fidelity (left) and fitness (right).'>>=

myqqplot <- function(x,y,...) {
sx <- sort(x)
sy <- sort(y)
lenx <- length(sx)
leny <- length(sy)
if (leny < lenx)
sx <- approx(1L:lenx, sx, n = leny)$y
if (leny > lenx)
sy <- approx(1L:leny, sy, n = lenx)$y
qplot(sx,sy,...)
}

df_independent <- subset(df_completed,truncate=="Independent")
df_dependent <- subset(df_completed,truncate=="Dependent")
ap <- myqqplot(sort(df_independent$ave_cor), sort(df_dependent$ave_cor), main="Final mean fidelity", xlab="Independent",ylab="Dependent")
bp <- myqqplot(sort(df_independent$ave_fit), sort(df_dependent$ave_fit), main="Final mean fitness", xlab="Independent",ylab="Dependent")
grid.arrange(ap,bp,nrow=2,ncol=1)
@

%Standard non-parametric tests include Wilcoxon and Mann-Whitney for comparing two
%independent continuous random samples where the underlying distributions
%are known to have essentially the same shape, or a Friedman test where the samples might be related (\eg in block %experiment designs) and the objective is to distinguish differences between treatments.

<<kstest, warning=FALSE, pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
x_cor <- ks.test(df_independent$ave_cor, df_dependent$ave_cor)
x_fit <- ks.test(df_independent$ave_fit, df_dependent$ave_fit)
@

Applying a two-sample Kolmogorov-Smirnov test to determine if the results for each method are taken from the same distribution provides strong evidence (for population mean fidelity, approx. p-value=\Sexpr{round(x_cor$p.value,2)} and for pop. mean fitness, approx. p-value=\Sexpr{round(x_fit$p.value,2)}) to reject the null hypothesis, confirmed by visual inspection of \cref{fig:limitcomparisonplots} and \cref{fig:limitqqplots}. The distributions produced by the two methods are different for both average fidelity and average fitness.

From these tests it is clear that the two methods do not have statistically similar effects for both fidelity and fitness, and hence we cannot find support for the contention that our conclusions in the hypothesis tests can be made without extensive consideration of limit method. Method is important, and our conclusions are dependent on the method chosen.

This conclusion of course is based on a comparison of two particular methods; a third, fitness-based, method may produce distributions that are statistically similar to those of, say, sampling. In which case we might conclude that any conclusions drawn on the basis of sampling would also extend to this third method. This extension however is left for future work.

Returning to our goal, as the choice of method affects our results and for practical reasons we must make a choice, it seems reasonable to choose a method that has as small an influence as possible on the conclusions we draw from our hypothesis tests. As our tests involve fitness, a method that is by design orthogonal to fitness is the better choice. A sampling method is a better fit for this than a selection method, which biases on fitness, and therefore we adopt fitness-independent sampling rather than fitness-based restriction.

\chapter{Characterizing the parameter space for the experiments}\label{reducing-the-parameter-space-for-the-experiments}

Translating model parameters into factors in the experiment design results in the factors in the first column of \cref{tbl:factor-levels-c6}. As is usual with exploratory experiments with a number of parameters, where each run of the model has some cost in time or other resources, the key problem is to understand the relationship between parameters and response variables at an acceptable cost. In this case, our main cost is time - each run of an evolutionary model is cheap in resources but takes a little time. Exhaustively sampling the entire parameter space is unrealistic. Therefore, we first reduce the search space by limiting the number of values that each parameter can take. By choosing these values appropriately, we can construct an analysis model from the results that is sufficiently accurate for our exploratory purposes at a greatly reduced cost in time.

\section{Experimental design}

As our interest is in the sensitivity of the model to each parameter, a factorial design is preferred (as described in \cref{approach}). 

%A full factorial design with seven 2-level factors would require testing $2^{7}$ combinations of factor values, or 128 sets of replicated runs, while a $2^{(7-3)}$ fractional factorial design \parencite{Montgomery2009}\footnote{\eg  \url{http://www.itl.nist.gov/div898/handbook/pri/section3/eqns/2to7m3.txt}} can reduce this to 16 sets of replicated runs without loss of validity on the assumption that 3-factor interactions and higher are not significant. In other words, a $2^{(7-3)}$ design is sufficient to separate the main effect from any 2-factor interactions. This seems a reasonable tradeoff between discriminatory power and the total number of runs required, given our goal is to eliminate uninteresting settings for the next set of experiments. Note also that as each level of each factor occurs the same number of times in the results, the design remains ``balanced'' in the statistical sense, greatly easing analysis.

\section{Factors and levels}\label{factors-and-levels}

Although several parameters in the model are continuous, at this stage the main ones can be reduced to a set of A/B alternatives, or two-level factors. $P_{reproduction}$ and $p_{selection}$ take four levels each to cover a reasonable range given the usual sensitivity of evolutionary models to these type of parameter, with three absolute values (0.33, 0.66 and 1.0) irrespective of fitness, and one meaning ``use the parent's value for this parameter.'' 

Where one or both parameters are set to use the parent's value, the model is similar to a standard EA, and when both are fixed the major source of variation has been removed from the model and so the behaviour is uninteresting. But what about the case where only one value is fixed; is that still interesting? Imagine the scenario where selection has the value $1.0$ while reproduction takes value $0$ - parents always survive to the next generation (subject to any population limits naturally), while producing children at each generation with a probability proportional to their fitness. Or reverse these values ($p_{selection} = 0$ while $p_{reproduction} = 1.0$), giving a run where parents always produce a fixed number of $n_{offspring}$ children at each generation, but their own survival rate is proportional to their fitness. Both cases are non-trivial and so should be examined in our experiments, along with the primary case where both are based on the parent's setting.

The factors and levels along with their mapping to model parameters are given in \cref{tbl:factor-levels-c6}.

\begin{table}
	\caption{Factors mapped to model parameters, plus factor levels}\label{tbl:factor-levels-c6}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{2cm}p{6cm}@{}}
		\toprule
		Factor                 &Model parameter		&Number of Levels 	& Levels\\
		\midrule
		$p_{reproduction}$     &$p_{reproduction}$	&4                	& 0.33 or 0.66 or 1.0 or $fitness$\\
		$p_{selection}$        &$p_{selection}$		&4                	& 0.33 or 0.66 or 1.0 or $fitness$\\
		$n_{children}$         &$n_{children}$ 		&2                	& 2 or 5\\
		Reproduction		   &Reproduction		&2				 	& Correlated and Uncorrelated (see \cref{reproduction-distribution-factors-c6})\\
		Distribution           &Reproduction		&2                	& Normal distribution ($\mathbb{N}$) or Uniform distribution ($\mathcal{U}$) (see \cref{reproduction-distribution-factors-c6})\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}\label{reproduction-distribution-factors-c6}
\caption{Levels for the factor \emph{Reproduction} against factor levels for \emph{Distribution}}
\begin{tabular}{@{}p{2.5cm}p{2.5cm}p{6cm}p{2.5cm}@{}}
\toprule
&&\multicolumn{2}{c}{Shape of distribution}\\
Reproduction&Child entity parameter					&Normal distribution								&Uniform distribution\\
\midrule
\multirow{2}{*}{Correlated}		&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$				&$\mathcal{U}[0, 1.0]$\\
								&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=1-fidelity$	 			&$\mathcal{U}[0, 1.0]$\\

\multirow{2}{*}{Uncorrelated}	&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$				&$\mathcal{U}[0, 1.0]$\\
								&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=\mathcal{U}[0, 1.0]$	&$\mathcal{U}[0, 1.0]$\\
\bottomrule
\end{tabular}
\end{table}

The design is complicated a little by the fact that two factors - $p_{reproduction}$ and $p_{selection}$ - require more than two levels. Fortunately a $2^n$ fractional design can be extended relatively simply to include 4-level factors (\textcite[368]{Montgomery2009}) either by replacement where each 4-level factor is mapped to two 2-level ones, or, as we choose to do, by a hybrid full-fractional design, where we use combinations of our four-level factors, $p_{reproduction}$ and $p_{selection}$, for two of the two-level factors, X1 and X2, of the standard $2^{(7-3)}$ design. This may not be quite as computationally efficient as a complete mixed-levels fractional factorial design but is efficient enough and meets our purposes. 

Based on preliminary runs, we begin with an initial estimate of 10 replicates for each combination of factor values given in the design. 
%The number of \glspl{replicate} required for a particular statistical power is related to the \gls{sd} of the response variable. 

\section{Initial conditions and settings}\label{initial-conditions}
Before each run we construct an initial population. From the hypothesis \cref{hypothesis-2}, we expect to see a population of low fidelity entities eventually replaced by one of high (or at least higher) fidelity ones. This is analogous to a key step on the path taken in biology from the abiotic world, where early copy mechanisms lacked the capabilities for high-fidelity copying, but developed it over time. Entities begin with an initial fidelity $\in\mathcal{U}[0, 0.3]$ and fitness $\in\mathcal{U}[0, 0.3]$ chosen randomly from a uniform distribution so as not to introduce any bias that might result from a repeated starting point. 

\section[Sensitivity to probability of reproduction]{Sensitivity to the parameter $p_{reproduction}$}
The parameter $p_{reproduction}$ in the simulation model is either related to the entity's fitness, or is set to a fixed value for all entities, irrespective of their fitness. We would expect, based on the substantial literature in \gls{ea}, that our simulation model would be highly sensitive to the value of this parameter. 



\section[Sensitivity to probability of selection]{Sensitivity to the parameter $p_{selection}$}
The simulation model parameter $p_{selection}$ closely follows the definition of $p_{reproduction}$--related to entity fitness, or a fixed value. Again, we expect that the model will be sensitive to the value of this parameter.

\section[Sensitivity to number of offspring]{Sensitivity to the parameter $n_{offspring}$}

<<pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
df <- subset(load.results.simple('results/results-53f6b74.data'), environment_change_frequency == 0)
@

<<popoffspring, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Population size over time for two values of parameter $n_{children}$ - 2 (on the left) and 5 (on the right) .'>>=
temp <- subset(df,n_offspring==1 & pop < 5000)
df$n_offspring = factor(df$n_offspring, labels=c("2","5"))
ggplot(df) + geom_point(aes(x=gen,y=pop), size=0.25) + labs(x="Generation", y="Population size") + facet_wrap(~n_offspring)
@

The vertical line on the extreme left of the right-hand side facet of \cref{fig:popoffspring} (for $n_{offspring} = 5$) consists of \Sexpr{nrow(subset(temp,gen==1))} runs from a total of nrow(subset(df,gen==0)) where the population dropped in the first generation to a mean size of \Sexpr{mean(subset(temp,gen==2)$pop)}, before recovering to the population upper limit by generation \Sexpr{max(temp['gen'])+1}. This is a characteristic of the initial conditions: runs where $n_{offspring} = 2$ and the probability of reproduction or selection is low, either because the parameter has a low, fixed, value or because they are derived from the parent's value, suffer high selection and low reproduction initially. Taking the case where both are given by the parent's value, $p_{reproduction} = p_{selection} = $\Sexpr{mean(subset(df,gen==0)$ave_fit)}. The difference between the two facets can be explained by the higher reproduction rate in the right-hand facet.

A similar effect can be seen in the left-hand side facet for $n_{offspring} = 2$ where some of the affected runs recovered while others went to extinction.

\section{Sensitivity to the parameter Reproduction}
The parameter $Reproduction$ describes the relationship between the properties of an entity and the properties of the related entity from which it is derived. In the simulation model this parameter is completely general, defined only as a mapping from $entity$ to $entity$. In attempting to characterize the sensitivity of the model to this parameter, we introduce two linked factors of two levels each, \emph{Reproduction} and \emph{Distribution}, that in combination map to the parameter $Reproduction$.

The factor \emph{Reproduction} from \cref{tbl:factor-levels-c6} describes two forms of relationship between parent and child entity. The first is ``correlated'' where the value of each child property has some significant relationship or correlation to the same property in the parent. A simple example of correlated properties from biology might be height: the height of a child at adulthood has a statistically significant correlation with the height of his or her parent. The second relationship is ``uncorrelated'' where the child property value is chosen independently of the parent's value. Our expectation is that the simulation model will prove sensitive to the choice of level for \emph{Reproduction}.
<<pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
df <- subset(load.results.simple('results/results-53f6b74.data'), environment_change_frequency == 0)
@

The factor \emph{Distribution} describes a function to return a value in the range $[0,1]$ given two input values, also in the range $[0,1]$, where the first is for the expected value of the result, and the second describes a range. Obvious candidates for \emph{Distribution} include probability distributions, where the function samples a value from a distribution. If the distribution is normal, the two parameters to \emph{Distribution} equate to its mean and variance. For other probability distributions, the parameters are distribution specific. For example, for a uniform distribution, the parameters have no influence on the output; the output will be a value in the range $[0,1]$ drawn randomly with equal probability, regardless of input parameters.

As \emph{Distribution} is used by \emph{Reproduction} to influence the relationship between the properties of an entity and its offspring, it seems plausible to hypothesise that different mapped shapes may have a significant effect on the experimental result.

Where the underlying probability isn't inherently limited to the output range of $[0,1]$, such as is the case for the normal distribution, then the mechanism used to map the underlying distribution to the output range may modify the probability distribution of the mapped values. Two out of many possible mappings are a straightforward bounded algorithm ($max(0,min(1,normal(mean,variance)))$), and a sampling algorithm:

\begin{algorithm}[H]
\Repeat{for ever}{
	$x \leftarrow$ normal($mean,variance$)\;
	\If{$x\geq 0$ and $x\leq 1$}{
	 \Return $x$\;
	}
}
\end{algorithm}
	
A visualisation of the results of these two algorithms alongside the unmapped normal distribution is given in \cref{fig:example_distributions}. The bounded algorithm produces a distribution with fat tails (middle of \cref{fig:example_distributions}), like a 'W', rather than the expected bell-shape of the standard normal distribution (on the left-hand side of the same figure), while the sampling algorithm distribution appears closer in shape to the unmapped distribution while mapping correctly to the output range. Note that neither shape though is ``wrong'' or ''right'', as the only requirements for the \emph{Distribution} are that it meets $[0,1]x[0,1]\mapsto [0,1]$, which is true of all of these described mappings.

<<example_distributions, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Effect of folding to range $[0,1]$ of normal distribution with mean = 0.5, standard deviation = 0.5'>>=
x <- rnorm(n=10000, mean=0.5, sd=0.5)
ap <- qplot(x,geom='density') + coord_cartesian(xlim=c(-1,2),ylim=c(0,1.6)) + labs(x="Normal distribution")
bp <- qplot(sapply(sapply(x,min,1.0),max,0),geom='density') + coord_cartesian(xlim=c(0,1),ylim=c(0,1.6)) + labs(x="Bounded normal")

x1 <- replicate(10000, {
repeat {
x <- rnorm(n=1,mean=0.5, sd=0.5)
if (x >=0 & x<=1)
break
}
x
})
cp <- qplot(x1,geom='density') + coord_cartesian(xlim=c(0,1),ylim=c(0,1.6)) + labs(x="Sampled normal")
grid.arrange(ap,bp,cp,nrow=1,ncol=3)
@

<<normal-uniform, pdfcrop=TRUE, echo=FALSE, cache=TRUE, out.width='0.45\\linewidth',fig.show='hold'>>=
df$distribution = factor(df$distribution, labels=c('Bounded normal','Uniform'))
ggplot(df) + geom_boxplot(aes(x=distribution,y=ave_cor)) + labs(x="Distribution", y="Final mean fidelity")
ggplot(df) + geom_boxplot(aes(x=distribution,y=ave_fit)) + labs(x="Distribution", y="Final mean fitness")
@

From a visual inspection of \cref{fig:normal-uniform}, we conclude that the results appear very similar for uniform and normal distributions, and from \cref{fig:sampling-folding} so do the bounded normal and sampled normal distributions. 

A more rigorous analysis would both use a factorial design to compare all six combinations (correlated:uncorrelated x uniform:normal bounded:normal sampled), and would use a formal test of similarity but at this stage this can be left for future work.

<<sampling-folding, pdfcrop=TRUE, echo=FALSE, cache=TRUE, out.width='0.45\\linewidth',fig.show='hold'>>=
temp <- subset(load.results('results/results-819350e.data'), ecf==0 & truncate == 0)
temp$distribution = factor(temp$distribution, labels=c('Bounded normal','Sampled normal'))
ggplot(temp) + geom_boxplot(aes(x=distribution,y=ave_cor)) + labs(x="Distribution", y="Final mean fidelity")
ggplot(temp) + geom_boxplot(aes(x=distribution,y=ave_fit)) + labs(x="Distribution", y="Final mean fitness")
@

\section{Conclusions}
\begin{DRAFT}
Independent variable is Fidelity correlation, the main factor of interest from hypothesis

Dependent variables, to qualify the sensitivity of the model:
\begin{enumerate}
	\item Distribution
	\item Number of offspring
\end{enumerate}

Set remaining parameters based on these screening experiments:
\begin{enumerate}
	\item Upper-size bound - sampling % truncate == 0
	\item Lower-size bound - sustainable populations % gen for run == max gen, and pop at max gen > 1000
	\item Probabilities - at least one of $p_{reproduction}$ and $p_{selection}$ is related to the parent's fitness (\ie the factor level has the special case value of 0.)      	
\end{enumerate}
\end{DRAFT}
\chapter[Model behaviour in stable conditions]{Experimental test of hypothesis under stable conditions}\label{experimental-test-of-h2-under-fixed-conditions}

Returning to the overall goals for these experiments (to test the predictions of hypothesis \cref{hypothesis-2}, and to examine the impact of the factors on the results), hypothesis \cref{hypothesis-2} makes two predictions for stable environments:

\begin{enumerate}
	\item Average inheritance will tend towards perfect inheritance, confirming a result of \textcite{Bourrat2015}.
	\item The variance of inheritance in the population will decrease more than would be expected by chance alone.
\end{enumerate}

The first test therefore is to examine if inheritance emerges from low-fidelity and low-fitness initial conditions, and then the second test is whether the population variance for inheritance decreases as predicted. Remember that as discussed earlier, inheritance is the outcome of the relationship between parent and child traits, as represented by the measure of fidelity.

\section{Does average inheritance approach perfect inheritance?}\label{does-average-inheritance-approach-perfect-inheritance}

We start with the following null and alternative hypotheses:

\begin{itemize}[label={}]
	\item H$_0$: fidelity does not approach 1.0 during a run, irrespective of factor values, or \newline
 $\vert \overline{fidelity}_{end}-\overline{fidelity}_{start} \vert = 0$
	\item H$_1$: fidelity increases to near 1.0 during a run, for some factor values, or \newline
 $\overline{fidelity}_{end}-\overline{fidelity}_{start} > 0$ and $1.0-\overline{fidelity}_{end} < \delta$ for some $\delta$ and for some factor values.
\end{itemize}

\section{Response variables}\label{response-variables}

From the predictions of the hypothesis (\cref{predictions}), the main property of interest is \emph{fidelity}, or the correlation between parent and child property values. \emph{Fidelity} therefore is our response variable. Specifically we use $\overline{fidelity}_{end}$, or the mean value for \emph{fidelity} (across all replicates) at the end of a run, as under hypothesis \cref{hypothesis-2} we expect $\overline{fidelity}_{end}$ to approach 1.0 in an unchanging environment.

\section{Design}\label{design}
<<pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
df_full <- load.results('results/results-819350e.data')
df <- subset(df_full, ecf==0 & truncate == 0 & (p_reproduce==0 || p_selection == 0))
@

The factors and levels along with their mapping to model parameters are given in \cref{tbl:factor-levels-c7}.

\begin{table}
	\caption{Factors mapped to model parameters, plus factor levels}\label{tbl:factor-levels-c7}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{2cm}p{6cm}@{}}
		\toprule
		Factor                 &Model parameter		&Number of Levels 	& Levels\\
		\midrule
		$p_{reproduction}$     &$p_{reproduction}$	&2                	& 0.66 or $fitness$\\
		$p_{selection}$        &$p_{selection}$		&2                	& 0.66 or $fitness$\\
		$n_{children}$         &$n_{children}$ 		&2                	& 2 or 5\\
		Reproduction		   &Reproduction		&2				 	& Correlated and Uncorrelated (see \cref{reproduction-distribution-factors-c7})\\
		Distribution           &--					&2                	& Folded normal distribution or sampled normal distribution\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}\label{reproduction-distribution-factors-c7}
		\caption{Levels for the factor \emph{Reproduction}}
		\begin{tabular}{@{}p{2.5cm}p{3cm}p{7cm}@{}}
		\toprule
		Reproduction&Child entity parameter					&Distribution shape\\
		\midrule
		\multirow{2}{*}{Correlated}		&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=1-fidelity$\\
		
		\multirow{2}{*}{Uncorrelated}	&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=\mathcal{U}[0, 1.0]$\\
		\bottomrule
	\end{tabular}
\end{table}

%\begin{table} % 5e33a27 and 819350e
%	\begin{center}
%		\caption{Factor levels for testing the hypothesis prediction of perfect inheritance in unchanging conditions}
%		\begin{tabular}{@{}llp{6cm}@{}}
%			\toprule
%			Parameter              & Number of Levels & Levels                                                   \\
%			\midrule
%			$p_{reproduction}$     & 2                & 0 or 0.66                                                \\
%			$p_{selection}$        & 2                & 0 or 0.66                                                \\
%			$n_{children}$         & 2                & 2 or 5                                                   \\
%			Population Restriction & 2                & Fitness-independent sampling or fitness-based truncation \\
%			Distribution           & 2                & normal dist., $\mathbb{N}$ or folded normal          \\
%			Correlate Fidelity     & 2                & false or true                                            \\
%			Shape of environment change		2&	Abrupt or continuous\\
%			\bottomrule
%		\end{tabular}
%	\end{center}
%\end{table}

\section{Results and discussion}

%df <- subset(load.results.simple('results/results-53f6b74.data'), environment_change_frequency == 0 & truncate==0)
<<popoverall, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Not all runs in fixed conditions can maintain a substantial population size over time. The horizontal line at the top of the figure is from runs that were capped by the population upper-bound, while the great majority of unsustainable runs fall within the asymptotically decreasing band from top-left to bottom-right. Note the extreme case represented by the almost vertical set of points to the far left, discussed in the text.'>>=
ggplot(df_full) + geom_point(aes(x=gen,y=pop),size=0.25) + labs(x="Generation", y="Population size")
@

Of the \Sexpr{nrow(subset(df_full,gen==0))} experiment runs, \Sexpr{nrow(subset(df_full, gen==max(df_full['gen'])))} reached the experiment limit of \Sexpr{max(df_full['gen'])} generations. Note that these results also provide one point of validation for the choice of 500 generations as the limit. From \cref{fig:popoverall}, all runs have approached the population size limit by approximately 300 generations, and by generation \Sexpr{max(df_full['gen'])} they are well into a second phase where the size is relatively stable at around that limit.

Our interest is in the final values for fidelity under fixed-environment conditions. Therefore, the data in the following analysis is from the final generation of those fixed-environment runs that reached the limit at generation \Sexpr{max(df['gen'])}; a total of \Sexpr{nrow(unique(df['run']))} runs out of the full dataset of \Sexpr{nrow(unique(df_full['run']))} runs.

<<lowstart, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Summary results, showing on the left-hand side an overview for the final mean fidelity ($\\overline{fidelity}_{end}$) for each run and a density plot showing the distribution of $\\overline{fidelity}_{end}$. The right-hand side shows the corresponding plots for final mean fitness ($\\overline{fitness}_{end}$)'>>=
ap <- qplot(row.names(df),ave_cor, geom="point", data=df, xlab='Experiment run',ylab="Final ave. fidelity") + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank())
bp <- qplot(row.names(df),ave_fit, geom="point", data=df, xlab='Experiment run',ylab="Final ave. fitness") + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank())
cp <- qplot(ave_cor, geom="density", data=df, xlab="Final ave. fidelity",ylab="")
dp <- qplot(ave_fit, geom="density", data=df, xlab="Final ave. fitness",ylab="")
grid.arrange(ap,bp,cp,dp,nrow=2,ncol=2)
@

<<lowstartbyfactor, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Summary results, this time averaged across all replicates of each factor combination (that is, grouped by replicate). Dark-coloured points represent values at end of run; light-coloured points are for initial values. Missing points are from those replicates that did not complete.'>>=
ap <- ggplot(subset(df,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=ave_cor, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='Factor combination', y='Mean fidelity') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
bp <- ggplot(subset(df,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=ave_fit, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='Factor combination', y='Mean fitness') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
cp <- ggplot(subset(df,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=sd_cor, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='', y='SD fidelity') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
dp <- ggplot(subset(df,gen==0 | gen==500)) + geom_boxplot(aes(x=factor(exp),y=sd_fit, colour=factor(gen))) + scale_colour_manual(name="", values=c("grey80", "grey10")) + labs(x='', y='SD fitness') + theme(axis.ticks.x=element_blank(), axis.text.x = element_blank(), legend.position='none')
grid.arrange(ap,bp,cp,dp,nrow=2,ncol=2)
@

<<pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
df <- subset(load.results('results/results-5e33a27.data'), ecf==0 & truncate == 0 & (p_reproduce==0 || p_selection == 0))
@

The first hypothesis prediction is that average fidelity will tend towards exact inheritance, or $1.0$. A simple visual inspection of this data in \cref{fig:lowstart} reveals that the fidelity measure is distinctly bimodal, with peaks around final mean fidelity values 0.5--0.6 and 1.0. Fitness is also bimodal, but less so than fidelity. From inspection, it seems clear that fidelity does approach 1.0 for some combination of factor levels.

<<lowstartfactors, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Comparison between correlated and uncorrelated values for the factor \\textbf{Correlate Fidelity} showing results for final mean fidelity ($\\overline{fidelity}_{end}$, on the left) and final mean fitness ($\\overline{fitness}_{end}$, on right)'>>=
df$correlation_correlation <- factor(df$correlation_correlation, labels=c('false','true'))
ap <- ggplot(df) + geom_boxplot(aes(x=correlation_correlation,y=ave_cor)) + labs(x='Final mean fidelity',y='')
bp <- ggplot(df) + geom_boxplot(aes(x=correlation_correlation,y=ave_fit)) + labs(x='Final mean fitness',y='')
grid.arrange(ap,bp,nrow=1,ncol=2)
@

From \cref{fig:lowstartbyfactor}, all runs result in an increase in fidelity from the initial range of $[0, 0.3]$ but only some approach or reach 1.0. Those that do are uniformly associated with the \textbf{Correlate Fidelity} factor value of \emph{true} (see top-left plot in \cref{fig:lowstartfactors}), and those that did not had a \textbf{Correlate Fidelity} value of -1.

In conclusion, H$_0$ can be rejected, and H$_1$ accepted. Inheritance increases regardless of the model design, but is strongest when \textbf{Correlate Fidelity} is \emph{true}, that is, when the child's fidelity is correlated with that of its parent.

\section{Does the variance of inheritance decrease over time in the population?}

The second prediction of the hypothesis is that the population variance for inheritance ($\sigma_{fidelity}$) should decrease over time towards a limit of $0$ in fixed environments.

\begin{itemize}[label={}]
	\item H$_0$: $\sigma_{fidelity_{end}}-\sigma_{fidelity_{start}} >= 0$, for all factor values.
	\item H$_1$: $\sigma_{fidelity_{end}}-\sigma_{fidelity_{start}} < 0$, for some factor values.
\end{itemize}

We use the same experimental setup and data as in the previous \nameref{does-average-inheritance-approach-perfect-inheritance}.

<<pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
df_full <- load.results('results/results-819350e.data')
df <- subset(df_full, ecf==0 & truncate == 0 & (p_reproduce==0 || p_selection == 0))
@

<<lowstartranges1, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Smoothed ranges over time of the standard deviation of fidelity (top) and fitness (bottom) for all levels of all factors, broken out by level of \\emph{Correlate Fidelity}. Lines that drop below zero are an artifact of the line smoothing algorithm used (local polynomial regression fitting).'>>=
ap <- ggplot(df,aes(x=gen,y=sd_cor,group=run, colour=factor(correlation_correlation))) + scale_color_manual(name="Correlate\nFidelity", values=c("grey80", "grey10"), labels=c("false","true")) + stat_smooth() + labs(x="Generation", y="Standard Deviation of Fidelity") + theme(legend.key=element_rect(fill="white"))
bp <- ggplot(df,aes(x=gen,y=sd_fit,group=run,colour=factor(correlation_correlation))) + scale_color_manual(name="Correlate\nFidelity", values=c("grey80", "grey10"), labels=c("false","true")) + stat_smooth() + labs(x="Generation", y="Standard Deviation of Fitness") + theme(legend.key=element_rect(fill="white"))
grid.arrange(ap,bp,nrow=2,ncol=1)
@

<<lowstartranges2, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Smoothed ranges for the mean rather than the standard deviation - mean fidelity on the top row, mean fitness below - again by \\emph{Correlate Fidelity}.'>>=
cp <- ggplot(df,aes(x=gen,y=ave_cor,group=run, colour=factor(correlation_correlation))) + scale_color_manual(name="Correlate\nFidelity", values=c("grey80", "grey10"), labels=c("false","true")) + stat_smooth() + labs(x="Generation", y="Mean Fidelity") + theme(legend.key=element_rect(fill="white"))
dp <- ggplot(df,aes(x=gen,y=ave_fit,group=run, colour=factor(correlation_correlation))) + scale_color_manual(name="Correlate\nFidelity", values=c("grey80", "grey10"), labels=c("false","true")) + stat_smooth() + labs(x="Generation", y="Mean Fitness") + theme(legend.key=element_rect(fill="white"))
grid.arrange(cp,dp,nrow=2,ncol=1)
@

Data is all generations for those fixed-environment runs that reached completion at generation \Sexpr{max(df['gen'])}; \Sexpr{nrow(unique(df['run']))} runs out of the full dataset of \Sexpr{nrow(unique(df_full['run']))} runs.

%<<lowstartranges2, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Range of 25\\% to 75\\% quartiles for \\gls{sd} for \\emph{true} setting for factor \\textbf{Correlate Fidelity}'>>=
%z<-by(df,df$gen,function(x) {aggregate(x$sd_cor ~ x$correlation_correlation, data=x, quantile)}) # quantiles aggregated by correlation_correlation
%z1<-apply(z,1,function(x){c(x[[1]][[2]][[2,2]],x[[1]][[2]][[2,3]],x[[1]][[2]][[2,4]])}) # correlation_correlation == -1
%z1<-apply(z,1,function(x){c(x[[1]][[2]][[1,2]],x[[1]][[2]][[1,3]],x[[1]][[2]][[1,4]])}) # correlation_correlation == 1
%z2<-z1[1:3,1:501]
%z3<-as.data.frame(cbind(1:501,z2[1,],z2[2,],z2[3,]))
%ggplot(z3,aes(V1,V2,V3)) + geom_ribbon(data=z3,aes(ymin=V2,ymax=V4), alpha = 0.2) + geom_line(aes(V1,V3))
%@



%<<ExperimentVarianceUnderHighStart, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='High start case: smoothed ranges for standard deviation of fidelity, as before grouped by \\emph{Correlate Fidelity}.'>>=
%ggplot(df,aes(x=gen,y=sd_cor,group=run, colour=factor(correlation_correlation))) + scale_color_manual(name="Correlate\nFidelity", values=c("grey80", "grey10"), labels=c("false","true")) + stat_smooth() + labs(x="Generation", y="Standard Deviation of Fidelity") + theme(legend.key=element_rect(fill="white"))
%@

%\chapter{Factor interactions}
%% EXPERIMENT 7 - Factor significance
%% Dataset: 2860d6fe
%
%<<ExperimentFactorInteractions, pdfcrop=TRUE, echo=FALSE, cache=TRUE>>=
%temp <- load.results('results/results-819350e.data')
%temp <- subset(temp, environment_change_frequency == 0 & truncate==0 & correlation_correlation==1)
%completing_factors <- unique(interaction(Filter(is.factor,temp[temp$gen==500,]))) # the factor levels that resulted in 500 generations
%df <- temp[interaction(Filter(is.factor,temp)) %in% completing_factors,] # raw data in long format - all low-start, fixed
%@
%
%<<lowstartfactorinfluence, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Box-plots for the effect of selected factors on final mean fidelity.'>>=
%#m0 <- lm(ave_cor~(p_reproduce+p_selection+n_offspring+distribution+fitness_correlation)^2, data=df)
%#x <- anova(m0)
%df$p_reproduce <- factor(df$p_reproduce,labels=c(0,0.33,0.66,1.0))
%df$p_selection <- factor(df$p_selection,labels=c(0,0.33,0.66,1.0))
%df$n_offspring <- factor(df$n_offspring,labels=c(2,5))
%df$distribution <- factor(df$distribution, labels=c("normal","uniform"))
%ap <- ggplot(df) + geom_boxplot(aes(x=p_reproduce,y=ave_cor)) + labs(x="Reproduction",y="Final mean fidelity")
%bp <- ggplot(df) + geom_boxplot(aes(x=p_selection,y=ave_cor)) + labs(x="Selection",y="Final mean fidelity")
%cp <- ggplot(df) + geom_boxplot(aes(x=n_offspring,y=ave_cor)) + labs(x="Offspring",y="Final mean fidelity")
%dp <- ggplot(df) + geom_boxplot(aes(x=distribution,y=ave_cor)) + labs(x="Distribution",y="Final mean fidelity")
%grid.arrange(ap,bp,cp,dp,nrow=2,ncol=2)
%@
%% significant with F = \Sexpr{round(x['F value'],2)} and p-value \textless{} \Sexpr{round(x['Pr(>F)'],2)}.
%
%Taking only runs where the factor \textbf{Correlate Fidelity} is \emph{true}, final mean fidelity is significantly influenced by all factors and by the first-level interactions between $p_{reproduction}$ and $n_{children}$, and $p_{reproduction}$ and $Distribution$.
%
%Examining this further, factor-by-factor, where \textbf{Correlate Fidelity} is \emph{true}, from \cref{fig:lowstartfactorinfluence} \TODO{complete}.
%
%\subsubsection{Is the choice of distribution function significant?}\label{distribution-function-1}
%
%normal implies a stronger relationship, uniform a broader range and less correlation. Considerations--connection to other fields -> normal. But uniform would be worst case--good to know conclusions hold even under these conditions.
%
%\begin{itemize}[label={}]
%	\item H$_0$: $\overline{normal} = \overline{uniform}$
%	\item H$_1$: $\overline{normal} \ne \overline{uniform}$
%\end{itemize}
%
%<<distributionfunction, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Comparison of normal and uniform distributions for Factor Distribution.'>>=
%df$distribution <- factor(df$distribution, labels=c("normal","uniform"))
%ap <- ggplot(df) + geom_boxplot(aes(x=distribution, y=ave_cor)) + labs(x="",y="Final mean fidelity")
%bp <- ggplot(df) + geom_boxplot(aes(x=distribution, y=ave_fit)) + labs(x="",y="Final mean fitness")
%grid.arrange(ap,bp,nrow=1,ncol=2,heights=unit(0.5, "npc"))
%@

\chapter{Model behaviour in changing environments}\label{model-behaviour-in-changing-environments}

Alongside our existing evolutionary model we now introduce an environmental model. This model describes the change of fitness resulting from enviromental change at each generation of the evolutionary model. 

Our intuition is that the average fidelity of the population will be inversely related to the degree of environmental change. More specifically, if we consider evolution to be a means by which a population learns how to adapt to an environment, the degree of environmental change can be described as the degree to which it's possible to learn the environment. We intuit that this is related to predictability, and hence to complexity. 

This seems a reasonable supposition. \textcite{Adami2002} recasts population fitness in terms of complexity, specifically his physical complexity measure: ``It is probably more appropriate to say that evolution increases the amount of information a population harbors about its niche (and therefore, its physical complexity)'' \textcite{Adami2002}. \textcite{Prokopenko2009} discusses the information-theoretic view of the benefits of complexity.

In this chapter we further develop this hypothesis to a testable form; propose it be tested by experiment on a simulation; describe an appropriate experimental design and model for a variety of environmental changes; and finally discuss the results of the experiment. The conceptual model underlying all of these steps is shown in \cref{fig:conceptual-model-for-environmental-change}. 

\begin{figure}
	\begin{center}
		\includegraphics[width=\linewidth]{figures/conceptual-model-for-environmental-change}
	\end{center}
\end{figure}\label{fig:conceptual-model-for-environmental-change}

First, we continue the discussion of learnability and predictability for two inter-related reasons: we need a testable measure for our hypothesis, and we need a generator for environmental changes that can be described in terms of the measure.

Now for some definitions:

A \emph{time series} is a set of observations $x_i$, each one being recorded at a specific time $t$ \textcite{Brockwell:2002dq} where an observation $x_i \in$ some set $\{X\}$, assumed to be $\mathbb{R}$.

\emph{Context} is any attribute whose values are largely independent but tend to be stable over contiguous intervals of another attribute known as the \emph{environmental attribute.} \textcite{Sammut:2010cr} The environmental attribute is typically, but not always, time; other attributes such as location are also possible. A sequence with stationary distribution is a context \textcite[p289]{Gama:2004ve}.

An instance $X_j$ is generated by a source, $S_j$. If every instance is sampled from the same source, that is $S_1 = S_2 = ... = S_{t+1} = S$ then the concept is \emph{stable}. If for any time points $i$ and $j$ $S_i \ne S_j$ then there is \emph{concept drift} \textcite{Zliobaite:2009cr}

According to Zliobaite \textcite{Bifet:2011uq,Zliobaite:2009cr}, the main types of concept drift can be classified using two attributes - speed, and reoccurrence - where speed can be either sudden or gradual, and reoccurrence either always new or reoccurring.  

These attributes when combined produce three independent categories - sudden, gradual and reoccurring.  In sudden drift there is a distinct break between concepts; gradual drift shows a period of mixed concepts, and reoccurring drift shows alternating or repeating concepts.  A problem may exhibit more than one source of concept drift, and in fact many real-world problems are of this form.

\section{Environmental model}\label{environmental-model}

\Textcite{Jablonka1995} and \textcite{Paenke:2007ie} share a simple model for environmental change, with abrupt switches between two defined environments, with the time between switches either being fixed or stochastic according to some probability. \Textcite{Gaucherel2012} also describes a single model for environmental change--a period of ``smooth'' change (either according to a form of $sin$ curve, or unchanging) followed by an abrupt change, repeated--with variation in the length and degree of each period. By contrast, \textcite[79]{Schuster2011}, when describing the relationship between fitness landscapes and error thresholds, details five distinct models of change: ``(i) the single-peak landscape corresponding to a mean field approximation, (ii) the hyperbolic landscape, (iii) the step-linear landscape, (iv) the multiplicative landscape, and (v) the additive or linear landscape.''.

Returning to first principles, any model must describe two particular elements of the environmental change: the scope of the change, and the shape of the change. First, we discuss the scope of change. Our evolutionary model allows us to group entities at three different levels:
\begin{enumerate}
	\item The group of all entities.
	\item A group for each set of ``related'' entities, where the most natural and obvious relation is that between parent and child; this is unambiguous and straightforward in our model where each entity has only one parent. We refer to a group of entities related by inheritance as a \emph{lineage}.
	\item A single-member group for each entity.
\end{enumerate}

In this work environmental changes may be applied to either of the first two of these three levels, with a consistent level applying throughout a run; the first level because it is the simplest application of environmental change, and the second as it represents the familiar scenario where we expect similar entities to react in similar ways to change, and where similarity is a result of descent: entities that share a common ancestor are more similar to each other than they are to other lineages. \todo{explanation for not addressing third level}

The shape of change is less constrained, and the space of all potential changes at any timestep effectively limitless: in fact, the potential change $\delta$ at timestep $t$ is $\delta_t\in R$. Simply taking a random sample from this space at each step is unlikely to result in enough resolution to test any relevant hypothesis. At the other extreme, taking only a small number of predetermined changes is likely to lead to a sampling fallacy where the choices bias the conclusions.

Instead, we need a way to parameterize the set of interesting enviromental changes so we can sample from a constrained but not predetermined parameter space. The range covered by the parameter space should include both predictable and unpredictable changes as the difference between the two is core to our hypothesis.

Our chosen method is to represent environmental change as a parameterized timeseries of particular form. Environmental change is modelled as an enhanced AR(1) or first-order autoregressive timeseries, with each timestep corresponding to one evolutionary generation. Specifically, we can describe the evolutionary change at each timestep as a function of the previous timestep:

$x_t = \Theta x_{t-1} + e_t + \delta$

where $x_t$ is the change at timestep $t$, $\Theta$ is the AR coefficient, $e_t$ is a random, normally distributed, error component around a mean of $0$, where $e_t\stackrel{iid}{\sim}N(0,\sigma^{2}_e)$, and $\delta$ is a fixed bias value.

This series allows us to represent a broad range of environmental changes:

\begin{itemize}
	\item Each timeseries is completely specified by three parameters, $\Theta$, $\sigma_e$ and $\delta$.
	\item $\Theta$ in an autoregressive timeseries can be interpreted as specifying stability or smoothness, while $\delta$ is a fixed change. We use $\delta$ to model a fitness trend - environments with a positive $\delta$ will see the fitness of each entity improved at each generation, with the opposite of course true of negative $\delta$. Note that with this formulation we can model linear trends in fitness from a fixed bias in the environment produced by the $\delta$ term. This is not the same as a ARI model where the environment timeseries itself would show a trend.
	\item The timeseries is defined by three independent elements, two predictable (driven by $\Theta$ and $\delta$) and the other ($sigma_e$) random and unlearnable. By changing the ratio between the two we can examine the performance of the evolutionary algorithm on some continuum of predictability.
	\item An AR timeseries has the property of stationarity, meaning that the mean of the series is constant through time. However, as we apply the series values as deltas to element fitness, fitness can be non-stationary, and so may show a long term trend. This allows a simple non-differencing timeseries to describe a steady improvement or worsening in fitness.
	\item As a corollary of stationarity, the range is strongly determined by the initial parameters. This is a useful property as it means that with appropriate parameter choices no scaling of the range is required. 
\end{itemize}

Statistical techniques are commonplace for time-series predictions \textcite{Brockwell:2002dq}. ARMA models are used for \emph{stationary} series, that is a series where \todo{Add definition}, equivalent to saying the series does not demonstrate concept drift. ARIMA models apply for non-stationary series where the difference between two sequential values of the original series can be shown to produce a stationary series. The I, or ``Integrated'' component, of the model provides the differencing. Seasonality, a particular form of re-occuring concept drift, may be modelled with both ARMA and ARIMA models by incorporating a seasonality component in the model \todo{reference}. If instead of mean value prediction we are interested in the mean variance (such as in financial markets) then ARCH and GARCH models are appropriate. ARMA or ARIMA combined with ARCH or GARCH can be used in iterative sequence to simultaneously predict both mean and variance for \todo{add defn - heteroscedastic} series. 

Time-series modeling provides techniques for describing time-series data in terms of an underlying model, summarizable in a few parameters. The process can also be reversed to produce a time-series from the model; in other words, if the variety of environmental change required to test our hypothesis can be described by a standard time-series model, the parameters that determine that model can also serve as our summary measure for environmental change. Note however that the change is described by a function or relationship between two or more parameters, depending on the model, rather than the one of a complexity-based measure.

\section{Hypothesis}

Our hypothesis, that fidelity is related to learnability, can now be refined in terms of the predictability of the environment, where predictability is proportional to some relation involving $\Theta$, $\sigma_e$ and $\delta$.

From the hypothesis we make these predictions:
\begin{enumerate}
	\item Fidelity is at a minimum in conditions of maximum unpredictability, that is for timeseries where $\Theta=0$, $\delta=0$ and $\sigma_e>0$.
	\item Fidelity is proportional to the predictability in the environment.
\end{enumerate}

\section{Experimental design}

As all three independent variables,  $\Theta$, $\sigma_e$ and $\delta$, are continuous in $\mathbb{R}$, and as we wish to test the specific relationship of fidelity across a range of these variables, our earlier factorial and fractional-factorial experiment designs are no longer appropriate. Instead we adopt a response surface design where each experiment run has initial values of the independent variables taken from a uniform random sample from their range, or in other words, a series of random samples with uniform probabilty from a space described as the hypercube with one variable on each of the three axes (see \cref{fig:hypercube}.)

\begin{figure}
	\begin{center}
		\includegraphics[width=\linewidth]{figures/hypercube}
	\end{center}
\end{figure}\label{fig:hypercube}

<<factorialthetasd, pdfcrop=TRUE, echo=FALSE, warning=FALSE, cache=TRUE, fig.pos='htp', fig.cap=''>>=
library(reshape2)
library(ggplot2)
library(cowplot) # styling of plots, extension of ggplot2
library(gridExtra)

t1 <- read.csv('results/environments-factorial.csv', header=FALSE, colClasses=c("numeric","numeric","numeric"))

t1$run <- 1:nrow(t1)
names(t1)[1:3]<-c("theta", "sd", "bias")
t2 <- melt(t1,id=c('run','theta','sd','bias'))
t2$theta <- round(t2$theta,3)
t2$sd <- round(t2$sd,3)
t2$bias <- round(t2$bias,3)

for (r in unique(t2$run)) {
	t2[t2$run==r,'t'] <- 1:50 # tag with timestamp
	
	fitness <- 0.5
	for (t in 1:50) {
		fitness <- max(0,min(1,fitness + t2[t2$run==r & t2$t==t,'value']))
		t2[t2$run==r & t2$t==t,'fitness'] = fitness
	}
}
ap <- ggplot(subset(t2,bias==0)) + geom_line(aes(x=as.numeric(variable),y=value)) + facet_grid(theta~sd, labeller='label_both') + labs(x="t", y="Fitness change")
bp <- ggplot(subset(t2,bias==0)) + geom_line(aes(x=t,y=fitness)) + facet_grid(theta~sd, labeller='label_both') + labs(x="t", y="Fitness change")
grid.arrange(ap,bp,nrow=2,ncol=1)
@

<<factorialsdbias, pdfcrop=TRUE, echo=FALSE, warning=FALSE, cache=TRUE, fig.pos='htp', fig.cap=''>>=
ap <- ggplot(subset(t2,theta==0)) + geom_line(aes(x=as.numeric(variable),y=value)) + facet_grid(sd~bias, labeller='label_both') + labs(x="t", y="Fitness change")
bp <- ggplot(subset(t2,theta==0)) + geom_line(aes(x=t,y=fitness)) + facet_grid(sd~bias, labeller='label_both') + labs(x="t", y="Fitness change")
grid.arrange(ap,bp,nrow=2,ncol=1)
@

<<sampleenvironment, pdfcrop=TRUE, echo=FALSE, cache=TRUE, fig.pos='htp', fig.cap=''>>=
library(reshape2)
library(ggplot2)
library(cowplot) # styling of plots, extension of ggplot2

t1 <- read.csv('results/environments.csv', header=FALSE, colClasses=c("numeric","numeric","numeric"))
t1$run <- 1:nrow(t1)
names(t1)[1:3]<-c("theta", "sd", "bias")
t2 <- melt(t1,id=c('run','theta','sd','bias'))
t2$theta <- round(t2$theta,3)
t2$sd <- round(t2$sd,3)
t2$bias <- round(t2$bias,3)
ggplot(t2) + geom_line(aes(x=as.numeric(variable),y=value)) + facet_wrap(~theta+sd+bias, labeller='label_both') + labs(x="t", y="Fitness change")
@

% Needs sampleenvironment
<<cumulativefitness, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.cap=''>>=
for (r in unique(t2$run)) {
	t2[t2$run==r,'t'] <- 1:50 # tag with timestamp
	
	fitness <- 0.5
	for (t in 1:50) {
		fitness <- max(0,min(1,fitness + t2[t2$run==r & t2$t==t,'value']))
		t2[t2$run==r & t2$t==t,'fitness'] = fitness
	}
}

ggplot(t2) + geom_line(aes(x=t,y=fitness)) + facet_wrap(~theta+sd+bias, labeller='label_both') + theme(strip.text.x = element_text(size = 6))
@

% Needs sampleenvironment
<<sampleentropy, pdfcrop=TRUE, echo=FALSE, warning=FALSE, cache=TRUE, fig.pos='htp', fig.cap='Approximate entropy of each example environment.'>>=
library(pracma)
library(ggplot2)
library(cowplot) # styling of plots, extension of ggplot2

t2 <- t1[,1:3]
names(t2)[1]<-"theta"
names(t2)[2]<-"sd"
names(t2)[3]<-"bias"
for(n in 1:nrow(t1)) {t2[n,'sample_entropy'] <- sample_entropy(unlist(t1[n,4:52],use.names=FALSE))}
for(n in 1:nrow(t1)) {t2[n,'approx_entropy'] <- approx_entropy(unlist(t1[n,4:52],use.names=FALSE))}

#summary(lm(sample_entropy~theta+sd,data=t2)) # can error as some sample_entropy values may be Inf
ggplot(t2, aes(sd,approx_entropy)) + geom_point() + geom_smooth(method='lm') # formula not required

#summary(lm(approx_entropy~theta + sd, data = t2)) #  SIGNIFICANT
@

The range of each variable (the length of each side of the hypercube) is set from earlier experimentation. We created two independent datasets by sampling from two hypercubes, described in \cref{tbl:range-of-independent-variables}.

\begin{table}
	\begin{center}
		\caption{Range of independent variables $\Theta$, $\sigma_e$ and $\delta$}
		\label{tbl:range-of-independent-variables}
		\begin{tabular}{@{}llll@{}}
			\toprule
			Dataset   	 	&  $\Theta$		& $\sigma_e$	& $\delta$\\
			\midrule
			Dataset no.1	& $[-0.4, 0.4]$	& $[0, 0.2]$ 	& $[-0.1, 0.1]$\\
			Dataset no.2	& $[-0.2, 0.2]$	& $[0, 0.1]$	& $[-0.05, 0.05]$\\
			Dataset no.3	& $[-0.2, 0.2]$	& $[0, 0.1]$	& $[-0.05, 0.05]$\\
			Dataset no.4	& $[-0.4, 0.4]$	& $[0, 0.4]$	& $[-0.04, 0.04]$\\
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}

The factors and levels along with their mapping to model parameters are given in \cref{tbl:factor-levels-c8}.

\begin{table}
	\caption{Factors mapped to model parameters, plus factor levels}\label{tbl:factor-levels-c8}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{2cm}p{6cm}@{}}
		\toprule
		Factor                 &Model parameter		&Number of Levels 	& Levels\\
		\midrule
		$p_{reproduction}$     &$p_{reproduction}$	&2                	& 0.66 or $fitness$\\
		$p_{selection}$        &$p_{selection}$		&2                	& 0.66 or $fitness$\\
		$n_{children}$         &$n_{children}$ 		&2                	& 2 or 5\\
		Reproduction		   &Reproduction		&2				 	& Correlated and Uncorrelated (see \cref{reproduction-distribution-factors-c8})\\
		Distribution           &--					&2                	& Folded normal distribution or sampled normal distribution\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}\label{reproduction-distribution-factors-c8}
	\caption{Levels for the factor \emph{Reproduction}}
	\begin{tabular}{@{}p{2.5cm}p{3cm}p{7cm}@{}}
		\toprule
		Reproduction&Child entity parameter					&Distribution shape\\
		\midrule
		\multirow{2}{*}{Correlated}		&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=1-fidelity$\\
		
		\multirow{2}{*}{Uncorrelated}	&$fitness_{new}$	&$\mu=fitness$ and $\sigma=1-fidelity$\\
										&$fidelity_{new}$	&$\mu=fidelity$ and $\sigma=\mathcal{U}[0, 1.0]$\\
		\bottomrule
	\end{tabular}
\end{table}


\section{Results and discussion}

<<figure22, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.cap='Distribution of maximum generation reached for all runs of dataset no.1 (top), and dataset no.2 (bottom). Axes are to the same scale. Runs are ordered by final generation reached.'>>=
library(ggplot2)
library(gridExtra)
library(cowplot) # styling of plots, extension of ggplot2

# BY_LINEAGE	CORRELATED	N_OFFSPRING	P_REPRODUCE	P_SELECTION	RESTRICTION	ar_bias	ar_sd	ar_theta	ave_fid	ave_fit	experiment	gen	pop	run	sd_fid	sd_fit
colClasses <- c("factor","factor","factor","factor","factor","factor","numeric","numeric","numeric","numeric","numeric","factor","integer","numeric","integer","numeric","numeric")
r1 <- read.csv('results/results-0c267bcd2-a.csv', colClasses=colClasses)
r2 <- read.csv('results/results-0c267bcd2-b.csv', colClasses=colClasses)
r3 <- read.csv('results/results-cc648a0a9.csv', colClasses=colClasses)
r4 <- read.csv('results/results-996060f.csv', colClasses=colClasses)
results = rbind(r1,r2,r3,r4)

t1 <- aggregate(r1$gen,by=list(r1$run),max)
t2 <- aggregate(r2$gen,by=list(r2$run),max)
t3 <- aggregate(r3$gen,by=list(r3$run),max)
t4 <- aggregate(r4$gen,by=list(r4$run),max)
max_nrow <- max(nrow(t1),nrow(t2),nrow(t3),nrow(t4))
ap <- ggplot(t1,aes(1:nrow(t1),t1[order(t1[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
bp <- ggplot(t2,aes(1:nrow(t2),t2[order(t2[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
cp <- ggplot(t3,aes(1:nrow(t3),t3[order(t3[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
dp <- ggplot(t4,aes(1:nrow(t4),t4[order(t4[,2],decreasing=TRUE),2]))+geom_bar(stat="identity") + scale_x_continuous(limits=c(0,max_nrow)) + labs(x="", y="Final generation")
grid.arrange(ap,bp,cp,dp,nrow=4,ncol=1)
@

A summary of the results from each of the four datasets is given in \cref{tbl:summary-for-changing-datasets}. The difference in the proportion of  completed runs to total runs reflects the respective ranges of the independent variables (as seen in \cref{tbl:range-of-independent-variables}), as shown graphically in \cref{fig:figure22}.

\begin{table}
	\begin{center}
		\caption{Summary of results for changing environments}
		\label{tbl:summary-for-changing-datasets}
		\begin{tabular}{@{}lll@{}}
			\toprule
			Dataset    		& $n$ (total runs) 				& Completed runs\\
			\midrule
			Dataset no.1	& \Sexpr{max(r1$run)+1}			& 	\Sexpr{nrow(r1[r1$gen==500,])+1}\\
			Dataset no.1	& \Sexpr{max(r2$run)+1}			& 	\Sexpr{nrow(r2[r2$gen==500,])+1}\\
			Dataset no.1	& \Sexpr{max(r3$run)+1}			& 	\Sexpr{nrow(r3[r3$gen==500,])+1}\\
			Dataset no.1	& \Sexpr{max(r4$run)+1}			& 	\Sexpr{nrow(r4[r4$gen==500,])+1}\\
			\bottomrule
		\end{tabular}
	\end{center}
\end{table}

<<figure23, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, fig.pos='htp', fig.cap='.'>>=
library(ggplot2)
library(gridExtra)
library(cowplot) # styling of plots, extension of ggplot2

ap <- ggplot(subset(results,gen==500),aes(ar_sd,ave_fid)) + geom_point() + geom_smooth(method='lm')
bp <- ggplot(subset(results,gen==500)) + geom_point(aes(ar_bias,ave_fid)) # fid ~ -bias when bias <0, otherwise fid can reach max
grid.arrange(ap,bp,nrow=2,ncol=1)

#anova(lm(ave_fid ~ ar_theta*ar_sd*ar_bias, data=subset(results,gen==500))) # theta not significant
#anova(lm(ave_fid ~ ar_sd*ar_bias, data=subset(results,gen==500))) # bias and sd:bias most important, then sd
#anova(lm(sd_fid ~ ar_sd*ar_bias, data=subset(results,gen==500 & -0.001<ar_bias & ar_bias<0.001))) # Remove effect of bias, then ar_sd 0.001
@
<<figure24, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.cap='.'>>=
library(ggplot2)
library(gridExtra)
library(cowplot) # styling of plots, extension of ggplot2

ap <- ggplot(subset(results,gen==500 & -0.002<ar_bias & ar_bias<0.002),aes(ar_sd,ave_fid)) + geom_point()  + geom_smooth(method='lm')  # ave fid drops as sd increases
bp <- ggplot(subset(results,gen==500 & -0.002<ar_bias & ar_bias<0.002),aes(ar_sd,sd_fid)) + geom_point()  + geom_smooth(method='lm')  # sd fid increases as sd increases
grid.arrange(ap,bp,nrow=2,ncol=1)
@
<<figure25, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.cap='.'>>=
library(ggplot2)
library(gridExtra)
library(cowplot) # styling of plots, extension of ggplot2

ap <- ggplot(subset(results,gen==500),aes(ave_fit,ave_fid)) + geom_point() + geom_smooth(method='lm') # and relationship between these two
# Relationship between sd_fid and ave_fid!
bp <- ggplot(subset(results,gen==500)) + geom_point(aes(sd_fid,ave_fid))
grid.arrange(ap,bp,nrow=2,ncol=1)
#anova(lm(sd_fid~ave_fid, data=subset(results, gen==500))) # 0.001
@

<<figure26, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.cap='Effect of lineage upon results.'>>=
library(ggplot2)
library(gridExtra)
library(cowplot) # styling of plots, extension of ggplot2

ap <- ggplot(subset(results,gen==500 & -0.002<ar_bias & ar_bias<0.002),aes(ar_sd,ave_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE)
bp <- ggplot(subset(results,gen==500 & -0.002<ar_bias & ar_bias<0.002),aes(ar_sd,sd_fid)) + geom_point()  + geom_smooth(method='lm')  + facet_wrap(~BY_LINEAGE)
grid.arrange(ap,bp,nrow=2,ncol=1)
@

%<<figure27, pdfcrop=TRUE, echo=FALSE, cache=TRUE, warning=FALSE,fig.pos='htp', fig.cap='Sample entropy.'>>=
%library(pracma)
%library(ggplot2)
%library(cowplot) # styling of plots, extension of ggplot2
%
%t2 <- t1[,1:3]
%names(t2)[1]<-"theta"
%names(t2)[2]<-"sd"
%names(t2)[3]<-"bias"
%for(n in 1:nrow(t1)) {t2[n,'sample_entropy'] <- sample_entropy(unlist(t1[n,4:52],use.names=FALSE))}
%for(n in 1:nrow(t1)) {t2[n,'approx_entropy'] <- approx_entropy(unlist(t1[n,4:52],use.names=FALSE))}
%
%ggplot(t2, aes(sd,approx_entropy)) + geom_point() + geom_smooth(method='lm') # formula not required
%@

\begin{DRAFT}
The unbiased sample variance with Bessel's correction is \todo{reference}:
\[
s^2 = \frac {1}{n-1} \sum_{i=1}^n  \left(x_i - \overline{x} \right)^ 2 = \frac{\sum_{i=1}^n \left(x_i^2\right)}{n-1} - \frac{\left(\sum_{i=1}^n x_i\right)^2}{(n-1)n}.
\]

Let us assume that the upper bound on fidelity of 1.0 has no effect on $s^2$.
Then we can divide the fidelity values at time $t$ into those below the mean and those above; arrange the sample values so that the first $m$ fall below the mean and the remainder above. The sample variance can now be written as:  

\[
s^2 = \frac {1}{n-1} \sum_{i=1}^n  \left(x_i - \overline{x} \right)^ 2 = \frac {1}{n-1} \sum_{i=1}^m  \left( \left(x_i - \overline{x} \right)^ 2 + \sum_{i=m}^n  \left(x_i - \overline{x} \right)^ 2 \right)
\]

As $\overline{x}$ approaches 1.0 (the upper bound on fidelity) from below:

\[
s^2 = \frac {1}{n-1} \left( \sum_{i=1}^m   \left(x_i - 1 \right)^ 2 + \sum_{i=m}^n  \left(x_i - 1 \right)^ 2 \right)
\]

But by our initial statement, $s^2$ remains unchanged, therefore...

\[
\frac {1}{n-1} \left( \sum_{i=1}^m   \left(x_i - 1 \right)^ 2 + \sum_{i=m}^n  \left(x_i - 1 \right)^ 2 \right) = \frac{\sum_{i=1}^n \left(x_i^2\right)}{n-1} - \frac{\left(\sum_{i=1}^n x_i\right)^2}{(n-1)n}.
\]
\end{DRAFT}


\section{Future work}\label{part2-future-work}

There are some obvious extensions of this model that for reasons of scope have been left for future work. First, the model currently assumes only single-parent inheritance, whereas many biological species have two parents. Extending to two parents would be a useful enhancement to increase the model's scope. Second, the model does not include any influence from development (the production of the phenome from the genome). However, it is unclear at this stage what effect development would have on the model as its effects are bundled into the overall \emph{fitness} parameter. Finally, although outside of the overall scope of this work in evolutionary systems, the effect of acquired characteristics would be interesting to explore. Others (\eg \textcite{Gaucherel2012,Paenke:2007ie,Sasaki:2000dq}) have studied the differences between general models based on acquired and non-acquired characteristics, finding a difference between models in changing environments. This would be another area of exploration for the future.

Two other topics for possible future work are abrupt environmental change, and an information-based measure for change, as explained below.

\subsection{Abrupt environmental change}
	
Although the generator described earlier produces a time series for environmental change with the property of stationarity, the $\delta$ term makes the evolutionary model of fitness non-stationary. However, any change is steady and gradual. An extension would be to coopt the idea of concept drift from time series analysis to induce an abrupt change with probability $p$ at each generation. Each change would therefore form a new `concept`. Instead of the environment changing in a predictable and describable way from one generation to another, the change could not be predictable from the earlier history.

Stationarity is inherently a constraint for applying statistical methods to the analysis of evolutionary models, where almost by definition, the outcomes change over time. One common approach is be to assume approximate stationarity over short(ish) periods, along the lines of moving window or local kernel methods in time-series analysis. Alternatively, we could reformulate the problem so that out of all the possible message channels, we choose to investigate only those that meet the stationarity assumption. It's hard to see though how we can effectively examine an evolving system by discarding most of the relevant information.

Another broad approach might be to modify the method to reduce its dependence on stationarity. For example, taking one part of the problem, \textcite{LingFengLiu2014} develops a modification of the well-known Shannon entropy formula for non-stationary processes. The method though assumes that the process moves between a number of states with the series output following a known distribution in each state. Although this approach does provide an upper-bound to the information entropy of the process output, identifying the states and the accompanying distributions from a black-box process is likely to prove a challenge. Fundamentally, non-stationarity remains a problem for most methods.

\subsection{An information-based measure}

Predictability related to compression and information entropy. Compression is a mechanism for pattern-discovery.  \textcite{Shalizi2001} identifies patterns (pattern $P$ of an object $O$) with the ability to predict (given $P$, can infer $O$) or compress (given $O$, can compress to $P$). Compression doesn't imply Prediction. There is a related concept in algorithmic complexity theory--the difference between easily solvable (P) (prediction) and easily verifiable (NP) (compression). A problem may be decidable without being easily solvable. 

In a time-independent way we can identify patterns in an image, for example, that allows us to substitute the pattern for the raw data. It is thus related to algorithms - compression is the discovery of a specific algorithm to take raw data and produce patterned data, with the goal of increasing the information content and reducing the information entropy of the patterned data. The algorithm is the patterned data. Information entropy can then, in theory at least, be measured by the Kolmogorov entropy or algorithmic complexity - the length of the algorithm. In practice various other entropy measures, such as Shannon, sample, and approximate entropy, are commonly used for time-series characterization.

In a time-dependent way compression equals prediction - in the sense that we can produce an algorithm that improves our ability to predict the future output of a process. Prediction on one spatial dimension is called a time series. Most prediction requires consistent conditions or contexts - when these change our predictive ability is reduced, (in time-series this is called concept drift). 

Compression, as mechanism to identify patterns, will identify items spatially if we can map items to patterns. The choice of compression method will privilege different ways of defining a pattern - if we are to use pattern discovery we need to determine what are interesting patterns - which is hardly domain agnostic. 

\textcite[Appendix 1]{Edmonds1999} contains a thorough review of complexity measures. More recently see \textcite{Prokopenko2009}, \textcite{Ladyman2011} and \textcite{Lloyd2001}.

Statistical Complexity, or $C_\mu$, based on causality, is fundamentally time-dependent: one dimension plus time, although an extension to two spatial dimensions has been done by Shalizi with a more general extension to multi-dimensions still open although a mapping method for multi-dimensional data has been proposed by \textcite{Nerukh2002}, and a dimension reduction approach by fuzzy-clustering can be found in \textcite{Young2005}.

The benefits of $C_{\mu}$ \textcite{Crutchfield1989} are that it matches our intuition of complexity (better than most alternatives), it has strong theoretical support, and it makes no major assumptions about the underlying data other than stationarity - it is domain agnostic. \textcite{Shalizi2001} provides the best theoretical explanation of $C_{\mu}$ and epsilon-machines; Shalizi's PhD thesis \textcite{Shalizi2001a} provides further context. 

$C_{\mu}$ has been applied to a number of domains including random boolean networks \textcite{Gong2012}, spin \textcite{Vrabic2012,Shalizi2007,Nerukh2002,Feldman1998}, estimation of cortical thinning from brain MRI data \textcite{Young2008}, autonomy of protocells \textcite{Krakauer2008} and detection of anomalies (such as imminent crankshaft failure) directly from the causal states \textcite{Xiang2008}.
The canonical formulation of $C_{\mu}$ depends on two assumptions--discrete values and discrete time \textcite[p.24]{Shalizi2001}, and exact joint probabilities--which are unproblematic in our domain, and another, conditional stationarity, which poses a problem. Conditional stationarity, or time-invariant transition probabilities \textcite[p.25]{Shalizi2001} means $P(\overrightarrow{S}_t^L = s^L) = P(\overrightarrow{S}_0^L = s^L)$ for all $t \in \mathbb{Z}$ or ``the distribution of futures, conditional on histories, must be independent of when the history comes to an end'' \textcite[p.119]{Shalizi2001}.



\chapter{Conclusions}
\begin{DRAFT}
Given:\newline
Hypothesis 1 (that Variation, Selection and Inheritance are sufficient for Evolution) and,\newline
hypothesis \autoref{hypothesis-2} (that Variation and Selection are sufficient for Inheritance),\newline
we suggest that:

\textit{Hypothesis 3}: Variation and Selection are sufficient for Evolution

\emph{erroneous copying} \parencite{Zachar2010} results in informational replicators.

The model as described is general, under the assumptions given below. It is also directly comparable to models from Evolutionary Computation and so we also expect any results and conclusions to be relevant to EC models.

\TODO{Map to standard EA models - mutation only etc}
\end{DRAFT}

\section{Elimination of alternative explanations}\label{elimination-of-alternative-explanations}
\begin{DRAFT}
	\subsection{Variation alone is sufficient for Inheritance}
	As an experimental test, we can discount this alternative hypothesis by showing an example of not(V-\textgreater{}I) or, V and not I.
	
	\subsection{Selection alone is sufficient for Inheritance}
	The test is to show an example of S and not I.
	
	\subsection{Variation and Selection, without property correlation, is sufficient for Inheritance}
	Test: already shown in earlier analysis, specifically in the Hypothesis analysis sections where the factor \textbf{Correlate Fidelity} is set to the low value ("false").
\end{DRAFT}
